





































































































































































































































































































































































































































































































































































































































































































[{"categories":["shell"],"contents":"介绍如何使用pyEGA3下载EGA数据。\n注意 一. 安装下载工具 要求Python版本大于等于3.6。\n使用pip安装，还有其他的安装方式，详情参考github主页：https://github.com/EGA-archive/ega-download-client\nsudo pip3 install pyega3 linux和mac用户检查端口8443和8052是否打开：\nopenssl s_client -connect ega.ebi.ac.uk:8443 openssl s_client -connect ega.ebi.ac.uk:8052 如果端口是打开的，命令行会显示CONNECTED。\nWindows用户，打开下面的网址：\nhttps://ega.ebi.ac.uk:8443/ega-openid-connect-server/ https://ega.ebi.ac.uk:8052/elixir/central/stats/load\n如果端口是打开的，可以直接打开网址。\n二、使用流程 2.1 构建一个credentials文件 将文件命名为：default_credential_file.json\n{  \u0026#34;username\u0026#34;: \u0026#34;ega-test-data@ebi.ac.uk\u0026#34;,  \u0026#34;password\u0026#34;: \u0026#34;egarocks\u0026#34; } 2.2 下载数据 在下载数据前，检查授权数据集，没有授权的数据集无法直接通过这种方法下载。\npyega3 -cf \u0026lt;/Path/To/default_credential_file.json\u0026gt; datasets 显示数据集中的文件\npyega3 -cf \u0026lt;/Path/To/default_credential_file.json\u0026gt; files EGAD\u0026lt;NUM\u0026gt; 根据检索到的数据集的ID：EGAD\u0026lt;NUM\u0026gt; 来下载数据集\npyega3 -cf \u0026lt;/Path/To/default_credential_file.json\u0026gt; fetch EGAD\u0026lt;NUM\u0026gt; --output-dir \u0026lt;/Path/To/OutputDirectory\u0026gt;   \n 下载单个文件\npyega3 -cf \u0026lt;/Path/To/default_credential_file.json\u0026gt; fetch EGAF\u0026lt;NUM\u0026gt; --output-dir \u0026lt;/Path/To/OutputDirectory\u0026gt; 还可以限定范围下载，比如从BAM文件中下载1号染色体的数据：\npyega3 fetch -cf \u0026lt;/Path/To/default_credential_file.json\u0026gt; --reference-name 1 --format BAM --output-dir \u0026lt;/Path/To/OutputDirectory\u0026gt; EGAF\u0026lt;NUM\u0026gt; 从BAM文件中下载1号染色体0-1000000范围的数据：\npyega3 fetch -cf \u0026lt;/Path/To/default_credential_file.json\u0026gt; --start 0 --end 1000000 --reference-name 1 --format BAM --output-dir \u0026lt;/Path/To/OutputDirectory\u0026gt; EGAF\u0026lt;NUM\u0026gt; 参考资料  github pyEGA3 ","date":"September 28, 2022","image":null,"permalink":"/post/2022-9-01_ega/","title":"使用pyEGA3下载EGA数据"},{"categories":["shell"],"contents":"介绍如何下载dbGAP数据库需要申请的数据。\n 一、下载步骤 title1 使用NCBI的SRA toolkit中的prefetch命令行功能和cart文件或者SRA accession进行下载。cart帮助批量下载数据，SRA accession帮助单独下载数据。\n1. 下载并安装Aspera connect Aspera：一个高速文件传输系统，方便下载数据。\n下载链接：https://downloads.asperasoft.com/en/downloads/8?list\n 确保安装的是connect\n 2. 选择并保存数据信息在cart文件中 除了cart文件，也可以根据SRA accession下载\n  登录dbgap\n  点击My Requests，查看批准的请求\n   确保已经获得批准\n  查看request file   \n 选择dbGap file selctor下载基因型和表型数据\n \n 选择SRA RUN selector下载SRA数据\n \n  选择数据并下载Cart文件   \n  \n 3. 使用prefetch进行数据下载 SRA Toolkit版本低于2.10.2时，需要在此步骤之前增加使用dbGaP repository key进行编译步骤，在通过编译产生的 dbGaP project directory目录下进行后续操作。\n3.1 找到密钥  dbGaP repository key文件包括了SRA Toolkit所需要用来确定申请人和dbga数据所属项目的信息，那么如何下载dbGaP repository key呢？  在action位置找到对应的批准的数据对应的project的get dbGap repository key，下载得到.ngc格式的文件。\n \n 3.2 表型数据 运行prefetch命令下载：\nprefetch --ngc your_file.ngc --cart cart_prj#####_###.krt 使用nohup和末尾的\u0026amp;后台运行，-X 99999999 是下载大小限制\nnohup prefetch -X 9999999999999 --ngc your_file.ngc --cart cart_prj#####_###.krt \u0026amp;   \n 表型数据需要解密，下载下来的表型数据后缀是.ncbi.enc，进行解密：\n \n $ vdb-decrypt --ngc your_file.ngc ~/ncbi/dbGaP-26086/files/ # 整个表型数据存放的文件夹进行解密 解密完成之后，文件的后缀ncbi_enc不见了。\n3.3 数据 cart文件或SRA accession下载\n cart文件  prefetch --ngc your_file.ngc --cart ###.krt  SRA accession  prefetch --ngc your_file.ngc SRR1234567 如果部分sra文件下载失败，提取下载失败的SRRXXX名字，放入一个新的文件中，对这个新的文件进行prefetch下载。\n参考资料  https://www.ncbi.nlm.nih.gov/sra/docs/sra-dbgap-download/  title2","date":"September 26, 2022","image":null,"permalink":"/post/2022-9-14_dbgap/","title":"下载dbgap数据"},{"categories":["shell"],"contents":"介绍经常使用的数据库，以及数据的申请和下载。\n一、常用的数据来源和申请渠道 排名不分先后。\n  NCBI（经常在dbGAP申请和下载原始数据）\n  UCSC Xena（TCGA，PCAWG；多组学数据，单细胞RNA测序\u0026hellip;）\n  EGA（原始数据）\n  NGDC（中国的数据库，申请友好，从申请到批准平均一天，必须有职称的人员申请）\n  UK biobank（原始数据在DNAnexus平台上）\n  cbioportal（靶向测序，TCGA，WES/WGS）\n  TCGA（肿瘤基因图谱计划）\n  ICGC Data Portal（国际肿瘤基因组计划；基因异常表达，体细胞突变，表观遗传修饰，临床数据等）\n  GEO（表达数据，芯片数据，单细胞数据）\n  CCLE（细胞系数据）\n  cosmic（细胞系数据）\n  gdsc（细胞系数据）\n  HMF（国外数据库不对中国开放）\n  文献中的supplement或其他储存方式\n  二、数据下载 2.1 NCBI 官网：https://www.ncbi.nlm.nih.gov/\n 数据范围  NCBI包含六大类数据库：\n \n 下载方式  我平时主要使用dbGAP去申请数据，所以着重介绍一下如何下载dbGAP数据：\n下载dbGAP数据\n2.2 UCSC Xena 官网：http://xena.ucsc.edu/\n包含1500+的数据集和50+种癌症类型，支持几乎任何基因组数据，提供简单的数据分析和数据下载。\n 数据范围  支持下载TCGA，PCAWG，ICGC，TARGET，GTEx（多组织、全基因组序列和rna序列数据），CCLE等等数据。\n数据类型包含：https://ucsc-xena.gitbook.io/project/public-data-we-host/types-of-data-we-have\n下载方式    直接通过网页访问和下载：https://xenabrowser.net/datapages/\n  R包：UCSCXenaTools\n  library(UCSCXenaTools) # 1 get all datasets XenaGenerate() # 2 get TCGA BRCA XenaGenerate(subset = XenaCohorts == \u0026#34;TCGA Breast Cancer (BRCA)\u0026#34;) # 3 get all datasets containing BRCA XenaGenerate(subset = grepl(\u0026#34;BRCA\u0026#34;, XenaCohorts)) 2.3 EGA 官网：https://ega-archive.org/\n 数据范围  包含生物医学研究项目产生的遗传和表型数据，包含癌症的数据。\n \n 下载方式  下载EGA数据\n2.4 NGDC 官网：https://ngdc.cncb.ac.cn/\n 数据范围   \n 下载方式  GSA：人类遗传资源组学原始数据归档库，是NGDC的一部分。\n下载GSA数据\n2.5 UK biobank 官网：https://www.ukbiobank.ac.uk/\n需要所在机构给UK biobank提出申请，才能够申请，数据分为4个等级，影像学数据可以提供下载，基因组数据需要通过dnanexus分析。\n 数据范围   \n 包含全基因组测序，全外显子组测序，影像学数据，临床数据等等。\n下载方式  影像学数据可以下载，基因组数据不提供下载，允许在dnanexus云平台分析。\n2.6 cbioportal 官网：https://www.cbioportal.org/\n 数据范围  多维度癌症基因集数据。整合了包括体细胞突变、DNA拷贝数变异、mRNA和miRNA表达量、DNA甲基化、蛋白质丰度、临床信息等数据类型，能够对数据进行可视化和分析。\n下载方式  下载cbioportal数据\n2.7 TCGA 官网：https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga\n 数据范围  肿瘤基因图谱计划，涉及33种癌症类型，包含基因组，表观基因组，转录组和蛋白质组数据。既包含汇总的处理好的数据，也可以下载原始数据。\n下载方式  测序原始数据和涉及个体信息的数据如生殖细胞突变等等需要获得批准才可下载。\n 使用gdc-client下载  下载地址\n  R包TCGAbiolinks下载\n  UCSC xena网页下载\n  2.8 ICGC 官网：https://dcc.icgc.org/\n 数据范围  是国际肿瘤基因组计划，包含基因异常表达，体细胞突变，表观遗传修饰，临床数据等。\n下载方式   直接通过网站下载  https://dcc.icgc.org/releases\n 原始数据受到限制，需要获得批准才可下载  官网提供了多种下载方式，可以进一步参考：https://docs.icgc.org/download/downloading-data/\n申请数据流程：https://docs.icgc-argo.org/docs/data-access/daco/applying\n2.9 GEO 官网：https://www.ncbi.nlm.nih.gov/geo/\n 数据范围  包含各种高通量实验数据的公共存储库，包含检测mRNA，基因组DNA和蛋白质丰度，以及非阵列技术，如基因表达系列分析（SAGE），质谱蛋白质组学数据和高通量测序数据，以及一些单细胞数据。罗列了数据集(GDS)、研究(GSE)、平台(GPL)、样本（GSM）的ID。\n下载方式   官网下载  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE63216\n R包GEOquery  主函数：\ngetGEO(  GEO = NULL,  filename = NULL,  destdir = tempdir(),  GSElimits = NULL,  GSEMatrix = TRUE,  AnnotGPL = FALSE,  getGPL = TRUE,  parseCharacteristics = TRUE )  GEO：字符串，四种类型的ID都可以，比如：\u0026lsquo;GDS505\u0026rsquo;,\u0026lsquo;GSE2\u0026rsquo;,\u0026lsquo;GSM2\u0026rsquo;,\u0026lsquo;GPL96\u0026rsquo;  library(GEOquery) eList \u0026lt;- getGEO(\u0026#34;GSE11675\u0026#34;) eData \u0026lt;- eList[[1]] eData ## ExpressionSet (storageMode: lockedEnvironment) ## assayData: 12625 features, 6 samples ## element names: exprs ## protocolData: none ## phenoData ## sampleNames: GSM296630 GSM296635 ... GSM296639 (6 total) ## varLabels: title geo_accession ... data_row_count (34 total) ## varMetadata: labelDescription ## featureData ## featureNames: 1000_at 1001_at ... AFFX-YEL024w/RIP1_at (12625 ## total) ## fvarLabels: ID GB_ACC ... Gene Ontology Molecular Function (16 ## total) ## fvarMetadata: Column Description labelDescription ## experimentData: use \u0026#39;experimentData(object)\u0026#39; ## Annotation: GPL8300  eList2 \u0026lt;- getGEOSuppFiles(\u0026#34;GSE11675\u0026#34;) 2.10 CCLE 官网：https://sites.broadinstitute.org/ccle/datasets\n 数据范围  是肿瘤细胞系数据，包含各种人源肿瘤细胞系的WES数据，WGS数据，RNAseq数据，扩增子数据，突变数据，甲基化数据，拷贝数变异数据等等。\n下载方式  https://sites.broadinstitute.org/ccle/datasets\n2.11 COSMIC 官网：https://cancer.sanger.ac.uk/cosmic\n 数据范围  汇集了和人类癌症相关体细胞突变的信息，数据来源于文献，且由专业的管理员审查。\n下载方式  https://cancer.sanger.ac.uk/cell_lines/download\n \n 2.12 gdsc 官网：https://www.cancerrxgene.org/\n 数据范围  描述了1000个人类癌细胞系，并用100种化合物对它们进行了筛选。可以找到药物反应数据。\nGDSC和CCLE具有重合473例细胞系：\n \n 下载方式  https://www.cancerrxgene.org/downloads/bulk_download\n参考资料   https://www.ncbi.nlm.nih.gov/books/NBK36439/\n  NGDC人类遗传资源组学原始数据归档库 数据申请及下载说明\n  linux下面ftp/wget命令下载文件夹目录\n  EGA\n  GEOquery\n  UK Biobank: An Open Access Resource for Identifying the Causes of a Wide Range of Complex Diseases of Middle and Old Age\n ","date":"September 26, 2022","image":null,"permalink":"/post/2022-9-14_datadownload/","title":"数据收集、申请和下载"},{"categories":["癌症基因组学","生物学"],"contents":"介绍易混淆的概念。\n  异倍性（aneuploidy）  描述染色体数目不是单倍体的倍数的一种状态。在肿瘤基因组中，该名词通常包括染色体臂的拷贝数变异，导致整条染色体变异和导致染色体臂变异的机制非常不同。不过该定义处于动态变化的过程。经典定义中指的是整条染色体的变化，扩展的定义则包含了染色体臂的扩增和缺失，在定量角度，则还包括以下情况：当受影响的基因组/基因/离散事件超过某阈值时。[1]\n 异倍性的涵盖范围\n 目前仍不清楚异倍性本身是如何影响肿瘤形成和进展的。oncogene以及肿瘤抑制基因几乎在所有的细胞类型和cellular context都驱动转化，但是异倍性不一样，它不是一个普遍的肿瘤发生的启动子。\n 染色体不稳定（chromosome instability, CIN）  导致异倍性产生的过程。通过增加基因组异质性，来促进肿瘤发生和肿瘤演化。虽然CIN和异倍性水平高度相关，但是存在一些癌细胞高度异倍性但是染色体稳定。任何可以定量染色体数目的方法都可以检测异倍性吗，但是这些方法不能够定量CIN，定量CIN需要检测染色体错误分离率，需要分析克隆种群中的染色体变异。\n CIN的后果是aneuploidy\nmutagenesis的后果是mutation\n  拷贝数变异负荷（CNA burden）  肿瘤中拷贝数变异的占比，通常定义为基因组受拷贝数变异影响的比例。\n focal copy number alteration  通常指的是包含很少的基因的小的拷贝数改变，和异倍性不同，该名词通常指的是基因的扩增超过1个拷贝。[1]\n euploidy  染色体数目完全是单倍体的整数倍。包括二倍体，三倍体等等，多倍体细胞都是euploidy。\n参考资料  [1]context is everything:aneuploidy in cancer ","date":"September 21, 2022","image":null,"permalink":"/post/2022-9-14_cnv1/","title":"【异倍性系列1】——易混淆概念"},{"categories":["癌症基因组学","生物学"],"contents":"介绍异倍性的概念。\n 异倍性难研究的原因：\n  大范围的一次染色体变异影响数百个基因，不能确定是哪个基因驱动特定的异倍性。\n  异倍性在context不同的情况下，会产生不同的，甚至相反的作用。\n  介绍或者排除特定的染色体存在技术困难。不能够系统的定义异倍性的后果。\n  一、异倍性的影响 1. 促进肿瘤发生   异倍性也会促进肿瘤发生：临床肿瘤样本的研究中发现，异倍性的程度和增殖富集以及细胞循环转录signature存在着正相关（通常被认为是促进肿瘤发生的指标【什么指标】）。mouse embryonic stem cells（mESCs）和human embryonic stem cells（hESCs）中展现出，特殊的单个三倍体同样可以是促进肿瘤发生。\n  肠癌早期的异倍性水平很低，在晚期上升。不止肠癌，在很多癌症中比如子宫癌等等，异倍性都是随着肿瘤进展增加的，可能标记着从局部到扩散。但是也存在癌症不是这种模式，比如乳腺癌和肺癌，异倍性在癌症早期就已经存在。\n  染色体不稳定性和异倍性不只影响原发肿瘤的生长，还塑造转移过程。染色体错误分开会通过增加karyotypic多样性【增加多样性会怎样？如何影响转移？】或通过激活cGAS-cGAMP-STING通路，来促进转移。\n  2. 抑制肿瘤发生   在酵母中发现单条染色体扩增会导致更慢的细胞增殖，以及有害的代谢和生理后果，在小鼠细胞系和人类细胞系中得到类似的结论：单条染色体扩增通常会损害增殖，改变代谢并诱导不同的压力反应。\n  另外，oncogene-transformed的三倍体细胞相比二倍体细胞，肿瘤发生减少了。另外，在癌细胞中，染色体臂gain或loss的发生频率和染色体臂上的coding gene数目相反。从这个角度，异倍性也会抑制肿瘤发生。【分别通过什么实验验证？什么样的数据验证得到的？】\n  二、异倍性被genomic context影响 2.1 体细胞变异发生的顺序影响癌症的演化 在小鼠模型中，获得Ras和Tp53突变的顺序不同，得到的肿瘤表型不同。同样的，TET2突变和JAK2突变的发生顺序不同，也影响了人类骨髓瘤的表征（manifestation）。\n2.2 异倍性可能对其他基因组变异特别敏感 Recurrent aneuploidy模式和特定的调节异常通路有关，也和特定的驱动突变有关。比如：\n  在乳腺癌小鼠模型中，被诱导过表达Myc基因的肿瘤通常在第15号染色体上会得到额外的拷贝，被诱导Her2过表达的肿瘤经常会丢失在第4号染色体上的拷贝。\n  有时，异倍性会先发生，并支配点突变的获得。在超过90%的肾透明细胞癌病人中，第3号染色体臂的丢失是一个肿瘤形成的早期事件（通常由于染色体碎裂事件），在癌症被检测出来之前十年就存在了。剩下的染色体臂位点上发生肿瘤抑制基因的突变（VHL突变通常发生在该事件之后），导致癌症形成。\n  2.3 全基因组扩增和异倍性的关系 WGD几乎发生在1/3的人类癌症中，通常在肿瘤形成早期发生。WGD和异倍性水平上升有关，尤其是染色体丢失相关。二倍体细胞中的染色体丢失容忍度低，染色体丢失经常发生在四倍体细胞中，并促进肿瘤形成。\n2.4 细胞微环境决定异倍性演化 在不同的环境下，受到的选择压力不同。细胞系，器官，小鼠模型等等，在不同的培养形态中，得到的染色体丢失和扩增都不同。\n2.5 免疫系统管理异倍性耐受 免疫识别和异倍性的关系非常复杂，有研究表明，肿瘤异倍性和免疫逃逸的标志物相关，且和免疫治疗反应降低有关。但是也有研究表明 ，异倍性会激活免疫反应。这取决于肿瘤形成的阶段，以及肿瘤微环境中的免疫细胞环境。\n三、异倍性的预后作用 临床上，可以通过不同的技术手段来检测异倍性，包括SNP array，aCGH和DNA测序以及RNA测序技术。\n \n 3.1 异倍性水平高和差的预后有关   cellular DNA ploidy在转移乳腺癌中、早期子宫内膜癌、早期卵巢癌、前列腺癌、以及结直肠癌中是独立的预后标志物。\n  TCGA的数据表明，CNA burden在原发乳腺癌、子宫内膜癌、肾透明细胞癌、甲状腺癌和结直肠癌中和OS/PFS显著相关。\n  结直肠癌中，对超过7000的病人进行系统的meta分析，表明晚期肿瘤的异倍性比早期的更高，表明异倍性可能是stage的预测标志物。mata分析中超过一半的研究表明，异倍性对OS、disease-specific survival和recurrence-free survival有显著的预后能力（独立于tumor stage）。在研究中，diploidy甚至比MSI的预后能力更强。\n  在卵巢浆液性肿瘤中，高度的异倍性和更差的生存有关。在1期卵巢癌，多变量分析中，异倍性是最强的预测因子。\n  在肺癌中，CIN和高度的CNA burden和肺癌的癌前病变的进展有关，类似的，在食管癌中，更高程度的异倍性在Barrett oesophagus将会转变成食管癌的病人中出现。以及，异倍性可以结合其他的标志物来确定疾病进展成高度的异型增生或者癌症。\n  在前列腺癌中，异倍性和PSA（前列腺癌中的标志物） 的预后（RFS）有关。并且，含有异倍性细胞的前列腺肿瘤，被切除后更容易复发。\n  相反的，在多发性骨髓瘤中，高度的异倍性和好的预后有关。\n  高异倍性的肿瘤细胞对化疗通常敏感度低。\n  核型的异质性是由于CIN造成的，可能是CIN而不是异倍性造成了耐药性，另外，异倍性水平和耐药性水平并不是简单的线性关系，因为肿瘤细胞对核型的复杂性有一定的容忍度。另外，极端的异倍性水平和/或CIN也会似的细胞对药物更敏感（少数情况）。\n  3.2 异倍性预后作用中容易混淆的因素  stage/grade：  因为异倍性在肿瘤形成的晚期更遍布，因此表面上可能是异倍性和预后存在关系，实际上是晚期的癌症更容易存在更多的异倍性和更容易扩散。因此构建异倍性和预后关系的时候，应该排除诊断时间和增殖率的影响。\n CIN和aneuploidy  异倍性水平和高度的CIN相关。研究认为，染色体碎裂在癌症中是另外一种主要的异倍性，CIN，染色体碎裂，p53状态三者之间的关系有综述描述过。\n 肿瘤内异质性（ITH）  由于单细胞组学技术，近些年的研究很多。研究表明了肿瘤内异质性在肿瘤进展和治疗反应的重要性。组织ITH和肿瘤增殖率反映了基因层面的ITH， 研究发现，数量和结构上的CIN驱使ITH发展和维持的能力比点突变还强。另外，CNA的异质性（而不是点突变的异质性）和预后的关系很强。\n有研究发现，高CNA burden+低异质性的病人和更好的预后有关，虽然不是直接表明异倍性， 但是CNA burden指的是基因组上受到拷贝数影响的基因占比，很大程度受到异倍性影响。这个研究表明，探索异倍性和临床关系的时候，需要控制ITH的影响。\n四、异倍性靶点 Angelika Amon认为有两种情况\n  targeting the cellular consequences 【】induced by a high degree of aneuploidy (independently of CIN)\n  targeting the unique vulnerabilities induced by specific recurrent aneuploidies.\n  潜在的specific aneuploidy可以分成两种概念：\n  identifying and targeting drivers of recurrent aneuploidies，可能是特定的癌症基因\n  identifying genes linked to these drivers that do not contribute to, but are invariably associated with, the specific aneuploidy.\n  4.1 靶向aneuploidy状态 异倍性造成的细胞压力主要分成五个部分：\n  蛋白毒性的\n  代谢的\n  复制的\n  有丝分裂的\n  低渗的\n  这些细胞压力可能会导致许多(如果不是全部的话)高度非整倍体细胞所共有的独特脆弱性，而不管哪个染色体的拷贝数发生了改变。与这一观点一致的是，在哺乳动物细胞系中，不同的非整倍体被发现诱导类似的转录程序，这些细胞系被基因操纵以容纳非整倍体。\n4.2 特定aneuploidy靶向的passengers  haploinsufficient  在二倍体中丢失一个基因产生的表型。\n  在经常发生丢失的染色体上的haploinsufficient基因，大约27%～45%的重要基因是haploinsufficient基因。单染色体上发生的拷贝数丢失，导致细胞对抑制这些基因更敏感。比如：编码剪切子SF3B1的基因的一个拷贝通常在11%的人类肿瘤中发生丢失，大多数（81%）情况下都是因为染色体臂2q的丢失。乳腺和造血细胞系发生特殊的aneuploidy后，对SF3B1抑制剂更敏感。重要的是，预测这种类型的弱点在人类癌症中普遍存在。\n  相反的，过表达毒性也可以被靶向标定。很多基因过表达后，会降低细胞生存能力和增殖能力，癌症演化过程中拷贝数图谱会避免获得这类基因。当三倍体中存在剂量敏感的基因时，就需要使得他们的基因或表型沉默来让三倍体忍受或者正向选择（比如，通过启动子甲基化）。逆转这些失活机制(例如，通过去甲基化)将对抗特定三倍体所赋予的适应度优势。这将增加一种有趣的可能性，即一些剂量敏感的癌症基因可以通过抑制和激活来靶向。\n  乘客基因的纯合子删除提供了另外一种治疗机会。丢失常染色体或着常染色体臂的两个拷贝是非常罕见的，但是单染色体体能够让基因完整的失活，通过位点突变了，或者部分缺失。这种部分缺失可能和肿瘤形成不相关，但是会导致癌症细胞特异的合成致死。比如，MTAP基因删除在很多癌症中都是经常发生的，由于靠近肿瘤抑制基因CDKN2A，MTAP缺失的细胞积累了MTA（抑制蛋白质PRMT5甲基转移酶的活性），使得细胞对PRMT5抑制剂更敏感。\n  参考资料   [1]context is everything:aneuploidy in cancer.\n  [2]Pan-cancer analysis distinguishes transcriptional changes of aneuploidy from proliferation.\n ","date":"September 21, 2022","image":null,"permalink":"/post/2022-9-14_cnv2/","title":"【异倍性系列2】——异倍性（aneuploidy）"},{"categories":["癌症基因组学","生物学"],"contents":"介绍染色体不稳定性的机制。\n 一、 背景 非整倍体和CIN之间的界限是模糊的，因为没有工具可以区分非整倍体(描述细胞核型的一种状态)和CIN(染色体错分离率增加)。\n这种区别很重要，因为一种染色体倍数可以以不同的方式产生，单染色体通过CIN可能是最常见的非整倍性途径。\n二、造成CIN的因素 正确的染色体分离过程中，需要染色体在细胞周期的G2和M期保持内聚，然后在后期开始时突然中断。\n2.0 有丝分裂中的染色体分离 有丝分裂是经过精心设计的，为了确保所有的姐妹染色单体分裂到不同的子细胞中，其中姐妹染色单体的cohesion是关键，它存在于DNA复制时，是通过the deposition of the cohesion complex建立的，在细胞周期的G2和M期保持，在后期开始时突然中断。精准的时间控制是通过周期蛋白依赖性激酶和SAC（spindle assembly checkpoint）的协同活动决定的。\n cohesion\n  SAC\n 染色体不合时宜地附着到纺锤体微管时，发出维持周期蛋白依赖性激酶活性的信号，会抑制后期的开始并阻止姐妹染色单体cohesion，比如，单向染色体没有附着到单个着丝粒上会出发等待后期的信号，而且，一个单个的没有附着的着丝粒足以阻止后期的发生。一旦所有的染色体都附着到正确的两个方向的着丝粒上，SAC满足条件，姐妹单色单体会突然分离，同时通过细胞周期机器诱导所有的染色体水解性地分裂复合体内聚物，最终，人类细胞的每个着丝粒平均附着了大约20个微管，每个微管都朝向同样的spindle pole来支持公正的染色体分割。但是着丝点-微管连接的随机性质导致了频繁的错误连接，其中单个着丝点同时与来自主轴两端的微管相结合——称为“嵌合”（merotely）。这种嵌合附着通常发生在早期有丝分裂中，并且不被SAC感知，会造成姐妹染色单体在后期迁移到一个spindle pole，造成染色体错误分离。\n 着丝点-微管连接类型\n 和CIN有关的蛋白质：https://www.cell.com/action/showFullTableHTML?isHtml=true\u0026amp;tableId=tbl1\u0026amp;pii=S0960-9822(10)00076-X\n2.1 Cohesion defects 参与染色体cohesion的蛋白质是通过测量出芽酵母中的the efficiency of transmission of minichromosomes来确定的。研究发现，出芽酵母中诱导CIN产生的基因（基因产物调控姐妹染色单体cohesion，包括cohesion complex的subunits）突变，在人类肿瘤中存在。不过没有直接的研究检验这种突变如何影响染色体cohesion。所以，还不知道细胞是倾向于姐妹染色单体过早分离或在后期开始时染色体分离失败，从而无法评估它们在CIN中的作用。另外，然而，利用RNA干扰，cohesion或cohesion调控因子Sgo1/分离酶的急性严重耗散会增加四倍体细胞的数量。四倍体细胞也会发生在过表达分离酶或不耗散形式的securin（分离酶抑制蛋白：切割cohesion激活分裂后期），这表明，cohesion的失调趋向于造成染色体分离全局性的影响，而不是增加单个染色体分离的错误发生。另外，可能cohesion subunit的显性突变通过阻止及时的染色体分离来增加染色体错误分离率，这一点和细胞融合实验中CIN的主要行为吻合。另一种值得探讨的观点是cohesion subunit的突变是否破坏了着丝粒染色质的有序排列，从而导致姐妹着丝粒典型的背对背定向的破坏。除了这些特定的突变，还有其他迹象表明 cohesion的破坏可能导致CIN。比如，例如，与正常组织对照相比，乳腺癌肿瘤样本中分离酶水平较高，过多的分离酶可引起姐妹染色单体过早分离，导致染色体错分离。然而，由于肿瘤和正常组织有丝分裂指数的差异，对肿瘤中mRNA水平改变的解释尚不清楚。这种差异是普遍存在的，并且适用于比较正常组织和肿瘤组织的许多其他领域。\n cohesion complex and cohesion subunit\n 2.2 SAC defects 2.3 Supernumerary centrosomes 2.4 Defect in Kinetochore-microtubule attachment dynamics 2.5 Defect in cell-cycle regulation 三、CIN作为靶点 四、CIN的检测方式 五、细胞能够耐受多少CIN https://aacrjournals.org/cancerres/article/78/23/6529/543014/Tolerance-of-Chromosomal-Instability-in-Cancer\n六、CIN和肿瘤免疫、炎症、转移之间的关系 染色体不稳定性的程度和部位决定了其致癌潜能https://www.nature.com/articles/s41467-020-15279-9\n七、CIN的作用 CIN和异倍性在肿瘤形成的过程中的作用还不清楚。小鼠模型中显示，CIN会偶然展示出散点的、继承性的长期潜伏的状态，主要是肺和脾脏中国，这表明CIN不是一个潜在的癌症驱动因素。在倾向性获得癌症的小鼠中，CIN在不同的情况下，能够促进肿瘤形成，或抑制肿瘤形成。\n异倍性虽然是CIN造成的，但是异倍性也会诱导CIN，实验发现，多一条染色体的细胞通常会产生更多的扩增或缺失。[The presence of extra chromosomes leads to genomic instability]此外，这些细胞表现出CIN的原因和/或特征，如(超细)后期桥，微核，染色体错误分离和胞质分裂失败。CIN通常会造成异倍性，因为CIN总是导致结构或数目异常。\n有丝分裂由数个关键蛋白严格调控的过程，但是也会发生错误，比如由于有丝分裂调控因子发生突变的情况下，一些有丝分裂错误会造成异倍性。例如，纺锤体微管在染色体上的错误附着导致染色体的错误分离，导致数量非整倍体。另外，来自相反方向/子细胞的多个纺锤体微管的附着可以有效地“撕裂”一条染色体，导致两个子细胞获得或失去染色体的一部分，导致结构非整倍体。非整倍体在有丝分裂过程中变得明显，它可能是由有丝分裂之前的过程引起的，例如DNA损伤或复制应激，还有很多缺陷被认为是癌症CIN的基础，比如有丝分裂检查点错误，lagging 染色体（Whole chromosome instability and cancer: a complex relationship），anaphase bridges，mono-multipolar spindles，cytokinesis failure，telomere dysfunction，replication stress，DNA damage等等。然而，需要注意的一点是，从患者肿瘤中确定CIN的机制是非常困难的。此外，许多研究集中于来自不同肿瘤组的细胞系，而CIN机制可能因肿瘤类型和潜在患者而不同(作者未发表的观察结果)。此外，最近的研究发现，染色体错分离在非转化细胞中具有非随机模式，一些染色体的错分离明显高于其他染色体。[Non-random mis-segregation of human chromosomes]常见脆弱位点(Common vulnerable Sites, CFSs)是已知的当细胞经历复制应激时，染色体内更容易破裂的位点，导致结构非整倍体[Genomic instability in fragile sites—still adding the pieces]，这些研究表明，不管是数量还是结构异倍性，都可能发生在非随机的基因组位点，因此，有可能由于染色体不稳定机制不同，在不同类型的癌症中这种模式是不同的。\n除了细胞核的染色体改变外，CIN还能促进异常细胞结构的获得，如微核。微核是含有少量遗传物质的小核结构。这种遗传物质可以是染色体分离时滞后的单个染色体，也可以是DNA损伤[Cell biology: the micronucleus gets its big break]造成的破碎DNA片段。微核含有较少的DNA修复和复制机制，往往容易破裂，增加了染色体异常的进一步积累[Chromothripsis from DNA damage in micronuclei]。它们还可以激活先天免疫系统，因为DNA释放到细胞质中。\n CIN can only be measured in living cells  作用总结   CIN在不同的情况下，能够促进肿瘤形成，或抑制肿瘤形成\n  异倍性虽然是CIN造成的，但是异倍性也会诱导CIN\n  CIN还能促进异常细胞结构的获得\n  CIN率可能比单独评估非整倍体率更能预测肿瘤结局\n  参考文献   [1] Mechanisms of Chromosomal Instability\n  [2]Sister Chromatid Cohesion Control and Aneuploidy\n  [3]Sister chromatid cohesion and separation\n ","date":"September 21, 2022","image":null,"permalink":"/post/2022-9-14_cnv3/","title":"【异倍性系列3】——chromosome instability 染色体不稳定性 (CIN)"},{"categories":["shell"],"contents":"拷贝数变异内容汇。\n【CNV系列1】——易混淆概念\n参考资料  linux下面ftp/wget命令下载文件夹目录 ","date":"September 21, 2022","image":null,"permalink":"/post/2022-9-14_cnvcombine/","title":"拷贝数变异内容汇总"},{"categories":["shell"],"contents":"介绍如何下载GSA数据库需要申请的数据。\n前言 在GSA数据库中，部分数据是需要申请的，注意：必须是PI进行数据申请，否则就算提交了也会被拒绝。\n数据申请成功后，按照下面的步骤进行下载即可。\n \n 下载  FileZilla  根据NGDC的官方文档，可以使用FileZilla，主机：human.big.ac.cn，用户名和密码，忽略端口，点击“快速连接”即可下载数据。但是FileZilla只限于从GSA下载数据到本地，不支持两个服务器传输数据。\nftp命令行  在命令行中，可以访问ftp服务器，再使用mget *来对目录下所有的文件进行下载，但是ftp命令行不支持下载文件夹。\nwget  使用wget来下载HRA000873目录下所有的文件（包含文件夹），\nwget -r -nH -P/ ftp://human.big.ac.cn/HRA000873/* --ftp-user=xxx --ftp-password=xxx   星号*必须有\n  -r 下载文件夹\n  -nH 不包含主机文件夹\n  -P 下载到指定目录，此处我已在该目录下/\n  参考资料   NGDC人类遗传资源组学原始数据归档库 数据申请及下载说明\n  linux下面ftp/wget命令下载文件夹目录\n ","date":"September 14, 2022","image":null,"permalink":"/post/2022-9-14_gsa%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD/","title":"GSA申请数据下载"},{"categories":["shell"],"contents":" recurrence-free survival  从开始治疗到没有癌症迹象存在。\n disease-specific survival  从检测或开始治疗到病人死亡之前的时间。\n","date":"September 14, 2022","image":null,"permalink":"/post/2022-9-14_%E4%B8%B4%E5%BA%8A%E4%BF%A1%E6%81%AF%E5%90%8D%E8%AF%8D/","title":"【临床系列】——名词解释"},{"categories":["shell"],"contents":"介绍R语言中的因子。\n源于Huang昨天问我的这个问题。\n \n 以及，大家在做图的时候应该也遇到一类问题，对横纵坐标的变量进行排序，以及排序并不是按照1，5，10，而是按照1，10，5这样的顺序排列时，需要人为设置因子从而改变阿拉伯数字的顺序。\n一. 什么是因子 在R中，因子适用于分类变量，变量具有已知的值。当需要对变量进行非字母顺序现实的时候，因子可以发挥作用。\n二、使用因子 forcats包是tidyverse包中的一部分。直接加载tidyverse包来使用。\n假设有一个变量记录了月份:\nx1 \u0026lt;- c(\u0026#34;Dec\u0026#34;, \u0026#34;Apr\u0026#34;, \u0026#34;Jan\u0026#34;, \u0026#34;Mar\u0026#34;) 使用字符串来记录这个变量存在两个问题：\n 只有12个可能的月份，如果拼写错误无法检查。  x2 \u0026lt;- c(\u0026#34;Dec\u0026#34;, \u0026#34;Apr\u0026#34;, \u0026#34;Jam\u0026#34;, \u0026#34;Mar\u0026#34;) 使用sort排序则只能按照首字母顺序，而不是月份的顺序。  这两个问题都可以通过因子来解决，为了创建因子，必须创建一个列表存储有效的级别：\nmonth_levels \u0026lt;- c(  \u0026#34;Jan\u0026#34;, \u0026#34;Feb\u0026#34;, \u0026#34;Mar\u0026#34;, \u0026#34;Apr\u0026#34;, \u0026#34;May\u0026#34;, \u0026#34;Jun\u0026#34;,  \u0026#34;Jul\u0026#34;, \u0026#34;Aug\u0026#34;, \u0026#34;Sep\u0026#34;, \u0026#34;Oct\u0026#34;, \u0026#34;Nov\u0026#34;, \u0026#34;Dec\u0026#34; ) 这样就可以创建因子了：\ny1 \u0026lt;- factor(x1, levels = month_levels) y1 #\u0026gt; [1] Dec Apr Jan Mar #\u0026gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec sort(y1) #\u0026gt; [1] Jan Mar Apr Dec #\u0026gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 任何不在这个集合中的值都会被转换为NA。\ny2 \u0026lt;- factor(x2, levels = month_levels) y2 #\u0026gt; [1] Dec Apr \u0026lt;NA\u0026gt; Mar  #\u0026gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 如果想增加一个警告，可以使用readr::parse_factor()\ny2 \u0026lt;- parse_factor(x2, levels = month_levels) #\u0026gt; Warning: 1 parsing failure. #\u0026gt; row col expected actual #\u0026gt; 3 -- value in level set Jam 如果省略了级别（levels），就默认按照字母顺序。\nfactor(x1) #\u0026gt; [1] Dec Apr Jan Mar #\u0026gt; Levels: Apr Dec Jan Mar 有时候，希望级别的顺序与数据中首次出现的顺序相匹配，可以使用unique或fct_inorder（首次出现的顺序）。\nf1 \u0026lt;- factor(x1, levels = unique(x1)) f1 #\u0026gt; [1] Dec Apr Jan Mar #\u0026gt; Levels: Dec Apr Jan Mar  f2 \u0026lt;- x1 %\u0026gt;% factor() %\u0026gt;% fct_inorder() f2 #\u0026gt; [1] Dec Apr Jan Mar #\u0026gt; Levels: Dec Apr Jan Mar 在可视化过程中，改变因子的级别很有用，举个例子，假设想要研究不同的宗教，每天平均看电视的时间：\nrelig_summary \u0026lt;- gss_cat %\u0026gt;%  group_by(relig) %\u0026gt;%  summarise(  age = mean(age, na.rm = TRUE),  tvhours = mean(tvhours, na.rm = TRUE),  n = n()  ) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument)  ggplot(relig_summary, aes(tvhours, relig)) + geom_point()   \n 现在想根据relig的层次来排序，可以使用fct_reorder()，fcr_reorder()有三个参数：\n  f，更改的levels\n  x，用来排列levels的数值向量\n  fun，如果x含有多个数值，可以对数值进行处理，默认是median\n  ggplot(relig_summary, aes(tvhours, fct_reorder(relig, tvhours))) +  geom_point()   \n 另外还可以对收入和年龄进行统计，\nrincome_summary \u0026lt;- gss_cat %\u0026gt;%  group_by(rincome) %\u0026gt;%  summarise(  age = mean(age, na.rm = TRUE),  tvhours = mean(tvhours, na.rm = TRUE),  n = n()  ) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument)  ggplot(rincome_summary, aes(age, fct_reorder(rincome, age))) + geom_point()   \n 可以使用fct_relevel()，将非金额的放在最后。\nggplot(rincome_summary, aes(age, fct_relevel(rincome, \u0026#34;Not applicable\u0026#34;))) +  geom_point() 因子的另外一个应用场景是颜色，fct_reorder2把因子根据最大的x数值，把y轴数值进行重排。\nby_age \u0026lt;- gss_cat %\u0026gt;%  filter(!is.na(age)) %\u0026gt;%  count(age, marital) %\u0026gt;%  group_by(age) %\u0026gt;%  mutate(prop = n / sum(n))  ggplot(by_age, aes(age, prop, colour = marital)) +  geom_line(na.rm = TRUE)  ggplot(by_age, aes(age, prop, colour = fct_reorder2(marital, age, prop))) +  geom_line() +  labs(colour = \u0026#34;marital\u0026#34;) 如果是条形图，可以使用fct_infreq递增排列：\ngss_cat %\u0026gt;%  mutate(marital = marital %\u0026gt;% fct_infreq() %\u0026gt;% fct_rev()) %\u0026gt;%  ggplot(aes(marital)) +  geom_bar()   \n 修改因子级别 最有效的改变级别的顺序的方法是直接更改数值。可以使用fcr_recode()来处理，\ngss_cat %\u0026gt;%  mutate(partyid = fct_recode(partyid,  \u0026#34;Republican, strong\u0026#34; = \u0026#34;Strong republican\u0026#34;,  \u0026#34;Republican, weak\u0026#34; = \u0026#34;Not str republican\u0026#34;,  \u0026#34;Independent, near rep\u0026#34; = \u0026#34;Ind,near rep\u0026#34;,  \u0026#34;Independent, near dem\u0026#34; = \u0026#34;Ind,near dem\u0026#34;,  \u0026#34;Democrat, weak\u0026#34; = \u0026#34;Not str democrat\u0026#34;,  \u0026#34;Democrat, strong\u0026#34; = \u0026#34;Strong democrat\u0026#34;  )) %\u0026gt;%  count(partyid) #\u0026gt; # A tibble: 10 x 2 #\u0026gt; partyid n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 No answer 154 #\u0026gt; 2 Don\u0026#39;t know 1 #\u0026gt; 3 Other party 393 #\u0026gt; 4 Republican, strong 2314 #\u0026gt; 5 Republican, weak 3032 #\u0026gt; 6 Independent, near rep 1791 #\u0026gt; # … with 4 more rows 另外，如果想要整合更多的级别，可以使用fcr_collapse，\ngss_cat %\u0026gt;%  mutate(partyid = fct_collapse(partyid,  other = c(\u0026#34;No answer\u0026#34;, \u0026#34;Don\u0026#39;t know\u0026#34;, \u0026#34;Other party\u0026#34;),  rep = c(\u0026#34;Strong republican\u0026#34;, \u0026#34;Not str republican\u0026#34;),  ind = c(\u0026#34;Ind,near rep\u0026#34;, \u0026#34;Independent\u0026#34;, \u0026#34;Ind,near dem\u0026#34;),  dem = c(\u0026#34;Not str democrat\u0026#34;, \u0026#34;Strong democrat\u0026#34;)  )) %\u0026gt;%  count(partyid) #\u0026gt; # A tibble: 4 x 2 #\u0026gt; partyid n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 other 548 #\u0026gt; 2 rep 5346 #\u0026gt; 3 ind 8409 #\u0026gt; 4 dem 7180 扩展 扩展阅读：\nIf you want to learn more about factors, I recommend reading Amelia McNamara and Nicholas Horton’s paper, Wrangling categorical data in R. This paper lays out some of the history discussed in stringsAsFactors: An unauthorized biography and stringsAsFactors = , and compares the tidy approaches to categorical data outlined in this book with base R methods. An early version of the paper help motivate and scope the forcats package; thanks Amelia \u0026amp; Nick!\n参考  R for Data Science ","date":"September 8, 2022","image":null,"permalink":"/post/2022-8-31_factor/","title":"R——因子"},{"categories":["shell"],"contents":"介绍混淆矩阵，准确率，召回率，ROC曲线以及AUC面积。\n混淆矩阵 注意一点，混淆矩阵是有顺序的，不能随意变换横纵的顺序。\n 混淆矩阵\n 根据混淆矩阵能够得出以下数值：\n 准确率（Precision）  $$ \\frac{TP}{TP+FP} $$\n正确预测为阳性的样本数/所有预测为阳性的样本数\n 召回率（Recall）  $$ \\frac{TP}{TP+TN} $$\n正确预测为阳性的样本数/所有正确预测的样本数\n准确率和召回率通常是不能同时满足的，提升一个就会损失另外一个。\n 真阳性率（True Positive Rate）又叫敏感性  $$ \\frac{TP}{TP+FN} $$\n正确预测为阳性的样本数/所有真正阳性的样本数\n 假阳性率（False Positive Rate）又叫特异性  $$ \\frac{FP}{FP+TN} $$\n错误预测为阳性的样本数/所有真正阴性的样本数\nROC曲线 ROC（Reveiver operating characteristic curve）以图片的形式，展示在分类阈值下分类模型的性能，包含两个参数：\n  真阳性率（TPR）\n  假阳性率（FPR）\n  ROC曲线绘制的是：每个分类阈值下，TPR比上FRR的值。分类的阈值越低，越多的样本被分类成阳性，假阳性和真阳性率都会增加。\n ROC曲线\n 假设分类模型使用的是逻辑回归，可以不同的分类阈值下，计算ROC曲线的点，多次评估模型，但是这样很低效。更高效的方式可以使用AUC，这是一种基于排序的算法。\nAUC曲线 AUC（Area under the ROC Curve），AUC计算从（0,0）到（1,1）ROC曲线下面积。\n AUC曲线下面积\n AUC对所有的可能的分类阈值进行总体性能度量，AUC是模型对随机阳性的排名高于随机阴性的概率。举个例子：按照逻辑回归预测数值把样本从左到右升序排列。\n 预测结果按照逻辑回归得分的升序排列\n 可以这样理解AUC：假设随机挑选阳性(绿色)和阴性(红色)的样本，我的模型有多大的概率把他们正确进行排序。AUC的取值范围是0到1，预测模型100%正确时AUC为1，预测模型100%错误时AUC为0。\nAUC的优点\n  AUC是尺度不变的，计算预测排序的好坏，而不是绝对的数值。\n  AUC是分类阈值不变的，计算模型的预测质量而不是分类模型阈值的选择。\n  pROC中如何计算auc 晚上的时候debug了一下，好奇pROC是如何计算AUC的。大概分为以下几个步骤：\n  根据分类的数值，设定阈值的个数和数值。\n  对样本进行排序。\n  计算每个样本数值点的真阳性率和假阳性率。\n  具体步骤如下：\n 不同的阈值根据predictor来决定，predictor就是每个样本的数值，response是good/bad分类标签。注意direction：auto（选择方向，即：大于阈值为阳性还是阴性）。  这里有113个样本，阈值选择了51个。\n unique.candidates \u0026lt;- sort(unique(predictor))  thresholds1 \u0026lt;- (c(-Inf, unique.candidates) + c(unique.candidates,  +Inf))/2  thresholds2 \u0026lt;- (c(-Inf, unique.candidates)/2 + c(unique.candidates,  +Inf)/2)  thresholds \u0026lt;- ifelse(abs(thresholds1) \u0026gt; 1e+100, thresholds2,  thresholds1) split对数据进行分组，good在一组，bad在一组。\nsplitted \u0026lt;- split(predictor, response) 在direction是auto的情况下，control默认是levels[1]，这里levels[1]是good。\nlevels [1] \u0026#34;Good\u0026#34; \u0026#34;Poor\u0026#34;  然后做了排序，按照降序来排列   predictor.order \u0026lt;- order(predictor, decreasing = decr)  predictor.sorted \u0026lt;- predictor[predictor.order]  response.sorted \u0026lt;- response[predictor.order] 排序，分数从大到小，predictor.order给出数值所在的位置，predictor.sorted给出排过序的数值，response.sorted给出排序数值对应的response的排序。\n计算出每个点的TP（response为阳性的累加）和FP（response为阴性的累加），se和sp，se是tp/ncase（ncase是所有的真阳性病人的个数），sp是control的数目-fp（所有的阴性样本减得到真正阴性的个数就是假阳性的样本）/control的数目(control是所有的阴性样本)，\nTP 1 2 3 4 5 6 7 8 9 10 11 12 12 12 13 13 14 14 14 14 14 15 16 16 17 17 18 18 18 19 19 20 21 21 22 23 24 ... se  [1] 0.02439024 0.04878049 0.07317073 0.09756098 0.12195122 0.14634146 0.17073171 0.19512195 0.21951220 0.24390244 ... table(response) response  0 1 72 41 dups.pred返回逻辑值，数值排序，从小到大检查和前一个数值是否一致，结果调换顺序。 dups.sesp返回每个位置上，se重复为TRUE且sp重复为TRUE的逻辑值，如果存在都是TRUE的，返回TRUE dups选择数值重复或者真阳性且假阳性都存在的\ndups.pred \u0026lt;- rev(duplicated(rev(predictor.sorted)))  dups.sesp \u0026lt;- duplicated(se) \u0026amp; duplicated(sp)  dups \u0026lt;- dups.pred | dups.sesp 检查：sum(!dups)（数值不重复的）是否等于length(thresholds) - 1（总的阈值数目-1），如果出现这种情况就是错误，立刻停止。\nse[!dups]选择数值不重复的或非真阳性且假阳性都存在的情况，\n if (direction == \u0026#34;\u0026lt;\u0026#34;) {  se \u0026lt;- rev(c(0, se[!dups]))  sp \u0026lt;- rev(c(1, sp[!dups]))  }  else {  se \u0026lt;- c(0, se[!dups])  sp \u0026lt;- c(1, sp[!dups])  }  计算auc  diffs.x \u0026lt;- sp[-1] - sp[-length(sp)] # 特异性就是假阳性率是纵坐标 means.vert \u0026lt;- (se[-1] + se[-length(se)])/2 # 敏感性就是真阳性率，是横坐标 auc \u0026lt;- sum(means.vert * diffs.x) # 将图形分块计算每个区间梯形面积（不对曲线进行平滑的基础上）   AUC曲线下面积\n AUC中的bias范围\n参考资料  Classification: ROC Curve and AUC ","date":"August 23, 2022","image":null,"permalink":"/post/2022-8-31_auc/","title":"AUC"},{"categories":["shell"],"contents":"介绍rCGH包的使用方法。\n一. rCGH介绍 rCGH是针对aCGH分析的流程，rCGH通过保存所有参数，确保了完全的可追溯性，并通过交互式可视化方便基因组图谱的解释和决策。rCGH支持以下商业芯片：\n  Agilent（从44K到400K的芯片）\n  Affymetrix SNP 6.0\n  cytoScanHD\n  custom芯片也支持（需要提供合适的数据格式）\n  aCGH数据也能够获取LOH的信息，如何分析通过分析或者其他的方式得到这个标签？\n二、使用流程 cgh \u0026lt;- readAffyCytoScan(\u0026#34;path/to/cytoScan.CNCHP.txt\u0026#34;) cgh \u0026lt;- adjustSignal(cgh) cgh \u0026lt;- segmentCGH(cgh) cgh \u0026lt;- EMnormalize(cgh) 主要的函数介绍，其他的函数介绍在安装好R包后，在R环境中使用 ?function 可获得具体的使用方法。\n 会议安排 ","date":"August 22, 2022","image":null,"permalink":"/post/2022-8-22_rcgh/","title":"rCGH包"},{"categories":["shell"],"contents":"介绍聚类的含义，聚类能够解决的问题，以及聚类性能的度量。\n一. 聚类是什么 聚类属于无监督学习。聚类过程能够形成多个类，每个类对应的概念语义需要使用者来解释。\n二. 性能度量 聚类重要的两个问题：\n  确定聚类的个数\n  聚类结果稳定\n  对于聚类的结果，需要使用某种性能度量来评估好坏，另一方面，如果明确了最终要使用的性能度量，可以直接讲其作为聚类过程的优化目标，从而得到符合要求的聚类结果。\n聚类的结果应该满足：\n  类别之间相似度高（intra-cluster similarity）\n  类别之间相似度低（inter-cluster similarity）\n  聚类性能的度量大致有两类：\n  将聚类结果与某个“参考模型”进行比较，称为“外部指标”（external index）\n  直接考察聚类结果，不利用任何参考模型，称为“内部指标”（internal index）\n  2.1 外部指标 2.1.1 Jaccarad系数（Jaccarad Coefficient, JC）\n2.1.2 FM指数（Fowlkes and Mallows Index, FMI）\n2.1.3 Rand指数（Rand Index, RI）\n2.2 内部指标 2.2.1 DB指数\n2.2.2 Dunn指数\n来源  会议安排 ","date":"June 21, 2022","image":null,"permalink":"/post/2022-8-10_%E8%81%9A%E7%B1%BB/","title":"【聚类1】——介绍"},{"categories":["shell"],"contents":"介绍kmeans分类。\n一. 聚类是什么 聚类属于无监督学习。聚类过程能够形成多个类，每个类对应的概念语义需要使用者来解释。\n二. 性能度量 聚类重要的两个问题：\n  确定聚类的个数\n  聚类结果稳定\n  对于聚类的结果，需要使用某种性能度量来评估好坏，另一方面，如果明确了最终要使用的性能度量，可以直接讲其作为聚类过程的优化目标，从而得到符合要求的聚类结果。\n聚类的结果应该满足：\n  类别之间相似度高（intra-cluster similarity）\n  类别之间相似度低（inter-cluster similarity）\n  聚类性能的度量大致有两类：\n  将聚类结果与某个“参考模型”进行比较，称为“外部指标”（external index）\n  直接考察聚类结果，不利用任何参考模型，称为“内部指标”（internal index）\n  2.1 外部指标 2.1.1 Jaccarad系数（Jaccarad Coefficient, JC）\n2.1.2 FM指数（Fowlkes and Mallows Index, FMI）\n2.1.3 Rand指数（Rand Index, RI）\n2.2 内部指标 2.2.1 DB指数\n2.2.2 Dunn指数\n来源  会议安排 ","date":"June 20, 2022","image":null,"permalink":"/post/2022-8-10_%E8%81%9A%E7%B1%BB-copy/","title":"【聚类2】——kmeans聚类"},{"categories":["shell"],"contents":"该部分会议内容如下：\n  一、Teresa Przytycka 突变模式可以作为一种工具来研究环境、细胞过程和疾病之间的关联，其中包含：\n  signature和分子通路之间的关联\n  突变过程和突变过程之间的关联\n  1. 突变过程和分子通路/突变过程的关联 研究的问题是吸烟和COVID-19易感。\n这部分暂时不是很感兴趣，有空再听一听补上笔记。\n2. 突变过程的可加性问题 存在两种形式的过程：\n  可加性的突变过程，单独的过程对应单个的signature。\n  非可加性的突变过程，产生的signature取决于主要的突变过程。\n  比如，在cosmic中，我们有至少7个signature和DNA错配修复有关，SBS14和SBS20都和错配修复有关，但是SBS14和错配修复+缺陷有关，SBS20和错配修复+D缺陷有关。（D Wojtowics st al., Cell System 2021）\n  为了进一步研究这个问题，该研究人员通过非可加性的模型来推测signature，建立DNA损伤和修复缺陷之间的关联。作者开发了一个工具：RepairSig，用来模拟主要和次要的突变过程。该算法包含三个功能：\n  可以模拟可加性的初级突变过程\n  模拟与主要过程相互作用的非可加性的次要过程\n  推断突变的机会，也就是基因组中容易被破坏或优先修复的位置的分布。（这里存在两个问题，一个是如何确定signature存在的位置，一个是如何推断优先级）\n  使用到的数学逻辑：\n 高阶张量代数，用到了tensorflow。  研究逻辑：\n  先针对模拟数据测试算法是否能够复原正确的分解结果\n  将算法应用在癌症数据中，并且发现通过该算法得到的dMMR signature和实验的结果更一致\n  研究者在乳腺癌中发现（D Wojtowicz et al., Cell System 2021）一个代表了DNA错配修复缺陷过程的次要突变过程。\n  以下是RepairSig的流程：\n  这里面的2个基因区域指的是？以下来自原文：\n  2.1 RepairSig基于的理论背景  NMF分解得到的signature理论上代表不同的突变过程，但是实际上存在多个signature对应一种突变过程的情况，这其中涉及到非单一的突变过程，该问题并未解决。  举例：COSMIC中，有至少8个不同的signature对应错配修复缺陷过程。\n   目前的假设：在基因组内，突变机会有所不同，但是这些突变在不同的癌症基因组中是相同的。不同的基因组中，突变机会也是不同的，因为存在DNA压力，双链断裂等等其他内源性的癌症过程。【不是特理解这部分假设，找个文献看看】\n  我的理解  通过常规的NMF方法可以分离出以下两种signature：    单独的过程\n  单独过程和其他过程的叠加发生过程\n  因此，目前的算法基础上，将叠加过程单独讨论即可。\n叠加过程也是一种重要的过程，具有其发生特殊性。  来源   会议安排\n  会议内容\n  会议公开视频\n  文献：\n  ","date":"June 9, 2022","image":null,"permalink":"/post/2022-6-10_analytical/","title":"【2021NCI】signature讲座"},{"categories":["shell"],"contents":"该部分会议内容如下：\n  来源   会议安排\n  会议内容\n  会议公开视频\n  ","date":"June 9, 2022","image":null,"permalink":"/post/2022-6-10_normal_tumor/","title":"【2021NCI】signature讲座"},{"categories":["shell"],"contents":"该部分会议内容如下：\n  【Steven Rozen】 Two signatures: one important for public health, one important for DNA damage and repair\n一、AA和肝癌发生 1. 背景 AA指的是aristolochic acid，存在于天然的植物中，广泛应用于中药中。在2013年在尿路上皮癌(upper tract urothelial carcinomas)病人中发现AA 突变模式，2016年发现多种其他的癌症类型中也存在。\n2. 目前研究 目前已经有很多证据证明AA和肝癌发生之间的因果/关联。\n3. 科学问题   AA暴露和肝癌发生之间的剂量关系是什么？是否和肝炎存在相关性？\n  病人发生的暴露是什么形式的暴露？哪一种类型的草本植物？如何准备的？\n  在非洲和拉丁美洲发生了什么样的暴露？\n  通过什么样的途径去进行教育和调控\n  是否存在非侵入性的检测方法（比如血液检测），来检测AA暴露？\n  通过检测可以进行二次预防，已经暴露的个体可以通过检测得知。\n  二、DNA损伤和修复 A hotspot mutation in toploisomerase II alpha (TOP2A) that causes a mutator phenotype in human cancer.\n   topoisomerases切除和重新连接DNA链，使得它们解开或者让他们的超螺旋双链解开。 在yeast topoisomerases II基因上发生的一个突变会造成2-4个碱基的复制，比如：  CGATAC ——C GATAGATA G ACATG——ACATCATG\nCATG——CATATG\n这个研究发现这个过程产生的变异和ID17的模式匹配。ID17的模式中包含以上三种形式的突变。\n  在4个胃癌病人中存在，以及另外3个肿瘤病人中存在，这7个病人的突变情况存在一致性：\n TOP2A p.K743N 4个胃癌病人存在K743N K743N突变和signature ID17存在强烈的相关性（p\u0026lt;10-14）    但是除了ID17的复制，K743N的肿瘤还存在没有在ID17中存在的删除事件。\n  发现这种删除事件和ID8的图谱一致，ID8是一个比较常见的，则产生一个科学问题：\n 是否造成K743N的删除的过程，也同样造成了ID8的产生，又或者是这些删除导致了K743N的突变。  研究发现：\n  存在K743N突变的肿瘤患者和主要是ID8的肿瘤患者存在不同的删除大小分布，通过比较，结论是：在K743突变的肿瘤患者中，2-4个碱基对删除事件更加常见。\n  在更大范围的删除事件中，K743N突变病人和ID8肿瘤病人有不同的删除大小分布，\n    以上这些大小分布的差异表明，很多或大多数的K743N肿瘤中的删除事件是由于K743N突变造成的，而不是ID8变异过程造成的。\n酵母和体外实验表明，在TOP2突变酵母中发现复制的signature，复制的原因是TOP2突变后则不能够重新连接裂口。细胞存在不同的方法去补救这种情况，\n  作者推测由于人类TOP2A K743N突变产生的复制，和酵母TOP2突变产生的复制，两者是来自于一样的过程。\n  作者发现两个序列的motif在K743N肿瘤患者中和复制以及删除有关，并且发现K743N突变的病人中存在的motif在ID8主导的病人中不存在，也印证了该K743N突变和ID8过程不同。\n 作者进一步研究了K743N突变和oncogen的关系。\n 作者的另外一些总结：\n 【Allan Balmain】 The impact of carcinogens, obesity, and chronic inflammatory processes on mutational signatures and cancer risk in mouse tumor models\n这部分没有特别关注，主要是做肿瘤病因学，做了很多小鼠实验，也研究了一些关于拷贝数变异的结果。一个概念：很多已知的致癌基因（carcinogene）不是诱变因素。\n讨论部分  听完全部再回头思考这些问题。\ndata mining 数据挖掘\nPanel discussion 专题讨论会\n 来源   会议安排\n  会议内容\n  会议公开视频\n  ","date":"June 9, 2022","image":null,"permalink":"/post/2022-6-10_process/","title":"【2021NCI】signature讲座"},{"categories":["shell"],"contents":"该部分会议内容如下：\n  来源   会议安排\n  会议内容\n  会议公开视频\n  ","date":"June 9, 2022","image":null,"permalink":"/post/2022-6-10_translational/","title":"【2021NCI】signature讲座"},{"categories":["shell"],"contents":"该部分会议内容如下：\n  somatic mutations in ageing and disease 1. 背景 对良性组织测序（non-malignant tissue）比较困难，这里使用的是laser capture microdissection，把组织切得更小，这样每次测序大概是200个样本，不需要任何预先对DNA进行扩增，这样可以获得很高质量的基因组。\n主要介绍的是正常组织中的突变模式，以肝脏作为例子进行讲解。\n2. 目前研究 3. 科学问题 来源   会议安排\n  会议内容\n  会议公开视频\n  ","date":"June 9, 2022","image":null,"permalink":"/post/2022-6-10_open_session/","title":"【2021NCI】signature讲座-Opening Session"},{"categories":["shell"],"contents":"很多实际问题可以归结为线性规划问题，其目标函数和约束条件都是自变量的一次函数。但是存在另外一些应用也很广泛的问题，目标函数和（或）约束条件很难用线性函数表达，如果目标函数或约束条件中含有非线性函数，就称这种规划问题为非线性规划问题。\n由于非线性函数的复杂性，解非线性规划问题要比解线性规划问题困难得多，而且也不能像线性规划有通用解法，目前还没有适用于解决各种问题的一般算法，各个方法都有自己特定的适用范围。\n一、基本概念 目标函数，或约束条件中含有非线性函数，就称这种规划问题为非线性规划问题。\n1. 非线性规划问题的数学模型 https://blog-1310600458.cos.ap-shanghai.myqcloud.com/10001654751778_.pic.jpg\n二、 无约束问题 1. 极值问题 1.1 局部极值和全局极值 由于线性规划的目标函数为线性函数，可行域为凸集（没有空洞和凹入部分的集合叫做凸集），因而求出的最优解就是在整个可行域上的全局最优解。\n非线性规划却不是这样，有时求出的某个解虽是一部分可行域上的极值点，但是却不一定是整个可行域上的全局最优解。\n1.1.1 极值点存在的条件\n极值点存在的必要条件和充分条件。\n定理1：a\n定理2：\n2. 凸函数和凹函数 在研究非线性规划问题中，凸集、凸函数和凸函数的极值性质必不可缺少。\n2.1 凸集 简单来说，没有空洞和凹入部分的集合叫做凸集。\n2.2 凸函数和凹函数 凸函数和凹函数的几何意义十分明显。\n2.2.1 凸函数的性质\n2.2.2 判断函数是否为凸函数\n定理1：一阶条件\n定理2：二阶条件\n2.2.3 凸函数的极值\n优化的目的，往往是要求函数在整个域中的最小值（或最大值）和最小点（或最大点）。为此，必须将所得的全部极小值进行比较（有时还需要比较边界值）来从中选取最小值。但是定义在凸集上的凸函数来说，则不需要这么麻烦，它的极小值就等于其最小值。\n定理1：\n定理2：\n2.3 凸规则 2.4 下降迭代算法 【一维搜索】\n3. 无约束极值问题的解法 3.1 梯度法 3.2 共轭梯度法 3.3 变尺度法 3.4 步长加速法 三、约束极值问题 实际工作中遇到的大多数极值问题，其变量的取值可能收到一定的限制，这种限制由约束条件体现，带有约束条件的极值问题成为约束极值问题，也叫规划问题。\n非线性规划的一般形式为：\n对于约束的极小化问题来说，除了要使目标函数在每次迭代有所下降之外，还要时刻注意解的可行性问题，寻优工作比较困难。为了实际求解和（或）简化其优化工作，可采用以下方法：将约束问题化为无约束问题；将非线性规划问题化为线性规划问题，，以及其他能够将复杂问题化为简单问题的各种方法。\n1. 最优性条件 2. 二次规划 某线性规划的目标函数为自变量X的二次函数（X表示n维欧氏空间中的向量（点）），约束条件又全是线性的，称这种规划为二次规划。二次规划的数学模型可以表述为以下：\n【】\n以matlab中的quadprog为例，提出示例：\n在quadprog语法中，问题的表示中，此处引入概念，H为海赛（Hesse）矩阵 ：\n按照海赛矩阵的公式得到H矩阵，\n检查H是正定矩阵。\n3. 可行方向法 4. 制约函数法 4.1 外点法 4.2 内点法 四、概念 1. 可微函数 在微积分学中，可微函数是指那些在定义域中所有点都存在导数的函数。可微函数的图像在定义域内的每一点上必存在非垂直切线。因此，可微函数的图像是相对光滑的，没有间断点、尖点或任何有垂直切线的点。\n2. 范数 线性代数中，涉及到相似矩阵及二次型一章节。\n列向量：在线性代数中，列向量是一个 n×1 的矩阵\n参考资料   封面图片来源\n  老司机用python脚本刷微信读书的时长\n  优化理论——二次规划\n  MathWorks 二次规划\n  凸集、凸函数、凸优化的简介与联系\n  凸优化(一): 凸集\n  ","date":"June 9, 2022","image":null,"permalink":"/post/2022-6-09_quangrop/","title":"非线性规划"},{"categories":["shell"],"contents":"NMF（非负矩阵分解）  NMF in mutational signature\n 当得到大量样本时，根据k个分类，可以创建一个计数矩阵M，包含每个样本在每个分类的计数，该矩阵可以通过非负矩阵分解为两个矩阵，这两个矩阵一个代表signature的分类图谱，一个代表每个样本的signature数值。\n而当我们只有一个样本时，则不能通过NMF分解来获得以上提到的两个矩阵，但是可以通过确定的signature图谱矩阵，来推测该样本的signature的exposure。这个步骤就是fitting。\n fitting方法 $$ M \\approx P\\times E $$\n问题简化：\n已知矩阵M和矩阵P，推测非负矩阵E，需要满足Frobenius norm最小化：\n$$ min_{E}\\left|| M-PE\\right||_{F} $$\n该函数的值表示分解的误差。对每个病人g，目标函数可以写为：\nmin⁡∑k=1K(mkg−∑n=1N(engpkn))  s.t.:{∑n=1Neng=1eng≥0.\n  quadratic programming (QP)  可以用R包【quadprog】来实现。QP算法非常快和稳定，但是需要一个预定义的signature矩阵P为全列秩【？？？】，并依赖于问题公式作为Frobenius范数的最小化。\nsimulated annealing (SA)  可以用R包【GenSA】来实现。SA可以广泛用于没有很好预定义的signature矩阵，以及更广泛的错误估计，但是和QP相比，SA收敛到合适的解更慢。重要的是，SA还可以用来随机探索接近最优分解的次优解。\n 稳定性 稳定性分为两个部分：decomposition stability with respect to the input data (输入数据的稳定性)和the stability of the optimal solution (优化解决方法本身)\n 输入数据的稳定性  量化由于不确定性造成的生物学数据的噪音，需要对测量进行重复，bootstrap是一种实用的替代方法。为了确定signature的贡献是如何被分配的，以及评估他们的可信度和稳定性，作者（Teresa M Przytycka et al., 2018）使用QP方法对每个患者的原始突变分类进行1000次可替换的随机重采样，并估计每个bootstrap样本的signature贡献。基于signature贡献的分布，可以对每个signature贡献估计bootstrap的置信区间，以及signature贡献高于特定阈值的经验概率。为了评估不同的signature的贡献稳定性（bias），比如：为了检验bootstrap实验的贡献与原始贡献之间的差异，可以计算bootstrap估计与原始数据中最优贡献之间的差异的均方误差(MSE)。\n优化解决方法本身的稳定性  通过测试优化算法本身的稳定性可以探索signature之间的隐藏的依赖关系。我们对次优分解的空间进行采样，比如：近似分解误差略高于最优解，使用模拟退火方法——修改用于寻找最优解的SA方法，通过强制停止规则，从而当达到目标函数的给定值(分解误差)时报告次优解。把分解误差的阈值设置的比最优方法的要高1、3或5%。该计算对每个病人重复计算1000次，按给定的分解误差阈值随机抽取次优分解空间。随后使用获得的signature分布，和bootstrap分析一样，评估signature贡献的置信和稳定性。\n【how】\n二次规划（QP） 二次规划(QP, Quadratic Programming)定义：目标函数为二次函数，约束条件为线性约束，属于最简单的一种非线性规划。\n参考资料   封面图片来源\n  老司机用python脚本刷微信读书的时长\n  优化理论——二次规划\n  MathWorks 二次规划\n  凸集、凸函数、凸优化的简介与联系\n  凸优化(一): 凸集\n  ","date":"June 7, 2022","image":null,"permalink":"/post/2022-6-07_fit_algorithm/","title":"fit算法"},{"categories":["shell"],"contents":"步骤   安装网易mumu, 通过应用中心安装微信读书\n  安装python包：uiautomator\n  安装adb连接mumu\n  运行python脚本\n   安装网易mumu 网页mumu下载地址: http://mumu.163.com/\n安装完毕后，在应用中安装微信读书，并且登陆自己的账号\n 准备python环境 由于我已经安装过python，因此我只需要通过python来安装新的包。\npip3 install uiautomator  安装adb连接mumu  安装adb  adb相当于mumu的驱动，由于我是macOS系统，因此我只需要在终端使用brew来安装\nbrew install --cask android-platform-tools #安卓设备 写给小雨：windows的用户可以通过以下方式进行安装：\n Windows版本：https://dl.google.com/android/repository/platform-tools-latest-windows.zip\nMac版本：https://dl.google.com/android/repository/platform-tools-latest-windows.zip\nLinux版本：https://dl.google.com/android/repository/platform-tools-latest-linux.zip\n 下载后进行解压，按键windows+r打开运行，输入sysdm.cpl，回车。高级》环境变量》系统变量》path，将adb的存放路径新建路径，然后添加进path中。\n打开命令行测试是否安装成功：\nadb --verision 连接mumu  完成adb安装后，打开微信读书的某一页，记得看一下刚才安装过程中的默认端口提示，我的默认端口是5555，所以我输入以下内容来连接mumu：\nadb connect 127.0.0.1:5555 运行python脚本 python脚本如下，保存并自定义命名：\nfrom uiautomator import device as d  import time  import datetime  import random  #点亮屏幕  def lightScreen():  d.screen.on()  # 自动翻页，翻页后休息5-10秒钟  def autoSwipe():  # 假装看书45-55秒钟(假装是人类在看书。。。)   read_time = random.randint(45,50)   time.sleep(read_time)   print(\u0026#34;阅读花费：\u0026#34;,read_time,\u0026#34;秒\u0026#34;)  # 从（1000,500）到（30,500）   d.swipe(1000, 500, 30, 500) #这里需要根据你的模拟器的具体坐标测试  # 休息一段时间(休息的时间=60秒-看书的秒数)   time.sleep(60-read_time)   print(\u0026#34;休息\u0026#34;,60-read_time,\u0026#34;秒,放松下眼睛~\u0026#34;)  # 执行5小时(300分钟) if __name__ == \u0026#39;__main__\u0026#39;:   all_time = 300   user_input_time = input(\u0026#34;请输入需要阅读的分钟数(请输入正整数):\u0026#34;)   try:   user_input_time = int(user_input_time)   if (user_input_time \u0026gt; 0):   print(\u0026#34;程序将会执行\u0026#34;,user_input_time,\u0026#34;分钟\u0026#34;)   all_time = user_input_time   except:   print(\u0026#34;您输入的值不合法， 将使用默认参数300， 程序将会自动执行5小时\u0026#34;)   pass   for i in range(all_time):   lightScreen()   print(\u0026#34;自动点亮屏幕, 开始阅读。。。\u0026#34;)   autoSwipe()   print(\u0026#34;==\u0026gt;已经阅读\u0026#34;, i+1 ,\u0026#34;分钟\u0026#34;, \u0026#34;还差\u0026#34;, all_time-i-1,\u0026#34;分钟完成阅读\u0026#34;) 我的脚本名为wechat_read.py，运行该脚本。\n bug处理 运行python脚本的步骤中，我发现出现这样的报错：\nandroid - adb more than one device/emulator 检查我所使用的设备：\n$ adb devices List of devices attached emulator-5554 device 127.0.0.1:5555 offline 看来需要终止其中一个：\nadb kill-server emulator-5554 再次运行python脚本就可以了。\n参考资料   封面图片来源\n  老司机用python脚本刷微信读书的时长\n  windows下载安装adb\n  雷电模拟器adb devices返回127.0.0.1:5555 offline分析和解决办法【转】\n  ","date":"April 23, 2022","image":null,"permalink":"/post/2022-4-12_read/","title":"参加读书活动"},{"categories":["shell"],"contents":" \n    cna burden\n    参考资料    ","date":"April 11, 2022","image":null,"permalink":"/post/2022-4-12_qunatify_cnv/","title":"定量拷贝数变异"},{"categories":["shell"],"contents":" \n 本文主要参考：Survival Analysis Part I: Basic concepts and first analyses\n生存分析基本介绍 大多数的癌症研究中使用：\n  Kaplan-Meier plots\n  logrank tests\n  Cox (proportional hazards) regression\n  接下来将会介绍每种方法以及它们的应用。\n生存分析研究的内容   描述生存过程\n  比较生存过程\n  分析危险因素\n  建立数学模型\n  比如cox回归模型。\n生存分析的目的   估计\n  比较\n  影响因素分析\n  预测\n   死亡的时间、治疗到产生治疗反应时间、复发/无复发生存时间（relapse-free survival time; desease-free survival time）。\n删失 只有一部分的个体有生存时间，而另外一部分没有，这个现象叫做删失（censoring），有可能通过以下方式产生：\n  在研究终止的时候，还没有经历这个事件，比如死亡，复发等等\n  在研究过程中失踪了\n  一个病人经历了不同的事件，无法进行进一步随访\n  无法知道起始时间\n  这种删失情况，低估了事件发生的真实(但未知)时间。\n生存和风险 生存数据通常用两种相关的概率来描述和建模，即生存（survival）和危险（hazard）。\n生存概率（survival probability）S(t)（又被称作survivor function）是一个个体从时间起点（如：诊断出癌症）到一个特殊节点的时间t的生存概率。不同t值的生存概率提供了从时间到事件数据的关键汇总信息，非常重要。\n风险通常表示为 h(t) 或 \\( \\lambda(t) \\)，是一个人在一个时间t，被观察到发生事件的概率。换句话说，它表示已经存活到时间t的个体的瞬时事件率。和生存概率不同，生存概率侧重于不发生事件，风险函数侧重于发生事件。\n总而言之，风险与事件(当前)事件率有关，而生存反映了累积的不发生事件。\n KM生存分析 可以对观察到的生存时间（不管是删失还是非删失），通过KM或product-limit方法使用非参数估计来生存概率。假设有k名患者在不同时间的随访期间发生了事件：\n$$ t_1\u0026lt;t_2\u0026lt;t_3\u0026lt;t_4\u0026lt;t_5\u0026lt;\u0026hellip;\u0026lt;t_k $$\n由于事件被假定为独立地发生，从一个区间到下一个区间的生存概率可以相乘从而得到累积生存概率。在时间\\( t(j) \\)时活着的概率\\( S(t_j) \\)，是通过以下公式计算得到的，\\( d_j \\)表示在\\( t_j \\)之前活着的病人数量，\\( d_j \\)是在\\( t_j \\)时发生的事件数量：\n \n 这里\\( t_0=0 \\)且\\( S_0=1 \\)。在事件发生的时间之间 S(t) 值是恒定不变的，估算的概率值只在每个事件发生的时刻发生改变，这个估计公式允许每个病人在已知没有发生事件时为计算贡献信息。如果每个个体都经历了事件(没有发生删失)，这个估计器将简单地减少到t时刻自由事件的个体数量除以参与研究的人数的比率。\n生存概率的置信区间也可以计算出来。KM生存曲线是KM生存概率随时间变化的曲线，它提供了有用的数据总结，可用于估计中位生存时间等指标。大多数生存数据的分布存在较大的偏差，这是不经常使用平均值的原因。\n 风险和累积风险 S(t) 和 h(t) 之间存在一个关系：\n \n 这个公式对于常规的生存分析并不重要，因为它被纳入了大多数统计计算机软件包。这里表明的是，不管是 S(t) 和 h(t) 其中哪一个已知，另外一个会自动地得到。\n不过和 S(t)不同的是，h(t) 没有简单的方法来估计，因此经常使用累积风险 H(t) ，它被定义为风险的积分，或者风险函数下的面积在0和t之间的积分，与log-生存曲线的区别只是符号：\n$$ H(t)=-log[S(t)] $$\n对 H(t) 的解释很难，但也许把 H(t) 理解为死亡率的累积是最简单的方法，或者如果事件是一个可重复的过程，每个个体在时间t时预期的事件数。 H(t) 被作为估算 h(t) 的中间度量，并作为评估模型有效性的诊断工具。简单的非参数估计方法来估计 H(t) 是Nelson-Aalen估计。\n另外一种估计风险的方法是假设生存时间遵循一个特殊的数学分布，下图展示的是四个参数指定的风险和相应的生存概率之间的关系。它说明了随着时间的推移风险率是恒定的(类似于生存时间的指数分布)，根据威布尔模型严格增加/减少危险率，以及使用对数正态模型减少和增加风险率的组合。\n Relationships between (parametric) hazard and survival curves: (a) constant hazard (e.g. healthy persons), (b) increasing Weibull (e.g. leukaemia patients), (c) decreasing Weibull (e.g. patients recovering from surgery), (d) increasing and then decreasing log-normal (e.g. tuberculosis patients).\n  非参数检验比较生存 两个或更多组病人的生存可以使用非参数检验来比较，logrank test是比较两个或更多个生存曲线最广泛使用的方法，这些组可以是治疗组或预后组。如果组与组之间没有差异，则该方法在每个事件时间为每个组计算：自上一个事件以来预期的事件数。然后将这些值相加，得出组i中预期的事件总数 \\( E_i \\) ，用logrank test来比较治疗组i观察到的事件数量 O_i 与预期事件数量进行比较：\n \n 这个值与具有(g−1)自由度的χ2分布进行比较，其中g是组的数量。这样可以计算p值来计算完全生存曲线之间差异的统计意义。\n如果这些组是自然排序的，一个更合适的测试是考虑它们之间存在生存趋势的可能性，例如，年龄组或癌症阶段。在存活率可能增加或减少的基础上计算每一组的Oi和Ei，结果是一个更强大的测试。对于新的Oi和Ei，比较趋势检验统计量与单自由度的χ2分布。\n当只有两组进行比较时，logrank test是检验零假设，即两组风险率的比值等于1。危险比(HR)是衡量两组患者相对生存经验的指标，可通过下面公式进行估计：\n \n 其中\\( O_i/E_i \\)是估计组i的相对风险(relative hazard)，HR的置信区间是可以被计算的，HR对效应强度的解释与风险比类似。HR为1指的是生存没有差异。在实践中，最好使用回归建模技术来估计HR，比如Cox回归，下一篇文章将对此进行描述。\n 截至目前为止，上述内容描述的是对不同的病人组建立KM生存曲线，并通过logrank检验来判断不同组之间是否存在差异。这些方法都是单因素分析。 多因素生存分析 建立多因素统计模型的必要性在于：单因素分析，必然忽略了其他因素的影响。在临床中的实际情况是，有几个(已知)量或协变量，可能影响患者预后。比如对两组患者进行比较：一组是有特殊的基因型，另一组没有，其中一组的个体更老，存活的差异可能由于基因型或年龄，或两者皆有。因此，当调查与任何一个因素相关的生存时，通常需要根据其他因素的影响进行调整。\n另外，虽然logrank检验提供了组间差异的p值，但它没有提供实际效应量的估计;换句话说，它提供了该因素的影响的统计评估而非临床评估。\nezcox包 可视化函数show_forest可以批量完成生存分析并进行绘图，内部调用ezcox包，进而调用coxph函数：\nshow_forest(data,  covariates = ,  controls = ,  vars_to_show = ,  merge_models = TRUE,  add_caption = FALSE,  point_size = 2 )  单因素生存分析  covariate列出所有需要分析的因素，controls是需要控制的变量（不控制变量的话controls不填写即可），vars_to_show为需要展示的因素，结果会按照对covariate中的每个因素进行单因素控制变量分析。举例，假设我们需要对SBS1和SBS2单因素分析，且控制癌症类型变量，则：\nshow_forest(dt,  covariates = c(\u0026#34;SBS1\u0026#34;, \u0026#34;SBS2\u0026#34;),  controls = \u0026#34;cancer\u0026#34;,  vars_to_show = c(\u0026#34;SBS1\u0026#34;, \u0026#34;SBS2\u0026#34;) ) 结果会同时展示这两个函数计算的结果：\ncoxph(Surv(time, status) ~ SBS1 + cancer, data=dt) coxph(Surv(time, status) ~ SBS2 + cancer, data=dt) 关于控制变量cancer，这是一个字符型变量，每种癌症类型都有结果数值，其中会有1个癌症类型作为reference，\n 多因素生存分析  假设我们需要对SBS1和SBS2进行多变量分析，且需要控制变量cancer（不控制变量的话controls不填写即可），函数写为：\nshow_forest(dt,  covariates = c(\u0026#34;SBS1\u0026#34;),  controls = c(\u0026#34;SBS2\u0026#34;,\u0026#34;cancer\u0026#34;),  vars_to_show = c(\u0026#34;SBS1\u0026#34;, \u0026#34;SBS2\u0026#34;) ) 这里可能有点难理解，因为covariates只写了SBS1，是因为多因素生存分析只需要计算一次，就可以展示所有的变量的结果，因此这个函数真实的调用函数如下：\ncoxph(Surv(time, status) ~ SBS1 + SBS2 + cancer, data=dt) 样本量多少足够？ 参考资料   Survival Analysis Part I: Basic concepts and first analyses\n  Survival Analysis Part II\n  https://www.plob.org/article/16141.html\n  latex 工具\n  ","date":"April 11, 2022","image":null,"permalink":"/post/2022-4-10_survival_analysis/","title":"生存分析"},{"categories":["shell"],"contents":" C index介绍 C index 是AUC的扩展，AUC是C index的特殊。\n \n 参考资料  已经猴年马月了，你还不知道C-index？！  ","date":"April 10, 2022","image":null,"permalink":"/post/2022-4-10_c_index/","title":"C index"},{"categories":["shell"],"contents":"Multimodal data 首先我们应该明确什么是multimodal data?\n事物发生或经历时，或者是研究问题包含了多模态。我们通过看、听、闻来体会世界时，就是一种多模态。\n Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities.\n  Multimodal Deep Learning 整合具有不同的层次噪音和存在争议的模态是具有挑战性的。实践中最常见的方法是将不同输入的高级嵌入连接起来，然后应用softmax。\n Example of Multimodal deep learning where different types of NN are used to extract features\n 先建立一个博客，内容后续需要用到的时候再补上。\n详细了解生物信息学中用到的multimodal DL可以看最近的这篇文章：Deep learning with multimodal representation for pancancer prognosis prediction\n参考资料   Multimodal Deep Learning\n  \n  ","date":"April 10, 2022","image":null,"permalink":"/post/2022-4-10_multimodel_dl/","title":"Multimodal deep learning"},{"categories":["shell"],"contents":"注释类型 首先我们应该明确注释是在什么样的文件中？\n1．代码中的注释\n2．文本中的注释\n其次我们应该明确，我们需要去除的注释都是什么样子的？\n1．注释行前有特定字符，比如R代码中的注释#\n2．注释被包含在特定字符之间，比如Python代码中的 ```，以及SRIM软件输出结果开头的注释包含的两行===\n根据注释的类型不同，去除注释的方法也不同，接下来介绍一下如何去除注释。\n 特定字符的注释 使用read.table()读入数据时，设置参数comment.char = '#'，就可以把开头为#的行跳过。\n comment.char： 字符型，注释字符，以此字符开头的行将被忽略   特定字符间的注释【grep跨行匹配】 理想情况是一批文件的注释都在文本的前n行，这样我们只需要通过对read.table()中的参数设置为skip=n，跳过前n行进行读取即可。另外一种情况是，注释包含在两行字符之间，每个文件中注释的行数不确定。举个例子，cat input.txt\n======annotation====== this is annotation ====================== col1 col2 col3 1 2 3 4 5 6 使用shell处理方法如下：\ngrep -Pzao \u0026#34;=(\\n|.)*=\u0026#34; input.txt \u0026gt;mid.txt comm -3 input.txt mid.txt | grep -v \u0026#39;=\u0026#39; \u0026gt;out.txt grep是行过滤工具，用于根据关键字进行行过滤，常规使用方法是不支持跨行匹配的，这里通过正则和-P实现，参数：\n  -P：匹配的pattern是perl兼容的正则表达式。\n  z：一个 0 字节的数据行，但不是空行，将输入和输出数据视为行序列，每个行序列以一个零字节(ASCII NUL字符)而不是换行符结束。像-Z或——null选项一样，这个选项可以与sort -Z这样的命令一起使用，以处理任意文件名。\n  a：像处理文本一样处理二进制文件。这里我的文件显示的是txt的形式，但是匹配时却提醒是二进制，因此加上了-a。这个后面继续说。\n  o：只打印匹配行中匹配的(非空的)部分，每个部分输出单独行。\n  pattern：\u0026quot;=(\\n|.)*=\u0026quot;，跨行\\n匹配包含在=之间的所有内容。\n  更详细的参数直接在命令行输入man grep来查看，如果发现没有-P的话通过grep -V检查一下自己的grep是哪个版本，我最开始使用2.7版本没有-P，更新版本才可使用。\n另外我尝试使用-v来取反来直接一步到位，但是没有成功，原因还没搞清楚，可能和跨行匹配有关。\ncomm用于比较两个有序文件，使用comm是发现diff虽然能够找到文件不同，但是有\u0026gt;等提示两个文件不同的符号，无法一步到位，另外diff需要加上-a，因为文件是二进制的，comm则不管二进制还是普通文本格式，直接可以比较我的两个文件。\n管道操作符后面的grep，是因为结果出现了奇怪的多余的一行===，因此通过grep -v取反输出该行之外的所有内容。但是比较两个文件并没有发现该行来源，需要进一步仔细检查一下。\ncomm -1 A B 不显示在A文件中独有内容(显示B文件独有内容+两个文件共有) comm -2 A B 不显示在B文件中独有内容 comm -3 A B 不显示同时在两个文件中都存在的内容 comm -12 A B 显示A与B公共的部分 comm -23 A B 显示A独有的 comm -13 A B 显示B独有的  参考资料   R数据读取写入\n  vim删除多行注释与添加多行注释 好用\n  grep用法\n  grep\n  两个文件内容比较comm、diff、grep\n  grep跨行匹配\n  ","date":"April 7, 2022","image":null,"permalink":"/post/2022-4-06_%E6%B3%A8%E9%87%8A/","title":"如何去除文本注释"},{"categories":["癌症基因组学","生物学"],"contents":"基本框架（按照从大到细）   预后标志物背景介绍\n  预后标志物的类型（分类标准有作用；存在性质等等），主要关注基因组预后标志物\n  泛癌、特定癌种的预后标志物，这部分聚焦于特定的例子\n  如何开发一个预后标志物，好的预后标志物应该包含哪些特征，预后标志物目前存在哪些问题\n  生物信息学在研究预后标志物中的作用，聚焦于分析手段\n   预后标志物背景介绍 预后是XXXX【概念介绍】\n 从愿景到现实\n TNM分期系统： T(肿瘤大小和深度)N（淋巴结扩散）M（转移的发生与否）恶性肿瘤分类是用于分类癌症扩散程度的全球公认标准，它已为许多实体瘤癌症赢得了广泛的国际认可，但不适用于白血病和中枢神经系统肿瘤。最常见的肿瘤具有其自己的TNM分类。有时也称为AJCC系统。后来，病人的年龄、肿瘤分期、组织学亚型信息也纳入该标准，能够提高预后和预测对治疗反应的能力。[wiki]\n 当新的治疗手段出来时，病人情况变得更加复杂，TNM分期系统面临的问题：\n  个体分子标志物将传统的癌症类型分成更多的亚型，亚型之间存在不同的行为。\n  化疗和生物制剂更有效和广泛的使用。\n  很多新的靶向制剂面向的是特定突变或表达水平的病人。\n   预后标志物的类型 按照标志物性质分类   DNA标志物：单核苷酸多态性（SNPs），染色体异常（比如BCR-ABL转座），拷贝数变异，微卫星不稳定，不同的启动子区域甲基化。\n  RNA标志物：转录因子过表达或低表达，调控RNA（比如microRNA）。\n  蛋白质标志物：细胞表面受体（比如CD20），肿瘤抗原（比如前列腺癌特异性抗原PSA），磷酸化状态，碳水化合物鉴定【翻译可能有误，原有词汇：carbohydrate determinant】，肿瘤释放到血清、尿液、唾液等其他体液中的多肽。\n  如果按照标志物的存在位置，则除了从组织取样的方法，还有目前很热门的血液中cfDNA取样检测，（应该还有pet-ct等等物理性的手段，不过这个应该属于检测）。\n按照标志物作用分类  临床应用中的肿瘤测序\n 可以分为：分类、分程度、分期、预后和治疗选择、种系变异癌症遗传风险等等，通过上图可以发现，部分标志物身兼数职。\n 分类(classification)：比如分癌症亚型，来找到能够对特定治疗/药物受益的人。  通过组织的起源对恶性肿瘤进行分类是最基本的。组织学上通常可以诊断以及定义肿瘤的亚型，但是新的分子标志物可能有不同的诊断，比如\n  针对原发位置不确定的腹部肿瘤，可以结合高通量RNA、蛋白质和组织微阵列芯片技术来有效的区分起源于结肠还是卵巢[6]。\n  区分原发头颈部鳞状细胞癌（HNSCC）和转移肺鳞状细胞癌（SCC）[7]，判断HNSCC原发肿瘤的位置[8]。\n  以及追踪肿瘤发展过程中产生的基因组变异[9]\n   分程度(grade)  每个解剖位置都有自己的组织学程度系统，通过分化程度来区分恶性程度【？】，相比高等级的肿瘤，低等级、高度分化的肿瘤通常严重程度低且预后更良好，高等级的肿瘤生长更快速而且更容易转移。等级分配通常依赖于病理学家的经验，比较主观，但是也有根据病理学家定义的评分【10】。\n 分期(stage)  肿瘤的分类、分期以及程度会用来评估病人预后。但是为了提升预后而去汇总众多指标比较费时费力。\n再考虑使用靶向治疗的情况下，表达标志物通常会代替或完善肿瘤分类、分期、分程度等等。比如：\n  CD20阳性，使用利妥昔单抗(Rituximab)治疗淋巴癌，利妥昔单抗是一种对B细胞上特有的CD20抗原具有高亲合力的单克隆抗体。\n  HER2/NEU阳性，使用曲妥单抗治疗乳腺癌[27]。\n  BCR-ABL转座，使用伊马替尼(imatinib)治疗慢性髓细胞性白血病。\n  \u0026hellip;\u0026hellip;\n部分已经获得FDA批准，部分仍在研究阶段。\n 预后和治疗选择(treatment)      扫描种系变异来找到可能会遗传的癌症风险[2021, David B, Solit]  比如BRCA1和BRCA2种系突变。\n 分析方法角度 如何证明某特征或标志物具有预后作用？通常通过什么样的分析方法来得到这一结果？\n 预测他莫西芬治疗的淋巴结阴性乳腺癌复发的多基因试验[12]  问题：选择的21个基因是否和淋巴结阴性患者复发的可能性相关？\n主要验证手段：\n（1）根据21个基因的表达水平为基础定义一个复发评分，根据复发评分将目标病人分为低、中、高风险三个类别，通过KM生存分析来评估三个类别中10年复发率。发现三组中的复发率高低确实和风险水平高低呈现对应关系。\n（2）多变量cox分析中，复发评分是独立于年龄和肿瘤大小，具有显著预测能力的指标。\n多模态深度学习建立预后模型  详细看这篇文章：Deep learning with multimodal representation for pancancer prognosis prediction，使用了卷积神经网络来对泛癌进行建模，使用c index来判断预测结果好坏。\n三阴性乳腺癌的标志物  详细参考这篇文章：Triple-negative breast cancer: promising prognostic biomarkers currently in development\n预后模型预测患者的生存  详细参考这篇文章：A novel prognostic model predicts overall survival in patients with nasopharyngeal carcinoma based on clinical features and blood biomarkers\n使用lasso回归建立模型，并且使用c index来进行预测\n prognostic and Predictive Biomarkers in Triple-Negative Breast Cancer\n  名词解释 : tumor agnostic   A tumor-agnostic treatment is a drug treatment that is used to treat any kind of cancer, regardless of where in the body it started or the type of tissue from which it developed. This type of treatment can be used when the tumor has a very specific molecular alteration that is targeted by the drug or predicts that the drug is likely to work.\nMost cancer treatments are developed to treat a cancer that has developed in a specific organ or tissue, like breast cancer or lung cancer. A tumor-agnostic treatment treats any kind of cancer as long as the cancer has the specific molecular alteration targeted by the drug.\n  OncoKB   OncoKB is a precision oncology knowledge base developed at Memorial Sloan Kettering (MSK) that collects and stores information on somatic cancer gene alterations. Alterations included in OncoKB are DNA-based, nonsynonymous mutations, rearrangements, insertions and deletions in cancer. The document uses “alterations”, “mutations” and “variants” interchangeably.   参考资料   维基百科\n  Ludwig, Joseph A., and John N. Weinstein. \u0026ldquo;Biomarkers in cancer staging, prognosis and treatment selection.\u0026rdquo; Nature Reviews Cancer 5.11 (2005): 845-856.\n  12:Paik S, Shak S, Tang G, et al. A multigene assay to predict recurrence of tamoxifen-treated, node-negative breast cancer. N Engl J Med 2004;351:2817-26. [PubMed]\n  《精准医疗：从愿景到现实》\n  What is a tumor-agnostic treatment?\n  OncoKB\n   补充 看了一下自然基金的架构，以后我写文献调研类也按照这个模板写，有条理一些。\n  项目的立项依据（研究意义、国内外研究现状及发展动态分析，需结合科学研究发展趋势来论述科学意义；或结合国民经济和社会发展中迫切需要解决的关键科技问题来论述其应用前景。附主要参考文献目录）\n  项目的研究内容、研究目标,以及拟解决的关键科学问题。（此部分为重点阐述内容）\n  拟采取的研究方案及可行性分析。（包括有关方法、技术路线、实验手段、关键技术等说明）\n  本项目的特色与创新之处。\n  年度研究计划及预期研究结果。（包括拟组织的重要学术交流活动、国际合作与交流计划等）\n  ","date":"April 3, 2022","image":null,"permalink":"/post/2022-3-21_prognosis/","title":"癌症预后"},{"categories":["癌症基因组学"],"contents":"一、 拷贝数变异的介绍 1.1 结构变异和拷贝数变异 结构变异（structure variation, SV）是指基因组上大片段碱基的缺失、插入、重复、倒位和易位。这部分变异的频率，和疾病或者表型的关系等等都不明确，另外还有一部分的变异也属于结构变异，比如异态性（heteromorphisms），脆性位点（fragile sites），marker染色体，等臂染色体（isochromosomes），双微体（double minutes）等等，这部分的结构不正常和疾病有关。\n 等臂染色体，是两条基因和形态都一致的染色体臂。\n双微体，是无着丝粒的，染色体外扩增的核染色质，通常包含特定的染色体片段或基因，在癌细胞中常出现。\nmarker染色体，也被称为结构外异常染色体或“多余”染色体。在荧光原位杂交实验中，除了正常的染色体补体外的染色体。\n 拷贝数变异可以看成是特殊的结构变异。鉴定SV对DNA测序深度有较高的要求（一般要\u0026gt;30x），而较低深度的（\u0026gt;5x）覆盖均一的DNA测序就可以鉴定到CNV。对于肿瘤样本中的体细胞CNV和SV，需要比较肿瘤样本和正常样本来得到肿瘤样本特有的变异。基因芯片技术分辨率较低，能检测到的片段都是大片段的（比如1kb以上）。二代测序对于比较大片段的SV，比如是超过150bp长的变异，一个reads是无法涵盖这个变异的，这种情况下会有不同的策略进行间接地推断。\n1.2 结构变异和拷贝数变异造成的影响   Cancer\n  精神类疾病\n  免疫类疾病（红斑狼疮）\n  21三体综合症：做缺陷新生儿产前诊断\n……等等\n  二、拷贝数变异的检测  检测人类基因组中结构变异的方法\n  CNV, copy-number variation ：拷贝数变异\nCGH, comparative genome hybridization：比较基因组杂交\nLCV, large-scale CNV ：大范围拷贝数变异\nFISH, fluorescence in situ hybridization ：荧光原位杂交(\nIndel, insertion and deletion：插入和删除\nMAPH, multiplex amplifiable probe hybridization：多重可扩增探针杂交\nMLPA, mutiplex ligation-dependent probe amplification：多重连接探针扩增技术\nQMPSF, quantitaive multiplex PCR of short fluorescent fragments：短荧光片段的多重定量PCR\nqPCR, quantitative PCR：定量PCR\n 2.1 传统技术 2.1.1 细胞遗传学中常用染色体核型分析：  利用PHA（植物血凝素）刺激成熟的淋巴细胞再次分裂 利用秋水仙素在细胞分裂中期破坏纺锤丝，抑制细胞分裂，形成染色体的形态 通过胰酶消化或缓冲液作用，将染色体显带，通过带纹和数目的分析判断染色体数目和结构的情况  2.1.2 荧光原位杂交（FISH） ……\n2.2 aCGH芯片（array-based Comparative genomic hybridization） 2.2.1 aCGH和CGH的异同 1992年，Kallioniemi发明了无需细胞培养的比较基因组杂交技术（CGH）：\n 用不同荧光分别标记肿瘤和正常对照样本，把两者DNA等量混合 与中期细胞染色体进行杂交 通过比较肿瘤和正常对照荧光信号的相对剂量来检测拷贝数异常，DNA局部扩增或缺失导致单个染色体上的荧光强度增加或减少  该方法的缺点是无法检测整个染色体组数目增加的多倍体变化，也无法检测DNA总数量不变的染色体畸变。\n1995年。Schena等利用CGH技术结合微阵列基因探针（aCGH）定量检测多个基因的表达，随后aCGH应用于检测拷贝数异常。和CGH相比，aCGH的优点是：该技术不需要染色体培养，一次杂交实验即可在整条染色体或染色体区带水平对不同基因组间DNA序列拷贝数的差异进行检测并定位，aCGH将两个样本的DNA用红绿两种荧光进行标记，然后与芯片进行杂交，用据分析软件检测红绿两种荧光的比值，分析相对对照样本，实验样本的DNA拷贝数是增加还是减少。\n 比较基因组杂交\n \u0026ldquo;dye-swap\u0026quot;检测了假信号，该方法进行了两次检测， 在第二次检测时颠倒肿瘤和正常样本的标签，这样，如果两次检测的信号有不对称的情况时，认为是 假信号。\n 基于aCGH芯片技术的全基因组拷贝数变异检测\n 对于芯片技术来说，探针的本质是一段很短的DNA序列，是提前设计好的，对于倒位（inversion）和易位（translocation）来说没有改变DNA的剂量，在芯片上看不出来，另外由于插入（insertion）的片段可能是原先基因组上没有的，而探针是根据已知序列进行设计的，因此插入也无法进行检测。\n2.2.2 数据拟合 软件最原始的输入数据为荧光的信号值，信号值是有波动的，而拷贝数一定是一个整数，算法通过对原始的荧光信号值进行拟合，以确定对应染色体片段的拷贝数水平。\n 离散的拷贝数数值\n  去除噪音 检测正常、增加、减少的拷贝数 断点的检测  2.2.3 断点检测之CBS（circular binary segmentation） 是一种基于染色体芯片数据检测拷贝数变异的方法，目前也适用于二代测序数据的拷贝数变异检测的方法。\nA. CBS的背景 芯片数据存在噪音，发生在连续区域的变异通常会覆盖多个标记(marker)，因此标记不能够完全反映test样本中真实的拷贝数变异情况，因此需要一个方法来将染色体划分成多个片段，保证每个片段中的拷贝数是一致的。循环二元分割算法是从1975年的二元分割算法改进来的，它提供了一种自然的方法将染色体分割成相邻的区域，并利用permutation reference distribution避免了数据的参数化建模。\nB. CBS算法 循环二元分割算法(circular binary segmentation, CBS)是目前常用的芯片数据分段算法, 其优势在于利用相邻待测区间的数据均值差构建 t 统计量, 进而精确检测不同变异区域间的分段点。介绍一下估计拷贝数变异区域位置与变点检测（change point detection）的关联。\n原始的变点检测策略是1975年Sen和Srivastava提出来的，假设\\( D \\) 是芯片数据，\\( n \\)是长度，设\\( \\mu_{i} \\)和\\( \\mu_{i}^{\u0026rsquo;} \\)分别为\\( D \\)第一个元素\\( i \\)的log2ratio均值和后一个元素\\( n-i \\)的log2ratio均值，把\\( i \\)定位在使得\\( \\left | \\mu_{i}-\\mu_{i}^{\u0026rsquo;} \\right | \\)最大化的位置上，并且使用\\( t \\)检验来判断两段信号差异是否显著，如果显著，则标记此处为一个变点。原始的方法是检验1个单个变点的情况，不能够在大片段中检验出小片段的拷贝数变化，CBS算法所做的改进在于：\n并非考虑单个的变点，而是假设片段环绕成一个圆圈，第一次运行时将数据划分为两个弧，从\\( i \\)到 \\( j \\)为第一个弧，从\\( j \\)经过\\( n \\)和\\( 0 \\)再到\\( i \\)为第二个弧，找到使得两段均值最大的位置，并使用\\( t \\)检验判断两段的均值是否显著有差异，差异显著则标记为一个变化片段（2个变点），接下来，递归地将算法应用于三个结果片段：从0到\\( i \\);从\\( i \\)到\\( j \\)，从\\( j \\)到\\( n \\)，直到发现不了新的变化片段。\nBS算法图解\nCBS算法图解\n CBS算法存在的问题是存在边界效应（edge effect），即假设\\( i \\) 和\\( j \\)符合\\( \\left | \\mu_{i}-\\mu_{i}^{\u0026rsquo;} \\right | \\)最大化，不管是\\( i \\)贴近1还是\\( j \\)贴近n，有可能只存在一个真正的变点而非预想的两个变点的情况。可以通过以下办法来避免：\n 首先使用BS测试（CBS的前身）是否数据支持\\( i \\)作为一个变点，如果不是则撤销对\\( i \\)的标记 同样对\\( j \\)也进行BS测试，是否数据支持\\( j \\)作为一个变点，如果不是则撤销对\\( j \\)的标记  C. 使用CBS算法进行分段的工具  R包：DNAcopy CNVkit：适用于全外显子，目的区域靶向测序等数据的CNV检测 ……  2.3 SNP芯片 SNP芯片本质是基于染色体区域内的SNP分型结果来判断对应拷贝数，SNP芯片的分型是通过比较A/B两种allel对应的荧光信号强度的比值来确定的。除了提供 拷贝数信息，SNP array还提供了表型信息比如：杂合性位点丢失，证明了 删除 以及 单亲二体（Uniparental disomy, UPD)的存在。\n 单亲二体： 是指子代的一对同源染色体全部或者 部分 来自父亲或母亲中的一方\n CCLE和TCGA里的拷贝数变异文件就是由芯片数据——Affymetrix SNP 6.0 array数据处理得到的，该芯片包括单核苷酸多态性（SNPs）和检测拷贝数变异的探针，是全基因组水平的探针，包含超过906,600 SNPs和超过946,000检测拷贝数变异的探针，和SNP 5.0 Arrays的482000 SNPs相比较，新增的424,000 SNPs是HapMap项目（在全基因组规模上，确立SNP在人群中的常见分布和传递模式）中得到的，新的标记在染色体X和Y以及线粒体SNP等表现更好。946,000个非多态性的拷贝数探针中744,000个探针是通过空间分布选择得到的，其他202,000是基于Toronto Database of Genomic Variants（DGV）已知的拷贝数变化，这样的数据可以用来从头检测拷贝数变化，以及通过对SNP和已知的拷贝数多态性位点（copy number polymorphism loci）进行关联研究。\n SNP array 5.0/6.0的检测数据来源\n 使用Affymetrix SNP 6.0 数据来定义重复的基因组区域以及该重复区域的拷贝数，这个pipeline使用已有的TCGA 第2水平的数据（normalized data） 和R包 DNAcopy 来实现CBS算法进行数据的分割。级别1的数据是原始的芯片强度数据，浏览了一下GDC上的数据，数据格式为CEL的，测序平台为SNP 6.0，这批原始数据是私密的。\n 级别1的数据\n 通常是用PICNIC等软件来处理原始的数据，得到分段记录的文件。TCGA级别2的Tangent Copy Number文件，通过对芯片强度数值进行归一化，估计原始的拷贝数，并且做切线归一化（tangent normalization）即减去在正常样本中发现的变异。Tangent Copy Number数据包含下面5列数据：\nChromosome Start End Num_Probes Segment_Mean 用DNAcopy包将TCGA级别2的 Tangent Copy Number 数据转换成 Copy Number Segment 数据，该文件以制表符分隔的格式将相邻染色体区域与log2比率段关联，与每个染色体区域相关联的带有强度值的探针的数量包括在该文件中(没有强度值的探针不包括在计数中)，在拷贝数分割过程中，从男性中去除伪常染色体区探针集，从女性中去除Y染色体片段。这里还有一个 masked copy number segments ，使用的是和上述一样的方法，不同之处在于过滤步骤，去除了Y染色体和探针集中种系拷贝数变异，针对该数据使用GISTIC2来获得拷贝数变异数值文件Copy number Estimate，最后只保留编码蛋白质的基因，以及这些基因的拷贝数变异数值，噪音阈值设定在0.3，认为:\n CNV数值\u0026lt;-0.3则分类为删除事件（-1） CNV数值\u0026gt;0.3则分类为扩增事件（+1） -0.3\u0026lt;CNV数值\u0026lt;0.3则分类为中性事件（0）   数据级别对应的数据类型\n  示例：个体15号染色体q臂的log R Ratio (LRR)和B Allele Freq (BAF) values\n 2.3.1 SNP芯片数据工具   PennCNV\n  DNAcopy\n  ……\n  2.3.2 隐马尔可夫模型 2.4 全基因组（WGS） 全基因组的成本很高，针对全基因组CNV的检测，开发了一种CNV_seq的测序策略，指的是低深度全基因组测序，只需要5X的测序深度，就可以有效的检测CNV，全基因组CNV分析的算法/策略（以删除和新序列插入为例）：\n Genome structural variation discovery and genotyping\n 二代测序技术采用双端测序（图中绿色部分就是所测序列两端），得到双端的序列比对到参考基因组上，可以根据比对到参考基因组上的两端序列之间的间隔推测变异是否存在，大家都以参考基因组为基准，推断方法有四种以上主要的策略：\n  Read Pair（RP） ： 是根据双端测序插入片段的长度分布来检测CNV的，以1为例，假设测得的基因序列是500bp的reads，但是匹配到参考基因组上发现，两端的序列匹配上之后序列比500bp还要长，那么认为两端序列之间发生删除后才是我们测到的序列。\n软件工具：BreakDancer；PEMer；Ulysses\n  Read Depth（RD） : 通过测序堆在参考基因组上，某处reads很多堆在一起(可能是扩增)，某处reads缺失（可能是插入），扩增的序列往往指在参考基因组上存在（或者相似度很高），而novel sequence insertion中novel意思是这段序列通常比较特殊，在参考基因组上找不到。\n软件工具：CNVnator；ERDs\n  Split Read（SR） : 把reads mapping到基因组上，刚好reads被切开，切开的两端可以很好的mapping到参考基因组上。\n软件工具：Pindel；SVseq2\n  Assmbly : 从头组装，不是和参考基因组去比对。通过测序得到的序列从头组装后得到的contig直接和参考基因组做序列比对，就可以知道发生变异的情况。\n  现在这四种方法都用，做得较好的软件：manta sv同时用到了这四种策略。\n2.5 全外显子组（WES） 由于全基因组的成本挺高的，又考虑到外显子上的变异可能更具有致病性，因此可以基于WES做CNV分析，由于CNV区域的长度可能横跨了多个外显子或者基因，断点可能位于外显子以外的位置，所以PR，SR的策略无法应用到WES的CNV分析中，只能通过RD的策略进行分析。\n可以使用CNVkit、XHMM来鉴定WES的CNV。\n2.6 靶向测序 https://cloud.tencent.com/developer/article/1556103\nhttp://www.njnad.com/marketing/421.html\nhttps://cloud.tencent.com/developer/article/1556107\n \n  \n 下期内容：  相对和绝对拷贝数数值的获取 示例：ABSOLUTE 使用隐马尔可夫模型检测CNV 主流获取CNV的工具比较 靶向测序检测CNV GATK所使用的拷贝数calling算法 CBS算法除了判断断点，如何判断拷贝数数值？ PennCNV能够同时判断断点和拷贝数数值咩？总强度用来判断拷贝数数值，相对强度BAF用来判断LOH咩？ 我认为PennCNV有一个缺点就是，但是实际上可能拷贝数扩增不止4，那么其他的软件是怎么解决这个问题的？为了优化HMM的参数，使用Baum-Welch算法去优化，使用Vitebi算法来推断最可能的状态路径。排除了所有包含SNP小于等于2的CNV，因为这些CNV很肯定是假阳性的结果。 马尔可夫链依赖于初值的选择，初值的选择影响大吗？ ……  参考资料   染色体核型分析介绍\n  PennCNV官方文档\n  拷贝数变异检测算法之CBS算法详解\n  Kallioniemi, Anne, et al. \u0026ldquo;Comparative genomic hybridization for molecular cytogenetic analysis of solid tumors.\u0026rdquo; Science 258.5083 (1992): 818-821.\n  Schena, Mark, et al. \u0026ldquo;Quantitative monitoring of gene expression patterns with a complementary DNA microarray.\u0026rdquo; Science 270.5235 (1995): 467-470.\n  Pinkel, Daniel, et al. \u0026ldquo;High resolution analysis of DNA copy number variation using comparative genomic hybridization to microarrays.\u0026rdquo; Nature genetics 20.2 (1998): 207-211.\n  Alkan, Can, Bradley P. Coe, and Evan E. Eichler. \u0026ldquo;Genome structural variation discovery and genotyping.\u0026rdquo; Nature Reviews Genetics 12.5 (2011): 363-376.\n  Wang, Kai, et al. \u0026ldquo;PennCNV: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome SNP genotyping data.\u0026rdquo; Genome research 17.11 (2007): 1665-1674.\n  图：Kai Wang et al. Genome Res. 2007;17:1665-1674\n  Circular Binary Segmentation from Jeremy Teibelbaum\u0026amp;rsquo;s blog\n  CKVkit：https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004873\n  Ming-Lian\u0026amp;rsquo;s blog\n  隐马尔可夫模型：https://www.cnblogs.com/skyme/p/4651331.html\n  coursera生物信息学：导论与方法第四周\n  动态贝叶斯网络\n  封面图来源\n  ","date":"March 19, 2022","image":null,"permalink":"/post/2022-3-29_cnv/","title":"CNV"},{"categories":["如何科研"],"contents":"最近在修改文章，感觉自己的英文表达能力和学术写作能力太弱，刚巧看到施一公教授分享的公众号文章，觉得收获很大，记录一下。\n如何写论文 1．要写好科研论文，必须先养成读英文文章的习惯，争取每天30-60分钟。刚开始可以选择以读英文报纸、英文新闻为主，逐渐转为读专业杂志。我会在近期专门写一篇博客文章介绍一套行之有效的增强读专业杂志能力的办法。\n2．写科研论文，最重要的是逻辑。逻辑的形成来自对实验数据的总体分析。必须先讨论出一套清晰的思路，然后按照思路来做图(Figures)，最后才能执笔。\n3．具体写作时，先按照思路（即Figures）写一个以subheading为主的框架，然后开始具体写作。第一稿，切忌追求每一句话的完美，更不要追求词语的华丽，而主要留心逻辑（logic flow），注意前后句的逻辑关系、相邻两段的逻辑关系。写作时，全力以赴，尽可能不受外界事情干扰（关闭手机、座机），争取在最短时间内拿出第一稿。还要注意：一句话不可太长。\n4．学会照葫芦画瓢。没有人天生会写优秀的科研论文，都是从别人那里学来的。学习别人的文章要注意专业领域的不同，有些领域（包括我所在的结构生物学）有它内在的写作规律。科研文章里的一些话是定式，比如 “To investigate the mechanism of …, we performed …”, “These results support the former, but not the latter, hypothesis …”, “Despite recent progress, how … remains to be elucidated …” 等等。用两次以后，就逐渐学会灵活运用了。在向别人学习时，切忌抄袭。在美国一些机构，连续7个英文单词在一起和别人的完全一样，原则上就被认为抄袭（plagiarism）。\n5．第一稿写完后，给自己不要超过一天的休息时间，开始修改第二稿。修改时，还是以逻辑为主，但对每一句话都要推敲一下，对abstract和正文中的关键语句要字斟句酌。学会用“Thesaurus”（同义词替换）以避免过多重复。第二稿的修改极为关键，再往后就不会大改了。\n6．第二稿以后的修改，主要注重具体的字句，不会改变整体逻辑了。投稿前，一定要整体读一遍，对个别词句略作改动。记住：学术期刊一般不会因为具体的语法错误拒绝一篇文章，但一定会因为逻辑混乱而拒绝一篇文章。\n用最简单的话表达最明白的意思，但一定要逻辑严谨！\n 一些细节  odds ratio而不是odd ratio。   参考资料   施一公：如何一个通宵写出一篇Nature？ 点击原文\n  Nature:How to write a good research paper title\n  ","date":"March 19, 2022","image":null,"permalink":"/post/2022-3-28_%E7%A7%91%E7%A0%94%E5%86%99%E4%BD%9C/","title":"如何进行科研写作——【转载】"},{"categories":["R","生信"],"contents":"自问   是否有方法的比较\n  比较的标准是什么，如何判断应该使用哪种\n  聚类的共性如何展示\n  核心的算法是什么\n  仔细分析这个包的目的是什么？【一个包为什么可以被开发出来的，开发出来使用的优势在于？一个包可以包含的内容，一个包为了一种类型的分析可以提供哪些？】\n  基本框架   聚类分析介绍\n  理论：聚类算法\n  实操：聚类工具\n   【R包】cola 为了检验子群分类的稳定性，通常采用一致性聚类（consensus clustering/consensus partitioning）。通过对数据随机选取子集重复聚类，并对聚类的鲁棒性进行汇总，最终给出所有样本的聚类结果。cola包就是用来做一致性聚类的。\ncola包的优点在于：\n  它将共识聚类过程模块化，可以在不同的分析步骤中轻松地集成各种方法。\n  它为解释结果提供了丰富的可视化。\n  它允许同时运行多个方法，并提供功能以直接的方式比较结果。\n  它提供了一种新的特征提取方法，该方法可以更有效地分离子组。\n   cola包的流程  flowchart\n （1）清洗输入矩阵（可选步骤）。这一步骤后续会进一步说明。\n（2）通过最高分数提取行的子集。这里的分数是通过特定方法（the top-value method）计算得到的。针对基因表达分析或甲基化数据分析，大多数研究中会使用到方差最高的行。这个方法可以是绝对中位差（MAD）或其他。\n（3）对处理后的矩阵进行归一化（可选步骤）。比如基因表达可能会用到，而甲基化数据则不一定会用到。\n（4）对处理后的矩阵根据一定概率，对行或列进行随机采样，并对矩阵的列使用特定的聚类方法进行聚类，同时尝试不同的分类个数。\n（5）重复第4步并汇总所有的分类。\n（6）进行一致性聚类分析并给出结果最稳定的分类数目。\n（7）在预测的类别之间进行统计学检验，找出显著不同的的行。比如：找出类与类之间最特殊的基因。\n（8）如果矩阵的行和基因有关，可以进一步进行下游分析比如富集分析等等。\n cola包的使用步骤 假设矩阵存储在名为mat的对象中（列为样本，行为特征），使用cola进行一致性聚类，\n主要分为三个步骤：\n（1）调整矩阵。\nmat = adjust_matrix(mat) # optional 移除有很多NA值的行；移除方差太低的行；当每行中NA值少于50%时，推算处理NA值；处理每行中的离群值。\n（2）使用多种方法运行一致性聚类。\nrl = run_all_consensus_partition_methods(mat, cores = ...)  聚类方法：参数partition_method = ...  包括以下几种：\nhclust\nkmeans\nskmeans:skmeans`\ncluster::pam\nMclust::mclust\n 提取行的方法：参数top_value_method = ...  默认提取顶层行的方法包括：SD（标准差）、CV（变异系数）、MAD（绝对差中位数，原数据减去中位数后得到的新数据的绝对值的中位数）、ATC（cola中特有的）。在该步骤中，可以选择运行所有方法，也可以通过设定参数来运行其中某个方法，甚至可以通过register_top_value_methods()使用自定义函数来进行提取。\n如果数据量非常大的时候，可以随机采样一个样本子集来分类（自定义），随后进行聚类。\n另外，2.0.0版本提供了新的函数:\nhierarchical_partition(mat, cores = ...) 其通过层次方法进行一致性聚类。矩阵很大时，设置参数subset以便对样本降采样来聚类。\n（3）生成具体的HTML文件来展示完整的分析过程。\ncola_report(rl, output_dir = ..., cores = ...) （4）基于分类结果预测新样本的类别\npredict_classes() 主要应用在两个场景中：\n  在新的数据中预测样本的类别。\n  在大样本中，用户使用随机的样本子集进行分类，随后需要对剩余的样本同样进行分类。\n  为了使用cola的分类结果，需要对结果进行选择，比如：\ndata(golub_cola) res = golub_cola[\u0026#34;ATC:skmeans\u0026#34;] res predict_classes()需要至少三个重要参数：\n  ConsensusPartition对象\n  子集的数量\n  新的矩阵\n  新的矩阵需要有和最初分析使用的矩阵一样的行数，即拥有同样的特征，且特征排列必须一致。对新矩阵scaling的方法也要和最开始使用的一致。\n步骤如下：\n（4.1）对于所提供的ConsensusPartition对象和选定的k，由get_signatures()提取区分类的特征(signature)。当特征(signature)数大于2000时，只随机抽取2000个特征(signature)。\n（4.2）特征质心矩阵为k列矩阵，其中每一列为对应类样本的质心，即样本间均值。如果在cola分析中对行进行缩放，则特征质心矩阵是缩放值的均值，反之亦然。请注意，在计算质心时，silhouette分数小于silhouette_cutoff(默认值0.5)的样本将被删除。\n（4.3）拥有特征质心矩阵和新的矩阵，能够进行预测。\n对于新的矩阵中的每个样本，需要找到其最近的质心，有三种方法：欧氏距离(Euclidean distance)，相似性距离(cosine distance)，斯皮尔曼距离(Spearman distance)。\n简单来说步骤如下：\n 获取res矩阵  mat = get_matrix(res)  对矩阵进行归一化处理  mat2 = t(scale(t(mat)))  通过res得到三个分类，进而预测mat2的类别  cl = predict_classes(res, k = 3, mat2) cl  ATC \n  参考资料   cola包文档\n  Picture\n  ","date":"March 19, 2022","image":null,"permalink":"/post/2022-3-24_cluster/","title":"聚类分析之cola包【没写完】"},{"categories":[" "," "],"contents":"安装包   pyexecjs：这个库主要是将 JS 代码运行在本地的 JS 环境中\n  lxml\n  参考资料：   https://juejin.cn/post/6844903798935126030\n  封面图来源\n  ","date":"March 16, 2022","image":null,"permalink":"/post/2022-3-17_sport/","title":"Python实现自动定场"},{"categories":["癌症基因组学","生物学"],"contents":"基本框架 拷贝数变异的博客框架：\n  介绍拷贝数变异的从属关系，和结构变异的关系；克隆性拷贝数变异和亚克隆拷贝数变异\n  拷贝数变异检测手段，拷贝数变异检测方法/算法（这个比较多，可以分多点讲）\n  结构变异的检测手段等等\n  引发拷贝数变异的机制\n  拷贝数变异的应用价值\n  拷贝数变异的最新研究动向\n  该博客的框架：\n  简单过一下拷贝数变异的介绍。\n  详细阐述每一种拷贝数变异的机制和机制发现的过程。\n  癌细胞中的基因组变异可以分为两种主要的类别：\n（1）小的变异：单核苷酸变异，双核苷酸变异，以及小的插入和缺失等等。\n（2）大的变异：结构变异。\n这里的大小是人为界定的，界定范围一般是50bp。（patterns and mechanisms of structural variation in human cancer）相比较结构变异，拷贝数变异的检测相对容易。\n Yi and Ju 2018\n 传统的细胞生成技术把结构变异分成了简单的四类：大的删除、扩增、易位和倒位。全基因组测序分析表明，很多结构变异不是独立的事件造成的，而是通过“单次命中（single-hit）”获得的，因此是复杂的基因组重排。下面介绍一些肿瘤中发现的复杂的重排模式。\n 染色体碎裂（chromothripsis） 1. 概念介绍 染色体碎裂于2011年首次被定义，命名含义：染色体被切成碎片（2011）。它是受到大量的（可以超过100个）结构变异断点影响的复杂的重排模式，主要集中在一个或几个染色体臂上(Korbel,J.O. \u0026amp; Campbell, P.J.2013)。通常情况下，染色体碎裂在约3%的肿瘤中出现，尤其是骨癌（25%）和脑癌（10%）中较为常见。（2011）但是对于其患病率和癌症类型特异性仍比较模糊。染色体碎裂涉及到的染色体臂的拷贝数变异只在两种状态间震荡变化(1个拷贝或2个拷贝，偶尔出现3个拷贝的情况)，在删除和正常的拷贝数状态之间变化，另外，杂合性缺失（LOH）在DNA拷贝数区域出现频繁。\n2. 染色体碎裂模式 最简单的解释染色体碎裂发生的模式是：在肿瘤细胞中的单次灾难性打击，同时将一个或几个染色体臂粉碎成数百个DNA片段，随后DNA修复通路（可能是NHEJ，这个后续会提到）将片段重新组装，但是是以错误的排序和方向进行的组装，在修复过程中没有参与重新组合的片段发生了丢失从而发生了删除事件，最终结果形成了染色体碎裂。\n上述解释了染色体碎裂在基因组上的特征，但是对于灾难性打击事件并不了解。目前有两种互斥的机制：\n（1）端粒危机:端粒短化，末端和末端的染色体融合，形成染色质桥（41）\n端粒（telomere）是染色体末端保护染色体的DNA区域，当端粒缩短，染色体末端（chromatid）可能会融合，形成具有双着丝粒（dicentric）的染色体，从而在有丝分裂中不能够分开进行子细胞，融合位点在有丝分裂后期伸展，形成染色质桥。在某些情况下，该桥诱导核膜在后期部分破裂，3 \u0026lsquo;修复外切酶1 (TREX1)的核酸酶活性产生大量的单链DNA和桥断裂[42]。在子细胞中观察其结构变异情况，容易发现其存在已知染色体碎裂存在的特征，以及局部超点突变(kataegis)。这个机制可以解释为什么染色体碎裂容易发生在端粒附近。\n（2）有丝分裂时染色体错分离，形成微核（18）\n在染色体上异常的核结构（微核）造成的物理隔离可能是染色体碎裂产生的机制。微核通常由于细胞分裂错误造成，比如在有丝分裂期间完整染色体的错误分离(43)以及异常DNA复制或修复过程产生的无着丝粒的基因组片段。微核中的分子过程容易出错，被分离出来的遗传物质被大量的分解成碎片，并重新组合，重新连接的DNA片段，显示出染色体碎裂的特征，并且被固定在子细胞中。\n????什么是微核\n Yi and Ju 2018\n 3. 染色体碎裂的定量/界定  chromoplexy 1. 概念介绍 chromoplexy是扩展了的平衡易位（balanced trandslocation），重新洗牌了很多染色体（超过两个染色体），结构变异在chromoplexy事件中通常涉及到超过3个染色体，并且是一个闭环“closed chain”的重排模式，尽管有小的删除会偶然的结合在断点周围形成“删除桥”，在chromoplexy时间中大部分的结构变异是拷贝数中性的。chromoplexy有很多相互依赖的结构变异断点（大部分是染色体易位），但是数量比染色体碎裂要少，这种现象在前列腺癌中发现（46），其发生的比例约90%，并且未在其他癌症类型中发现（截止文章发表的2018年）。chromoplexy机制通常是会破坏肿瘤抑制基因（比如：PTEN、TP53和CHEK2等等），并通过融合基因的形成来激活致癌基因（oncogene）（比如：TMPRSS2-ERG），\n2. chromoplexy和染色体碎裂的异同点   同：都是由于一次灾难性打击后（不是相同的灾难性打击），产生了很多DNA双链断点。\n  同：染色体碎裂和chromoplexy都是：破碎+缝合，因此几乎不涉及到扩增，尽管chromoplexy有小的删除，但绝大部分chromoplexy是拷贝数中性的。\n  异：染色体碎裂只限于染色体臂，chromoplexy则分布在染色体上，不过双链断点的分布并不是随机的，而是富集在转录活跃的和开放的核染色质区域（48-50）。这表明了核转录中心，这个在空间上聚集了很多共同调控的基因组区域的部分，由于一次灾难性打击被片段化了。但是这个灾难性打击并不清楚是什么。\n   Yi and Ju 2018\n  微同源介导的双链断裂修复（microhomology-mediated break-induced replication, MMBIR） 1. 概念介绍 一个父位点导致的大量散布的拷贝数扩增，这些扩增子直接和常见的微同源（2-15bp）以及模版插入在断点连接处相互连接，该模式最开始是用来解释种系拷贝数变异的，研究假设：跨损伤DNA聚合酶比如Rev1等等参与产生了MMBIR（53）。\n细胞条件下诱导MMBIR产生的机制仍不明确。研究假设：由于大量的DNA加合物或/和单链DNA断裂干涉了正常DNA的复制，并刺激了模板的转换（？），形成破损复制叉（replication fork），通常为了修复破损的复制叉，模板的转换使用了姐妹染色单体，但是这个过程有利有弊，该修复过程在选择非等位的（non-allelic）染色体区域作为模板时，会导致染色体重排。\n总结：扩增；复制叉\n Yi and Ju 2018\n  断裂融合桥（breakage-fusion-bridge cycle, BFB cycle） 1. 概念介绍 断裂融合桥首次在1939年被发现（57），当两个着丝粒在细胞后期被撕开时，端粒融合和断裂形成了具有双着丝粒的环，在部分细胞周期中，两个着丝粒中间随机形成了随机的大量双链断裂点，断裂融合桥环的典型特征就是重排，包括：\n  在亚端粒区域的stair-like增加（？）[41]\n  在断点处的fold-back inversion的富集\n  BFB环调控的结构变异在急性淋巴细胞白血病的亚型中展现出来，涉及到21号染色体的染色体内扩增，以及RUNX1基因的扩增。\n Yi and Ju 2018\n  同源重组修复缺陷（homologous recombination repair defect， HRD） 1. 概念介绍 同源重组（HR）是使用一致的或相似的DNA序列来修复双链断裂的基本细胞机制，同源重组的步骤通常是：\n（1）切除双链断裂的5‘【这段检查一下】\n（2）把3’端悬挂的部分匹配到一致的或类似的DNA片段上【是不是避免发生而不是推动发生】\n（3）DNA修复使用1个或2个通路——double-holliday junction[62]或synthesis-dependent strand annealing\n双链断裂修复缺陷（比如：BRCA1和BRCA2的失活）造成了基因组的不稳定【这个增加风险是如何得到该结论的？？？见下图64，65】，并且增加了乳腺癌和卵巢癌的风险。通常，在同源重组通路中，BRCA1伴随ATM，TP53和CHEK2来识别DNA双链断裂，BRCA2在加载(loading of)RAD51中起到重要作用，RAD51是5‘末端切割后链匹配必须的基因，在7%的乳腺癌患者中发现BRCA1和/或BRCA2完全失活，尤其是三阴性乳腺癌中。\n 1994\n BRCA基因突变的乳腺癌患者和其他乳腺癌患者相比存在更高的结构变异负荷，根据失活基因，发现了结构变异的特殊的模式。比如，BRCA1失活的肿瘤中主要是短的(\u0026lt;10kb)串联重复（tandem duplication），BRCA2失活的肿瘤主要是删除[68]，\n 2018\n HRD在临床上非常重要，因为其存在靶向药物（PARP抑制剂）来抑制碱基切除修复通路，通过靶向其他的基因组不稳定性作用于同源重组修复缺陷的细胞，只使得肿瘤细胞死亡。【如何进行靶向的如何把靶向HRD的肿瘤细胞呢】\n 双微体和新染色体（double-minute chromosome and neochromosome） 1. 概念介绍 双微体是缺少着丝粒的小环形的异常基因组片段，双微体通常在血液和实体瘤肿瘤细胞中大量扩增，在40%的恶性胶质瘤中存在，部分致癌基因比如CDK4,MDM2,EGFR等在双微体中一起扩增。双微体在肿瘤发生和肿瘤克隆性演化中[78,79]非常重要。\n新染色体（neochromosome）是异常的环形或线形的基因组片段。和双微体不同，新染色体有着丝粒结构和端粒区域（如果是线形的），新染色体在3%的癌症中出现，尤其是间叶性肿瘤【什么是间叶性肿瘤】[80]，脂肪肉瘤的基因组可以阐述新染色体的形成。[81]。和双微体一样，新染色体初始是环状DNA结构，中间的结构随后抓住着丝粒，最终通过双末端获取端粒形成线形。\n 2018\n  可移动原件的转座（transposition of mobile elements） 1. 概念介绍 转座子(transposable elements,TEs)是人类基因组上占据45%的重复的DNA序列[82]，这些元件通过“剪切-粘贴”（DNA转座）或“拷贝-粘贴”（逆转录转座子）的方法产生结构变异，在基因组演化过程中产生重要作用，人类基因组中大部分的转座子在种系和体细胞中是缩短和不活跃的（肿瘤细胞中存在比较频繁的现象，比如L1逆转录子），\n 2018\n  外源性DNA的插入（insertion of external DNA sequence） 1. 概念介绍 除了对核基因组进行重新洗牌的方法，肿瘤细胞可以从病毒、线粒体和细菌中获取崭新的核外DNA序列，比如超过95%的宫颈癌和12%的头颈癌患者的基因组中含有HPV的DNA序列，HPV基因组整合直接涉及到肿瘤发生（例：通过HPV的致癌基因E6来抑制P53通路）以及导致基因组不稳定性的发生。HPV插入的区域会通过“环调控机制”频繁扩增，插入的区域趋向于形成环结构，基因组DNA片段由于病毒插入会扩增超过50倍，导致病毒致癌基因表达上调，并且和附近的基因产物共同扩增。\n细胞内部核转移全部或部分的线粒体DNA序列在癌症基因组中也存在（在2%的肿瘤中，尤其是皮肤癌、肺癌、乳腺癌中），但是线粒体DNA如何移动和插入基因组DNA的分子机制并没有完全阐明（截止2018）。大部分的体细胞核基因组整合线粒体DNA并不是单独发生的，而是和重排事件组合发生，认为，线粒体染色体片段可能在体细胞中DNA修复过程中充当“补充材料”或线形编织破损的核DNA片段[106]。\n 2018\n  结构变异的功能作用 结构变异对肿瘤发生和克隆性演化中的功能性结果至少可以分为四个直接的机制：\n  截断基因（truncation of genes），比如基因删除或破坏\n  对整个基因扩增，通过“剂量效应”来提升表达水平\n  融合基因的形成，比如肺癌中的EML4-ALK和白血病中的BCR-ABL\n  前三种是传统的机制，第四种存在概念进展。\n 劫持增强子。比如：对肿瘤基因替换基因表达，包括IRS4、SMARCA1、TERT等等[119]，在乳腺癌中，乳腺癌组织特异性调控区域反复重复，表明正向选择压力的存在，很多非编码的结构变异可能会影响近端或远端的基因表达。   拷贝数变异具有的特征  focal和arm-level染色体变异  在整个基因组上，最常见的体细胞拷贝数变异（SCNA）是短的染色体变异（focal），和几乎和染色体臂或整条染色体等长的染色体变异（arm-level）。[3] arm-level的染色体变异发生的占比大约是focal的30倍，且几乎所有的癌症类型中都是这样。认为这两者发生概率不同，意味着是分别发生的。\n \ns 撕开 pull apart 细胞分裂后期 anaphase translocation异位;inversion倒位 prevalence某现象发生的比例 平衡易位是什么 核染色质区域 扩增子\nCNV和CNA有什么区别和关系？\n SV和CNV有什么区别和关系？\n CNV和CNA有什么区别？\n CNV，CNA和aneuploidy有什么区别？chromosome instability？\n   稳定性？\n  适应性？\n   参考资料   维基百科\n  算法的鲁棒性\n  [2]context is everything:aneuploidy in cancer\n  [3]The landscape of somatic copy-number alteration across human cancers\n  ","date":"March 16, 2022","image":null,"permalink":"/post/2022-3-16_mechanism_of_cnv/","title":"拷贝数变异机制"},{"categories":["算法","机器学习"],"contents":"通过搜索发现，鲁棒性是一个应用很广泛的词汇，我们主要关注它在计算机科学的算法和统计学中代表的含义。\n维基百科上这样描述：稳健性（英语：Robustness）是指一个计算机系统在执行过程中处理错误，以及算法在遭遇输入、运算等异常时继续正常运行的能力。\n Robustness is the capacity of a method to remain unaffected by small, deliberate variations in method parameters.\n 在分析方法中，鲁棒性是在分析方法的验证研究中评估过的一个参数，它被定义为“在实验条件存在微小变化的情况下，分析方法产生无偏结果的能力”。\n总结：鲁棒性看起来并不是强调方法的普适性，而是描述方法在面对异常情况时的稳定能力，强调的是面对干扰的能力。\n描述一个方法/算法可以适用不同来源的数据，应该用什么词？\n   稳定性？\n  适应性？\n   参考资料   维基百科\n  算法的鲁棒性\n  ","date":"March 15, 2022","image":null,"permalink":"/post/2022-3-15_robustness/","title":"什么是鲁棒性(robustness)"},{"categories":["R","机器学习"],"contents":"介绍机器学习R包。\n1. 数据分割 基于输出变量的分割 在建模之前，需要对样本数据进行分割分为训练集和测试集。在之前建模过程中，我发现我使用sample进行分割存在一定的问题，比如我分割出来的数据中response的占比在训练集和测试集中差别很大等等。caret包中可以解决这个问题，通过设置p值，同时确定训练集和测试集的占比，并各个因子水平下取占比（表述的有点问题）。\ncreateDataPartition(y,  times = 1,  p = 0.5,  list = TRUE,  groups = min(5, length(y))) 2. 预处理 2.1 虚拟变量处理 数据预处理又包括：对因子型变量进行虚拟变量处理（比如response在数据中是yes或no的形式表示，那么可以在这一步转换为虚拟变量0,1，这一步骤尤其适合多个因子型变量都需要处理的情况，可以节约时间）；\ncaret包假定所有的数据都是数值型的，比如因子型的可以通过model.matrix和dummyVars转换为dummy的变量。 dummyVars：\ndummyVars(formula, data, sep = \u0026#34;.\u0026#34;,  levelsOnly = FALSE,  fullRank = FALSE, ...) predict(object, newdata, na.action = na.pass, ...) formula：y~x1+x2，公式右边需要处理为哑变量的因子型变量，不确定哪些是因子型变量的话，可以直接使用y~.来制定所有的列，自动把因子型变量的进行处理。\n2.2 近零方差变量的删除 比如有些变量存在一些很特殊的值，这些值的占比很少，假设response中yes的为99个，no的为1个，那么一些模型来说，模型会崩溃(crash)或者fit to be unstable. 当数据做交叉验证时进行分割以及bootstrap采样的时候，这些变量可能是零方差的，举个例子：\ndata(mdrr) data.frame(table(mdrrDescr$nR11))  ## Var1 Freq ## 1 0 501 ## 2 1 4 ## 3 2 23 当存在很多变量时，可以用过这个函数批量处理：\nnearZeroVar(x, freqCut = 95/5,  uniqueCut = 10,  saveMetrics = FALSE,  names = FALSE,  foreach = FALSE,  allowParallel = TRUE) nzv(x, freqCut = 95/5, uniqueCut = 10, saveMetrics = FALSE, names = FALSE) freqCut：阈值，默认值是最频繁的数值个数95/次频繁的数值个数5\n2.3 删除高相关的预测变量和完全线性关系的变量 2.4 数据标准化处理 2.5 缺失数据的处理 2.6 变量转换 3. 特征选择 4. 使用重采样的模型调整 5. 变量重要性的评估 参考资料：  教你使用caret包(一)\u0026amp;ndash;数据预处理  ","date":"February 24, 2022","image":null,"permalink":"/post/2022-2-24_caret1/","title":"R包caret基本功能【1】——六种基本功能"},{"categories":["R","机器学习"],"contents":"介绍机器学习R包mlr3，该包提供了分类、回归、生存分析以及其他的机器学习任务，包含超参的调节以及特征的选择，本地支持很多操作的并行化。\n1. mlr3 Quickstart install.packages(\u0026#34;mlr3\u0026#34;) 对iris数据集的前120行训练一个决策树，并且对后30行进行最终的预测，最后判断预测模型的准确性。\nlibrary(\u0026#34;mlr3\u0026#34;) task = tsk(\u0026#34;iris\u0026#34;) learner = lrn(\u0026#34;classif.rpart\u0026#34;)  # train a model of this learner for a subset of the task learner$train(task, row_ids = 1:120) # this is what the decision tree looks like learner$model 预测\npredictions = learner$predict(task, row_ids = 121:150) predictions 准确性\n# accuracy of our model on the test set of the final 30 rows predictions$score(msr(\u0026#34;classif.acc\u0026#34;))   2. R6 mlr3提供的所有基本构建块都是R6类，因此需要了解一下R6类。R6是R用于面向对象编程(OO)的语言之一，面向对象是以功能来划分问题，而不是步骤。\n  object是通过R6::R6Class()创建的，foo = Foo$new(bar = 1)就是创建了一个新的Foo类的object，设定bar这个参数值为1，在mlr3中很多object都是通过特殊的功能来创建的。e.g. lrn(\u0026quot;regr.rpart\u0026quot;)。\n  object有沉默状态，可以通过$来调用，比如我们可以通过 foo$bar调取foo变量中的bar参数值或者重新对参数值进行设定。\n  object还公开了一些方法来检查object的状态，检索信息或执行改变对象内部状态的操作，比如$train通过建立和存储一个训练过的模型来改变学习者的内部状态，以便在给定数据的情况下使用该模型进行预测。\n  object有公开和私密的field和方法，公开的field和方法定义了和object联系的API，私密的方法只和使用者有关。（？？？）\n  拷贝object可以使用$clone()方法以及对nested object使用deep=TRUE参数，比如foo2 = foo$clone(deep = TRUE)\n  更多关于R6的介绍可以看R6介绍，特别是其中introduction部分。\n2.1 R6基础介绍 创建一个简单的R6类，public参数是项目列表，可以是函数和filed（非函数），函数可以被当作方法使用。\nlibrary(R6)  Person \u0026lt;- R6Class(\u0026#34;Person\u0026#34;,  public = list(  name = NULL,  hair = NULL,  initialize = function(name = NA, hair = NA) {  self$name \u0026lt;- name  self$hair \u0026lt;- hair  self$greet()  },  set_hair = function(val) {  self$hair \u0026lt;- val  },  greet = function() {  cat(paste0(\u0026#34;Hello, my name is \u0026#34;, self$name, \u0026#34;.\\n\u0026#34;))  }  ) ) 要实例化这个类的一个对象，使用$new():\nann \u0026lt;- Person$new(\u0026#34;Ann\u0026#34;, \u0026#34;black\u0026#34;) ann $new()方法创建了对象并且使用了initialize()方法（如果存在的话）。在class方法里，self指的是对象，对象中面向公众的成员可以通过self$x来使用，赋值通过self$x \u0026lt;- y完成。一旦对象被实例化，就可以通过$来获取值和方法。\nann$hair ann$greet() ann$set_hair(\u0026#34;red\u0026#34;) ann$hair 2.2 R6的私密成员 在上面的例子中，所有的成员都是公开的，但也可以在对象中添加私密成员：\nQueue \u0026lt;- R6Class(\u0026#34;Queue\u0026#34;,  public = list(  initialize = function(...) {  for (item in list(...)) {  self$add(item)  }  },  add = function(x) {  private$queue \u0026lt;- c(private$queue, list(x))  invisible(self)  },  remove = function() {  if (private$length() == 0) return(NULL)  # Can use private$queue for explicit access  head \u0026lt;- private$queue[[1]]  private$queue \u0026lt;- private$queue[-1]  head  }  ),  private = list(  queue = list(),  length = function() base::length(private$queue)  ) )  q \u0026lt;- Queue$new(5, 6, \u0026#34;foo\u0026#34;) 公共的成员可以通过self来获取，比如self$add()，私密的成员可以通过private来获取，比如private$queue，公共的成员使用方法如下：\n# Add and remove items q$add(\u0026#34;something\u0026#34;) q$add(\u0026#34;another thing\u0026#34;) q$remove() #\u0026gt; [1] 5 q$remove() #\u0026gt; [1] 6 q$remove() #\u0026gt; [1] \u0026#34;foo\u0026#34; q$remove() #\u0026gt; [1] \u0026#34;something\u0026#34; q$remove() #\u0026gt; [1] \u0026#34;another thing\u0026#34; 但是私密的成员没办法直接获取。\nq$queue #\u0026gt; NULL q$length() #\u0026gt; Error: attempt to apply non-function 这样的设计可以使得方法连接使用，因为可以让方法在可能的情况下返回self（不可见的）。\nq$add(10)$add(11)$add(12) 2.3 Active bindings Active bindings看起来像fields，但是每次获取时，会调用一个函数，通常是公开可见的。\nNumbers \u0026lt;- R6Class(\u0026#34;Numbers\u0026#34;,  public = list(  x = 100  ),  active = list(  x2 = function(value) {  if (missing(value)) return(self$x * 2)  else self$x \u0026lt;- value/2  },  rand = function() rnorm(1)  ) )  n \u0026lt;- Numbers$new() n$x 当以读取值的方式访问active binding时，它会调用value的函数作为缺少的参数:\nn$x2 #\u0026gt; [1] 200 当它像赋值一样被访问时，它使用赋值值作为value参数:\nn$x2 \u0026lt;- 1000 n$x #\u0026gt; [1] 500 如果函数没有参数，那么不能使用赋值符号：\nn$rand #\u0026gt; [1] 0.2648 n$rand #\u0026gt; [1] 2.171 n$rand \u0026lt;- 3 #\u0026gt; Error: unused argument (quote(3)) 2.4 继承 一个R6类可以继承另外一个R6类，也就是有超类和亚类。亚类可以有另外的方法，而且可以有覆盖超类的方法，举个例子，queue保留它的历史，添加show()方法，覆盖remove()方法：\n# Note that this isn\u0026#39;t very efficient - it\u0026#39;s just for illustrating inheritance. HistoryQueue \u0026lt;- R6Class(\u0026#34;HistoryQueue\u0026#34;,  inherit = Queue,  public = list(  show = function() {  cat(\u0026#34;Next item is at index\u0026#34;, private$head_idx + 1, \u0026#34;\\n\u0026#34;)  for (i in seq_along(private$queue)) {  cat(i, \u0026#34;: \u0026#34;, private$queue[[i]], \u0026#34;\\n\u0026#34;, sep = \u0026#34;\u0026#34;)  }  },  remove = function() {  if (private$length() - private$head_idx == 0) return(NULL)  private$head_idx \u0026lt;- private$head_idx + 1  private$queue[[private$head_idx]]  }  ),  private = list(  head_idx = 0  ) )  hq \u0026lt;- HistoryQueue$new(5, 6, \u0026#34;foo\u0026#34;) hq$show() #\u0026gt; Next item is at index 1  #\u0026gt; 1: 5 #\u0026gt; 2: 6 #\u0026gt; 3: foo hq$remove() #\u0026gt; [1] 5 hq$show() #\u0026gt; Next item is at index 2  #\u0026gt; 1: 5 #\u0026gt; 2: 6 #\u0026gt; 3: foo hq$remove() #\u0026gt; [1] 6 亚类的方法可以称之为super$xx()，CountingQueue（接下来的例子）持续计算曾经加在queue里的object的总数，它覆盖了add()方法——它增加一个计数器，然后用超$add(x)调用超类的add()方法：\nCountingQueue \u0026lt;- R6Class(\u0026#34;CountingQueue\u0026#34;,  inherit = Queue,  public = list(  add = function(x) {  private$total \u0026lt;- private$total + 1  super$add(x)  },  get_total = function() private$total  ),  private = list(  total = 0  ) )  cq \u0026lt;- CountingQueue$new(\u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;) cq$get_total() #\u0026gt; [1] 2 cq$add(\u0026#34;z\u0026#34;) cq$remove() #\u0026gt; [1] \u0026#34;x\u0026#34; cq$remove() #\u0026gt; [1] \u0026#34;y\u0026#34; cq$get_total() #\u0026gt; [1] 3 2.5 包括参考object的field 如果你的R6类包含任何具有引用语义的字段(例如，其他R6对象，环境)，这些字段应该在initialize方法中填充。如果该字段在类定义中直接设置为引用对象，则该对象将在R6对象的所有实例中共享。这里有一个例子:\nSimpleClass \u0026lt;- R6Class(\u0026#34;SimpleClass\u0026#34;,  public = list(x = NULL) )  SharedField \u0026lt;- R6Class(\u0026#34;SharedField\u0026#34;,  public = list(  e = SimpleClass$new()  ) )  s1 \u0026lt;- SharedField$new() s1$e$x \u0026lt;- 1  s2 \u0026lt;- SharedField$new() s2$e$x \u0026lt;- 2  # 改变 s2$e$x 也会改变 s1$e$x 的值 s1$e$x #\u0026gt; [1] 2 为了避免上面出现的同时改变的情况，请填充initialize方法中的字段:\nNonSharedField \u0026lt;- R6Class(\u0026#34;NonSharedField\u0026#34;,  public = list(  e = NULL,  initialize = function() self$e \u0026lt;- SimpleClass$new()  ) )  n1 \u0026lt;- NonSharedField$new() n1$e$x \u0026lt;- 1  n2 \u0026lt;- NonSharedField$new() n2$e$x \u0026lt;- 2  # n2$e$x 不会影响 n1$e$x 的值 n1$e$x #\u0026gt; [1] 1 2.6 在已有的类中添加成员 在已有的类中添加成员是一个很有用的操作，可以在generator对象中使用$set()方法来完成。\nSimple \u0026lt;- R6Class(\u0026#34;Simple\u0026#34;,  public = list(  x = 1,  getx = function() self$x  ) )  Simple$set(\u0026#34;public\u0026#34;, \u0026#34;getx2\u0026#34;, function() self$x*2)  # To replace an existing member, use overwrite=TRUE Simple$set(\u0026#34;public\u0026#34;, \u0026#34;x\u0026#34;, 10, overwrite = TRUE)  s \u0026lt;- Simple$new() s$x #\u0026gt; [1] 10 s$getx2() #\u0026gt; [1] 20 $set()中第一个输入表示public的成员，第二个输入表示新增加的函数名称/成员为x，第三个是增加的函数/用新的值覆盖原先的x值。为了防止修改类，可以在创建类时使用lock_class=TRUE。也可以按照如下方式锁定和解锁一个类:\n# Create a locked class Simple \u0026lt;- R6Class(\u0026#34;Simple\u0026#34;,  public = list(  x = 1,  getx = function() self$x  ),  lock_class = TRUE )  # This would result in an error # Simple$set(\u0026#34;public\u0026#34;, \u0026#34;y\u0026#34;, 2)  # Unlock the class Simple$unlock()  # Now it works Simple$set(\u0026#34;public\u0026#34;, \u0026#34;y\u0026#34;, 2)  # Lock the class again Simple$lock() 2.7 克隆对象 默认的，R6对象存在clone方法来克隆对象。\nSimple \u0026lt;- R6Class(\u0026#34;Simple\u0026#34;,  public = list(  x = 1,  getx = function() self$x  ) )  s \u0026lt;- Simple$new()  # Create a clone s1 \u0026lt;- s$clone() # Modify it s1$x \u0026lt;- 2 s1$getx() #\u0026gt; [1] 2  # Original is unaffected by changes to the clone s$getx() #\u0026gt; [1] 1 如果不希望添加克隆方法，可以在创建类时使用cloneable=FALSE。如果任何加载的R6对象有一个克隆方法，该函数将使用83,552字节，但是对于每个额外的对象，克隆方法只消耗少量的空间(112字节)。\n2.8 深层克隆 如果有任何字段是具有引用语义的对象(environments、R6对象、引用类对象)，则副本将获得对同一对象的引用。这有时是可取的，但通常不是。\n例如，我们将创建一个对象c1，其中包含另一个R6对象s，然后克隆它。因为原始的和克隆的s字段都指向同一个对象，所以从一个字段修改它会导致另一个字段的变化。\nSimple \u0026lt;- R6Class(\u0026#34;Simple\u0026#34;, public = list(x = 1))  Cloneable \u0026lt;- R6Class(\u0026#34;Cloneable\u0026#34;,  public = list(  s = NULL,  initialize = function() self$s \u0026lt;- Simple$new()  ) )  c1 \u0026lt;- Cloneable$new() c2 \u0026lt;- c1$clone()  # Change c1\u0026#39;s `s` field c1$s$x \u0026lt;- 2  # c2\u0026#39;s `s` is the same object, so it reflects the change c2$s$x #\u0026gt; [1] 2 可以发现更改c1后c2也同时发生了改变，我们可以使用deep=TRUE选项来让克隆对象接收到s的拷贝:\nc3 \u0026lt;- c1$clone(deep = TRUE)  # Change c1\u0026#39;s `s` field c1$s$x \u0026lt;- 3  # c2\u0026#39;s `s` is different c3$s$x #\u0026gt; [1] 2 此时c3并不会改变，克隆的默认行为(deep=TRUE)是复制R6对象的字段，但不复制环境、引用类对象或其他包含其他引用类型对象的数据结构(例如，带有R6对象的列表)的字段。\n如果R6对象包含这些类型的对象，并且希望对它们进行深度克隆，则必须在名为deep_clone的私有方法中提供用于深度克隆的自己的函数。下面是一个R6对象的例子，它有两个字段，a和b，都是环境，都包含一个值x。它还有一个字段v，它是一个常规(非引用)值，和一个私有的deep_clone方法。\nCloneEnv \u0026lt;- R6Class(\u0026#34;CloneEnv\u0026#34;,  public = list(  a = NULL,  b = NULL,  v = 1,  initialize = function() {  self$a \u0026lt;- new.env(parent = emptyenv())  self$b \u0026lt;- new.env(parent = emptyenv())  self$a$x \u0026lt;- 1  self$b$x \u0026lt;- 1  }  ),  private = list(  deep_clone = function(name, value) {  # With x$clone(deep=TRUE) is called, the deep_clone gets invoked once for  # each field, with the name and value.  if (name == \u0026#34;a\u0026#34;) {  # `a` is an environment, so use this quick way of copying  list2env(as.list.environment(value, all.names = TRUE),  parent = emptyenv())  } else {  # For all other fields, just return the value  value  }  }  ) )  c1 \u0026lt;- CloneEnv$new() c2 \u0026lt;- c1$clone(deep = TRUE) 当c1$clone(deep=TRUE)被调用时，c1中的每个字段都会被调用deep_clone方法，并传递字段的名称和值。在我们的版本中，a环境被复制，但b没有，v也没有(但这没关系，因为v不是一个引用对象)。我们可以测试克隆:\n# Modifying c1$a doesn\u0026#39;t affect c2$a, because they\u0026#39;re separate objects c1$a$x \u0026lt;- 2 c2$a$x #\u0026gt; [1] 1  # Modifying c1$b does affect c2$b, because they\u0026#39;re the same object c1$b$x \u0026lt;- 3 c2$b$x #\u0026gt; [1] 3  # Modifying c1$v doesn\u0026#39;t affect c2$v, because they\u0026#39;re not reference objects c1$v \u0026lt;- 4 c2$v #\u0026gt; [1] 1 在上面的deep_clone方法示例中，我们检查了每个字段的名称，以确定如何处理它，但我们也可以通过使用继承(value，“R6”)或is.environment()等来检查值。\n2.9 在环境中打印R6对象 R6对象有一个默认的打印方法，该方法列出了对象的所有成员。如果类定义了打印方法，那么它将覆盖默认方法。\nPrettyCountingQueue \u0026lt;- R6Class(\u0026#34;PrettyCountingQueue\u0026#34;,  inherit = CountingQueue,  public = list(  print = function(...) {  cat(\u0026#34;\u0026lt;PrettyCountingQueue\u0026gt; of \u0026#34;, self$get_total(), \u0026#34; elements\\n\u0026#34;, sep = \u0026#34;\u0026#34;)  }  ) ) pq \u0026lt;- PrettyCountingQueue$new(1, 2, \u0026#34;foobar\u0026#34;) pq #\u0026gt; \u0026lt;PrettyCountingQueue\u0026gt; of 3 elements 2.10 终结器 有时候，在对象被垃圾回收时运行一个函数是很有用的。例如，您可能希望确保关闭文件或数据库连接。为此，您可以定义一个私有finalize()方法，当对象被垃圾收集时，将不带参数调用该方法。\nA \u0026lt;- R6Class(\u0026#34;A\u0026#34;, private = list(  finalize = function() {  print(\u0026#34;Finalizer has been called!\u0026#34;)  } ))  # Instantiate an object: obj \u0026lt;- A$new()  # Remove the single existing reference to it, and force garbage collection # (normally garbage collection will happen automatically from time # to time) rm(obj); gc() #\u0026gt; [1] \u0026#34;Finalizer has been called!\u0026#34; #\u0026gt; used (Mb) gc trigger (Mb) max used (Mb) #\u0026gt; Ncells 678820 36.3 1349101 72.1 1349101 72.1 #\u0026gt; Vcells 1273761 9.8 8388608 64.0 3247078 24.8 2.11 类方法和成员函数 当R6类定义包含函数时，这些函数都是class方法：可以通过self来调用，当R6对象被拷贝时，最终的对象将会有一个self来指代新的对象，这是通过改变克隆对象中方法的封闭环境来实现的。\n相比较class method，我们可以在R6对象中添加常规的函数做为成员，可以通过在initialize方法中把方法分配到filed，或者在对象被实例化之后，这些函数不是class methodm，也无法通过self，private或super来接触到。\n下面是一个简单的类，它有一个方法get_self()，它只返回self，还有一个空成员fn。在这个例子中，我们将赋予fn一个函数，它具有与get_self相同的函数体。然而，由于它是一个常规函数，self将引用R6对象以外的东西:\nFunctionWrapper \u0026lt;- R6Class(\u0026#34;FunctionWrapper\u0026#34;,  public = list(  get_self = function() {  self  },  fn = NULL  ) )  a \u0026lt;- FunctionWrapper$new()  # Create a function that accesses a variable named `self`. # Note that `self` in this function\u0026#39;s scope refers to 100, not to the R6 object. self \u0026lt;- 100 a$fn \u0026lt;- function() {  self }  a$get_self() #\u0026gt; \u0026lt;FunctionWrapper\u0026gt; #\u0026gt; Public: #\u0026gt; clone: function (deep = FALSE) #\u0026gt; fn: function () #\u0026gt; get_self: function ()  a$fn() #\u0026gt; [1] 100 从R6 2.3.0开始，如果对象被克隆，成员(非方法)函数的外部环境将不会改变，这是人们通常所期望的。它会这样表现:\nb \u0026lt;- a$clone()  b$get_self() #\u0026gt; \u0026lt;FunctionWrapper\u0026gt; #\u0026gt; Public: #\u0026gt; clone: function (deep = FALSE) #\u0026gt; fn: function () #\u0026gt; get_self: function ()  b$fn() #\u0026gt; [1] 100 3. S3 参考资料：   2分钟让你明白什么是面向对象编程\n  mlr3 book\n  ","date":"February 24, 2022","image":null,"permalink":"/post/2022-2-24_mlr31/","title":"R包mlr3基本功能【1】——R6类——需要修订"},{"categories":["R"],"contents":"R包功能的实现需要各种函数，函数应该如何编写？什么样的步骤可以被包括在函数里？函数需要哪些基本的功能？函数应该如何命名？函数可以通过调用函数并且给定参数来代替对代码的重复操作（当一个操作需要重复2次时），通过自定义的函数命名来使得功能易懂，并且方便后续的更新和更改，对功能进行更改只需要变更函数，而非在所有的代码中一一修改。\n1. 基本步骤 写函数的基本步骤如下：\n1.1 函数命名   命名要尽量短，而且指示函数的功能，长一点能够清楚的展示功能也无妨。\n  函数名尽可能是动词，不过相比使用get、compute、calculate、 determine这样宽泛的动词来说，名词相对更好，函数的参数尽可能是名词。想到好的名字随时去更改掉它。\n  当函数名包含很多单词时，可以统一选取一种使用，可以使用snake_case，或者camelCase的形式，两者不要混着用。\n  同类的功能名称保持一定的一致性。\n  # Good input_select() input_checkbox() input_text()  # Not so good select_input() checkbox_input()   尽量避免和已有的函数名称重复，尤其是基本包里的。\n  习惯使用注释把文件分割，快捷键是：cmd/ctrl + shift + R\n  # Load data --------------------------------------  # Plot data -------------------------------------- 1.2 列出输入数据或参数 1.3 函数内部功能 我觉得还需要加上一个步骤就是，确定函数的输出是什么。写完函数还需要对函数进行交互式测试，参考这本书的测试章节。通过下面的简化过程比较容易理解：\n初始未简化：\ndf \u0026lt;- tibble::tibble(  a = rnorm(10),  b = rnorm(10),  c = rnorm(10),  d = rnorm(10) )  df$a \u0026lt;- (df$a - min(df$a, na.rm = TRUE)) /  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE)) df$b \u0026lt;- (df$b - min(df$b, na.rm = TRUE)) /  (max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE)) df$c \u0026lt;- (df$c - min(df$c, na.rm = TRUE)) /  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE)) df$d \u0026lt;- (df$d - min(df$d, na.rm = TRUE)) /  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE)) 编写函数进行简化：\nrescale01 \u0026lt;- function(x) {  rng \u0026lt;- range(x, na.rm = TRUE)  (x - rng[1]) / (rng[2] - rng[1]) }  df$a \u0026lt;- rescale01(df$a) df$b \u0026lt;- rescale01(df$b) df$c \u0026lt;- rescale01(df$c) df$d \u0026lt;- rescale01(df$d) 目前仍存在重复的步骤，可以通过向量和迭代的使用来简化，并进一步修改函数：\nx \u0026lt;- c(1:10, Inf)  rescale01 \u0026lt;- function(x) {  rng \u0026lt;- range(x, na.rm = TRUE, finite = TRUE)  (x - rng[1]) / (rng[2] - rng[1]) } rescale01(x) #\u0026gt; [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667 #\u0026gt; [8] 0.7777778 0.8888889 1.0000000 Inf 1.4 返回值  函数返回值的位置  函数默认返回最后一步的状态值，但是可以在运行过程中return()来返回目标数值，比如input是空的情况下，可以立刻返回0等等，另外一种情况是：\nf \u0026lt;- function(){  if (x){  # complicated condition  }else{  # simple result  } } 当各种条件不能够满足，应该把简单的结果摆在前面提前返回值，就不需要做那么多的条件判断。\n 可管道操作的函数  最基础的两个管道函数类型是：transformation和side-effect，前者将对象传递给函数的第一个参数，并返回修改后的对象，后者传递的对象不会被转换，该函数对对象执行一个操作，后者不可见的返回第一个参数，这样即使没有输出也可以在管道中使用。举个例子：\nshow_missings \u0026lt;- function(df) {  n \u0026lt;- sum(is.na(df))  cat(\u0026#34;Missing values: \u0026#34;, n, \u0026#34;\\n\u0026#34;, sep = \u0026#34;\u0026#34;)   invisible(df) }  show_missings(mtcars) #\u0026gt; Missing values: 0  x \u0026lt;- show_missings(mtcars) #\u0026gt; Missing values: 0 class(x) #\u0026gt; [1] \u0026#34;data.frame\u0026#34; dim(x) #\u0026gt; [1] 32 11  mtcars %\u0026gt;%  show_missings() %\u0026gt;%  mutate(mpg = ifelse(mpg \u0026lt; 20, NA, mpg)) %\u0026gt;%  show_missings() #\u0026gt; Missing values: 0 #\u0026gt; Missing values: 18 2. 具体细节 2.1 条件执行   条件必须是逻辑值，如果是向量，需要给出warning，如果是NA，需要报错。\n  可以使用||和\u0026amp;\u0026amp;组合多个逻辑表达式，不要在if语句中使用|或\u0026amp;，这些是适用于多个值的向量化操作，如果确实存在逻辑向量的话，可以使用any或者all来将其折叠为单个值。==也是向量化的，容易得到多个输出，要么检查长度为1，使用all或any折叠，要么使用非向量化的identical，identical非常严格，总是返回单个的TRUE或这单个的FALSE，并且不强制类型，因此在比较整数和双精度浮点数时要小心。\n  identical(0L, 0) #\u0026gt; [1] FALSE  x \u0026lt;- sqrt(2) ^ 2 x #\u0026gt; [1] 2 x == 2 #\u0026gt; [1] FALSE x - 2 #\u0026gt; [1] 4.440892e-16 上述可以使用dplyr::near()进行比较，x == NA没有任何用。\n 多个条件时，当条件很多不停的写if的时候，最好重新写，可以使用switch()，能够根据位置或者名称来计算所选的代码（？？？），以及cut()函数来消除if语句的长度，可以用于离散的变量。  2.2 代码风格 多行输写除非很短。\n2.3 函数参数   参数分为两个部分，一个是支持什么样的数据，另外一个是计算的细节。后者通常会有最常使用的默认值。\n  参数的命名\n  参数的命名也很重要，命名较长且应该尽量详细，常用命名如下：\n  x,y,z：向量\n  w：向量的权重\n  df：数据框\n  i,j：行或者列的数字指标\n  n：行的长度或行的个数\n  p：列的个数\n  2.4 检查数值 当写了很多函数的时候，很容易因为忘记函数的使用方法而用无效的输入来调用函数。需要使用提示语句来对输入进行约束。只在关键的几个地方写就可以了，没必要检查每一个，好的举例：\nwt_mean \u0026lt;- function(x, w) {  if (length(x) != length(w)) {  stop(\u0026#34;`x` and `w` must be the same length\u0026#34;, call. = FALSE)  }  sum(w * x) / sum(w) } 另外可以使用内置的stopifnot()来检查每个参数是否为TRUE，如果不是那么生成一个错误的消息。\nwt_mean \u0026lt;- function(x, w, na.rm = FALSE) {  stopifnot(is.logical(na.rm), length(na.rm) == 1)  stopifnot(length(x) == length(w))   if (na.rm) {  miss \u0026lt;- is.na(x) | is.na(w)  x \u0026lt;- x[!miss]  w \u0026lt;- w[!miss]  }  sum(w * x) / sum(w) } wt_mean(1:6, 6:1, na.rm = \u0026#34;foo\u0026#34;) #\u0026gt; Error in wt_mean(1:6, 6:1, na.rm = \u0026#34;foo\u0026#34;): is.logical(na.rm) is not TRUE 2.5 \u0026hellip; R里面的很多函数不限制输入的参数个数，\u0026hellip;可以捕捉任何就算没有匹配的参数，并且把这些参数传输到另外的函数中使用，尤其适用一个函数包装另外一个函数的情况，缺点是不会对拼写错误的参数报错。\ncommas \u0026lt;- function(...) stringr::str_c(..., collapse = \u0026#34;, \u0026#34;) commas(letters[1:10]) #\u0026gt; [1] \u0026#34;a, b, c, d, e, f, g, h, i, j\u0026#34; 想要捕捉\u0026hellip;的数值，可以使用list(\u0026hellip;)\n2.6 lazy evaluation R中的参数是延迟计算的：直到被需要才会计算，如果使用不到那么不会调用，这是R编程的一个重要属性。\n参考资料：  r4ds  ","date":"February 23, 2022","image":null,"permalink":"/post/2022-2-23_function/","title":"R包开发【2】——编写函数"},{"categories":["R"],"contents":"R包开发的各种细节。\n1. 命名   尽量避免同时使用大小写字母\n  使用该包测试命名是否能用（？？？）。\n  library(available)  available(\u0026#34;doofus\u0026#34;) 2. 依赖包 如果只是使用其他的包中的少量函数时，建议在DESCRIPTION文件中的Imports:中标注包的名称，并且在使用函数过程中使用pkg::fun()。如果需要重复使用函数，可以避免繁琐的::可以@importFrom pkg fun，这样可以更快速，因为::增加了5us去使用函数，管道符号也可以使用同样的方法使用@importFrom magrittr %\u0026gt;%。如果重复使用很多其他包中的函数，可以把这个包中所有的函数全部导入@import pkg，不过这样会使得包的代码比较不容易阅读。\nImports部分并不是把function导入到namespace中，它只确保包的安装。无论是否附加包，您都需要以完全相同的方式导入函数。\n在DESCRIPTION中对依赖包进行注释：\nImports:  randomForest,  stats 在函数中使用依赖包中的函数时，需要标注pkg::fun。\n 是在roxygen注释中添加@import pkg。这种方法会在R包的NAMESPACE文件中添加import域，在加载R包时，第三方包的所有函数都会被导入。在使用函数时必须用pkg::fun的方法，以防函数名冲突。第二种方法，是在roxygen注释中添加@importFrom pkg fun。这种方法会在NAMESPACE文件中添加importFrom域，在使用时可以直接使用函数名，就像在.GlobalEnv中创建的函数一样。这里推荐第二种引用方法，因为可以大幅减少函数冲突。\n check之后存在warning：\n\u0026gt; checking dependencies in R code ... WARNING  \u0026#39;::\u0026#39; or \u0026#39;:::\u0026#39; imports not declared from:  ‘cli’ ‘dplyr’ ‘furrr’ ‘future’ ‘purrr’ ‘tibble’ 它说的是:\u0026rsquo;::\u0026lsquo;或\u0026rsquo;:::\u0026rsquo; import没有从‘cli’ ‘dplyr’ ‘furrr’ ‘future’ ‘purrr’ ‘tibble’中声明。这里重要的词是“import”。就像我们在包中导出函数一样，我们需要明确何时在另一个包中使用函数。为此，我们可以使用usethis::use_package()。\nusethis::use_package(\u0026#34;cli\u0026#34;) no visible global function definition for ‘:=’\nmagrittr Consider adding importFrom(\u0026ldquo;stats\u0026rdquo;, \u0026ldquo;end\u0026rdquo;, \u0026ldquo;setNames\u0026rdquo;, \u0026ldquo;start\u0026rdquo;) to your NAMESPACE file.\n为了export对象，需要把@export放在roxygen block中，比如：\n#\u0026#39; @export foo \u0026lt;- function(x, y, z) {  ... } 这将根据对象的类型生成export()、exportMethods()、exportClass()或S3method()。export函数供其他人使用，export的函数必须文档化。\n现在有一种更简单的方法来支持包中的管道。奇妙的包usethis具有use_pipe()功能。你运行该功能一次，它处理一切。这就是use_pipe()文档中描述的usethis函数：\n是否需要在包内部使用magrittr的管道并为包的用户重新导出它：\n将magrittr添加到DESCRIPTION中的“Imports”\n使用必要的roxygen模板创建R / utils-pipe.R\nuse_pipe() 2.1 包中具体函数的依赖 2.2 一个包中所有函数的依赖 3. 如何在R包中内置数据 这部分内容主要参考r-pkg-data。\n目前有三种主要的方法来放置数据：\n  储存二进制数据方便用户使用：将数据存储在data/目录下，这是存储示例数据最好的地方。\n  存储解析数据但不提供给用户使用：将数据存储在R/sysdata.rda中，这是存储函数所需数据最好的地方。【什么时解析数据】\n  存储原始数据：将数据存储在inst/extdata中。\n  这三个选项的一个简单替代方案是将它包含在包的源代码中，可以手工创建，也可以使用dput()将现有的数据集序列化到R代码中。\n3.1 导出数据 最常用的存储数据的目录是data/，该目录下的数据都应该是通过save得到的格式为.RData的数据（可以使用其他的格式，但是RData的格式是最快，最省空间，最直接的【为什么，可以单独写一下RData的存储】），对于较大的数据集，可以对数据进行压缩，默认值是bzip2，但有时gzip或xz可以创建更小的文件。数据可以使用use_data来创建：\nx \u0026lt;- sample(1000) usethis::use_data(x, mtcars) 如果DESCRIPTION中LazyData的设置是true，当载入包时会lazily loaded这种数据，除非我们对其进行使用，否则不会占用空间：\npryr::mem_used() #\u0026gt; 50.2 MB library(nycflights13) pryr::mem_used() #\u0026gt; 58 MB  invisible(flights) pryr::mem_used() #\u0026gt; 98.7 MB 通常在data/中的数据是开发者从其他地方收集的原始数据的清洗版本。建议在包的源版本中包含处理数据的代码，这样更容易更新或复制数据的版本，处理数据的代码放入data-raw/中，不需要在包的捆绑版本中使用它，所以也要将它添加到.rbuildignore中。用一个步骤做到这一切:\nusethis::use_data_raw() 3.2 文档数据 文档数据类似于对函数进行文档化【？】，把数据存储在R中，举例，roxygen2封装ggplot2中的diamond数据，存储为R/data.R：\n#\u0026#39; Prices of 50,000 round cut diamonds. #\u0026#39; #\u0026#39; A dataset containing the prices and other attributes of almost 54,000 #\u0026#39; diamonds. #\u0026#39; #\u0026#39; @format A data frame with 53940 rows and 10 variables: #\u0026#39; \\describe{ #\u0026#39; \\item{price}{price, in US dollars} #\u0026#39; \\item{carat}{weight of the diamond, in carats} #\u0026#39; ... #\u0026#39; } #\u0026#39; @source \\url{http://www.diamondse.info/} \u0026#34;diamonds\u0026#34; 在编写数据文档中有两个另外的标签非常重要：\n  @format给出了数据集的全貌，对于数据框，应该给出每个变量的描述。\n  @source提供了数据的来源细节，通常是一个\\url{}\n  3.3 内部数据 有些函数需要预先处理过的数据，如果把这些数据放在data/中，用户仍然可以使用，这点不太合适。可以将这些数据存储在R/sysdata.rda，可以使用usethis::use_data()，使用参数internal = TRUE来创建这些文件：\nx \u0026lt;- sample(1000) usethis::use_data(x, mtcars, internal = TRUE) R/sysdata.rda的对象不会输出(export)，因此不需要文档化，只有在包中才可以获取。\n如何载入/使用内部数据？\n3.4 原始数据 想要展示载入或解析原始数据的例子时，把原始文件放在inst/extdata中，当安装包时，所有在inst/目录下的文件以及文件夹都被提升到上一级目录中，因此不能够命名为R/或DESCRIPTION，要引用inst/extdata中的文件(无论是否安装)，请使用system.file()。举个例子：readr包使用inst/extdata来存储带分隔符的文件，如下所示:\nsystem.file(\u0026#34;extdata\u0026#34;, \u0026#34;mtcars.csv\u0026#34;, package = \u0026#34;readr\u0026#34;) #\u0026gt; [1] \u0026#34;/home/runner/work/_temp/Library/readr/extdata/mtcars.csv\u0026#34; 注意:默认情况下，如果文件不存在，system.file()不会返回错误——它只返回空字符串:\nsystem.file(\u0026#34;extdata\u0026#34;, \u0026#34;iris.csv\u0026#34;, package = \u0026#34;readr\u0026#34;) #\u0026gt; [1] \u0026#34;\u0026#34; 如果你想在文件不存在的时候有一个错误消息，添加参数mustWork = TRUE:\nsystem.file(\u0026#34;extdata\u0026#34;, \u0026#34;iris.csv\u0026#34;, package = \u0026#34;readr\u0026#34;, mustWork = TRUE) #\u0026gt; Error in system.file(\u0026#34;extdata\u0026#34;, \u0026#34;iris.csv\u0026#34;, package = \u0026#34;readr\u0026#34;, mustWork = TRUE): no file found 3.5 其他的数据   用来测试的数据：可以将小的数据直接放在test目录下，但是请记住，单元测试是为了测试正确性，而不是性能，所以请使用小的数据。\n  数据片段：如果想展示如何处理已载入的数据集，请将该数据放在data/中。如果您想演示如何加载原始数据，请将该数据放在inst/extdata中。\n  3.6 CRAN 笔记 通常，包中数据应该小于1Mb——如果大于1Mb，则需要争取豁免。如果数据在自己的包中，并且不会频繁更新，那么这通常更容易做到。你还应该确保数据已被最佳压缩:\n  使用tools::checkRdaFiles()来确定每个文件最佳的压缩\n  重新使用usethis::use_data()，并设置compress到合适的大小，如果丢失了重新创建文件的代码，可以使用tools::resaveRdaFiles()来重新保存。\n  4. 如何在函数中调用Python或MATLAB？ 5. 如何制作R包的图标（LOGO） 使用这个包能够生成R包六边形LOGO，函数sticker的输出是一个ggplot的对象，filename参数是自定义输出的图标图片名称，使用plot(object)可以直接查看图标。\ninstall.packages(\u0026#34;hexSticker\u0026#34;) library(hexSticker) 实例：\nlibrary(ggplot2)  p \u0026lt;- ggplot(aes(x = mpg, y = wt), data = mtcars) + geom_point() p \u0026lt;- p + theme_void() + theme_transparent()  sticker(p, package=\u0026#34;hexSticker\u0026#34;, p_size=20, s_x=1, s_y=.75, s_width=1.3, s_height=1,  filename=\u0026#34;inst/figures/ggplot2.png\u0026#34;) 参数：\n  p可以是自己生成的图片，也可以是ggplot绘制图的对象\n  p_size：字体大小\n  s_x、s_y：图片在图中的位置\n  6. 如何给包写说明书 参考资料：   r4ds\n  R：在自编写的包中使用magrittr管道运算符\n  ","date":"February 23, 2022","image":null,"permalink":"/post/2022-2-23_rpkg2/","title":"R包开发【3】——R包开发细节"},{"categories":["R"],"contents":"任何可以被自动化的，都应该让它自动化，给自己省时间，也可以方便任何人使用。devtools的目的是使得开发工具变得容易，囊括了多个包来支持开发的各个功能。\n前言：R包开发书籍的基本内容   第二章 示例包\n  第三章 为包开发准备系统\n  第四章 包的基本结构，不同的状态下结构不同（？）\n  第五章 回顾核心的工作流程，介绍核心工具之间的联系：devtools和usethis，Rstudio\n  其余章节 开发细节\n  通过示例入门 1. 在制定路径下新建R包，创建了新的项目 先安装一些包\ninstall.packages(c(\u0026#34;devtools\u0026#34;, \u0026#34;roxygen2\u0026#34;, \u0026#34;testthat\u0026#34;, \u0026#34;knitr\u0026#34;)) library(usethis) create_package(\u0026#34;/Volumes/home /project/Immarker\u0026#34;) 目录下有这些文件\n    .Rbuildignore\n  .Rproj.user\n  DESCRIPTION 文档说明\n  NAMESPACE 列出了外部和内部使用到的函数\n  The R/ directory\n  Immarker.Rproj 不使用Rstudio的话这个可以在创建时，使用参数rstudio = FALSE去除\n  如果使用者经常创建包，那么可以通过usethis.description来设定一些全局变量使得每次新建包时，DESCRIPTION的值是默认的（比如姓名、邮箱以及许可证等等），详细说明见usethis设置，DESCRIPTION的文件格式是DCF(Debian control format)，每行由一个字段名和一个值组成，用冒号分隔。当值跨多行时，需要缩进。\n2. 目前创建的目录是一个R包以及RStudio的项目，现在我们再将其增添为Git仓库。 library(devtools) use_git() 3. 写第一个函数 根据自己的需求写函数，这本书不涉及到函数应该如何写，但是可以参考Functions chapter of R for Data Science and the Functions chapter of Advanced R.\n举个例子：\nstrsplit1 \u0026lt;- function(x, split) {  strsplit(x, split = split)[[1]] } 4. 定义R函数 把R函数保存在R文件中，存放在R目录下。\n\u0026gt; use_r(\u0026#34;strsplit1\u0026#34;) ✓ Setting active project to \u0026#39;/Volumes/home /project/Immarker\u0026#39; • Modify \u0026#39;R/strsplit1.R\u0026#39; • Call `use_test()` to create a matching test file 只在这个文件中写入函数的function，不能包含任何library(devtools)，x，use_git()等其他，R包依赖的函数会在后面详细说明。\n5. 测试函数功能 先使用load_all让函数能够被测试，load_all能够模拟构建、安装和载入我们创建的R包的过程，而且load_all比实际的这个过程迭代速度更快。\nload_all() 测试函数功能\n(x \u0026lt;- \u0026#34;alfa,bravo,charlie,delta\u0026#34;) #\u0026gt; [1] \u0026#34;alfa,bravo,charlie,delta\u0026#34; strsplit1(x, split = \u0026#34;,\u0026#34;) #\u0026gt; [1] \u0026#34;alfa\u0026#34; \u0026#34;bravo\u0026#34; \u0026#34;charlie\u0026#34; \u0026#34;delta\u0026#34; 该函数能够运行，不过它并不在全局的环境中存在。\nexists(\u0026#34;strsplit1\u0026#34;, where = globalenv(), inherits = FALSE) #\u0026gt; [1] FALSE 6. commit该函数 如果使用Git，可以使用自己熟悉的方法把新的R函数commit上去。记得规范化commit的message。 Angular 提交信息规范\n7. 检查 检查所建R包的是否能够正常运行。check的时间一般比较久，但是check是一个好习惯。\ncheck() 处理check输出的结果。\n0 errors ✔ | 1 warning ✖ | 0 notes ✔ 8. 编辑对包的描述DESCRIPTION文件 修改包的作者为自己的名字或ORCID号，\n第八章会详细描述。文件内容看上去类似下面的形式：\nPackage: regexcite Title: Make Regular Expressions More Exciting Version: 0.0.0.9000 Authors@R:  person(\u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;, , \u0026#34;jane@example.com\u0026#34;, role = c(\u0026#34;aut\u0026#34;, \u0026#34;cre\u0026#34;)) Description: Convenience functions to make some common tasks with string  manipulation and regular expressions a bit easier. License: `use_mit_license()`, `use_gpl3_license()` or friends to pick a  license Encoding: UTF-8 Roxygen: list(markdown = TRUE) RoxygenNote: 7.1.2 9. 设置license 任意选择一个license，默认的似乎是MIT的。\nuse_mit_license() 10. 函数使用文档 在原文件中开发者对函数进行特殊格式的注释，并使用roxygen2包处理函数注释文档man/strsplit1.Rd的建立。关于这个包的具体使用在第十章有描述。使用RStudio可以直接打开函数R文件，每一行的开头为#'，不使用RStudio时，可以自己写comment。\n把光标放在函数内部(必须是括号内部！这样才能确定注释的是哪个函数)，使用快捷键ctrl+alt+shift+R，会在函数的开头自动生成注释文档的格式如下：\n#\u0026#39; Title #\u0026#39; #\u0026#39; @param x #\u0026#39; @param split #\u0026#39; #\u0026#39; @return #\u0026#39; @export #\u0026#39; #\u0026#39; @examples strsplit1 \u0026lt;- function(x, split) {  strsplit(x, split = split)[[1]] } 随后使用document将注释转化为函数的Rd文档，并保存在man文件夹下：\ndocument() 此时可以使用?strsplit1来预览函数的帮助文档。在正式构建和安装包之前，不会正确连接包的文档。这消除了帮助文件之间的链接和包索引的创建等细节。\n另外，document还基于@export更新了NAMESPACE文件，这个文件是只读模式不能够进行更改的，NAMESPACE的文档内容如下：\n# Generated by roxygen2: do not edit by hand  export(strsplit1) export意味着使用者可以通过载入该包来使用这个函数。\n11. 再次check() 12. 安装该包 install() 安装完之后就可以和其他包一样的使用了，可以restart R然后重新载入该包。\n参考资料  rpkg  ","date":"February 22, 2022","image":null,"permalink":"/post/2022-2-22_rpkg/","title":"R包开发【1】——基本流程"},{"categories":["R"],"contents":"基本内容   Excel文件的读入\n  txt和csv文件的读入\n  文件的写出\n  批量读入数据并合并\n  RData和rds的储存形式\n  read.csv和read.csv2的区别\n  Excel文件的读入 在R语言实战实战这本书中表示，读取Excel文件最好的方式，是在Excel中将其导出为一个逗号分隔文件（csv），并使用读取csv的方法读取数据。或者采用xlsx包直接读取数据。xlsx包可以用来对Exceln97/2000/XP/2003/2007文件进行读取、写入和格式转换。还可以使用readxl包来读取Excel的.xls和.xlsx文件。\nread_xlsx(path, sheet = NULL, range = NULL, col_names = TRUE,  col_types = NULL, na = \u0026#34;\u0026#34;, trim_ws = TRUE, skip = 0,  n_max = Inf, guess_max = min(1000, n_max),  progress = readxl_progress(), .name_repair = \u0026#34;unique\u0026#34;) read.xlsx(  xlsxFile,  sheet = 1,  startRow = 1,  colNames = TRUE,  rowNames = FALSE,  detectDates = FALSE,  skipEmptyRows = TRUE,  skipEmptyCols = TRUE,  rows = NULL,  cols = NULL,  check.names = FALSE,  sep.names = \u0026#34;.\u0026#34;,  namedRegion = NULL,  na.strings = \u0026#34;NA\u0026#34;,  fillMergedCells = FALSE ) 参数：\n sheet  Excel表格含有多个表格，读取其中一个表格\n startRow  Excel表格选取部分行进行读取\n  Excel表格\n  .name.repair：是对列名进行更改，默认情况下，确保的列名是非空且特殊的即\u0026quot;unique\u0026quot;，该参数可以输入toupper——将列名变成大写字母，该参数可以输入universal——将列名中空格部分用\u0026rsquo;.\u0026lsquo;代替，也可以指定为自定义函数或其他函数，对列名进行更改。\n  示例： death.xlsx通过Excel打开如下：\n death.xlsx文件\n death.xlsx有两个子表格，且真正需要的部分是A5:F15的部分，在不想修改原始文件的情况下，读入时使用.来代替空格，可通过以下代码进行读取：\n read_excel(  readxl_example(\u0026#34;deaths.xlsx\u0026#34;),  range = \u0026#34;arts!A5:F15\u0026#34;,  .name_repair = \u0026#34;universal\u0026#34;  )   New names: * `Has kids` -\u0026gt; Has.kids * `Date of birth` -\u0026gt; Date.of.birth * `Date of death` -\u0026gt; Date.of.death  创建模板\n 参考资料：  R语言实战（第2版）  ","date":"December 23, 2021","image":null,"permalink":"/post/2021-12-23_basic_r/","title":"R基础——读入和写出数据"},{"categories":["生信"],"contents":"背景介绍 1. 获取绝对拷贝数数值的难点 （1）采样过程中癌细胞混合了未知比例的正常细胞——肿瘤纯度；\n（2）由于染色体数量和结构异常导致的癌细胞的实际DNA含量(倍性)是未知的；\n（3）由于正在进行的亚克隆进化，癌细胞群可能是异质性的。\n理论上，如果知道每个肿瘤细胞中DNA的含量，则可通过测得的相对拷贝数获得绝对拷贝数，或者通过单细胞测序技术解决。\n2. 芯片原始原始数据格式.CEL 对于芯片数据来说，Affymetrix SNP芯片的原始文件为CEL文件，一个CEL文件即是一个个体的全部SNP分型结果。Affymetrix基因芯片是一种生物芯片，它包含一个对一个实验有效的微阵列。为了制造这些芯片，玻璃或硅载玻片上排列有探针，根据它们是否与原始DNA样本互补，探针将表达水平(强度)报告为完全匹配(PM)和不匹配(MM)值。.CEL文件格式有多个版本，使用不同的格式。例如，版本3使用ASCII文本格式，而版本4使用二进制格式。 注意：.CEL 文件需要相应的.CDF 文件，它是存储在.CEL文件中的原始探测级数据的字典。MATLAB有一个名为affyread的内置函数，可以用来读取Windows版本软件中的.CEL 文件。\n3. SNP6.0拷贝数变异检测流程 这里介绍Affymetrix SNP6 Copy Number Inference Pipeline。\n输入：CEL文件\n输出：每个样本的片段化的拷贝数结果：genotype calls；相对的拷贝数数值且经过标准化处理，使得每个样本接近双倍体；拷贝数变异区域\n流程：\n  校准信号强度\n  计算基因型\n  将信号强度转换为拷贝数数值\n  计算拷贝数噪音\n  移除离群的探针减少噪音\n  通过减去一组预先定义的正常样本中的变化，进一步降低噪声\n  将拷贝数片段化\n  计算基因组中片段的数量，并与定义的阈值进行比较，以检查超分割情况\n  工具介绍 1. ABSOLUTE 可以评估癌细胞的纯度和倍性，计算出绝对的拷贝数和突变倍数。\n输入数据：\n可以是HAPSEG，也可以是segmentation文件，前者需要安装HAPSEG包，后者segmentation文件来自芯片CGH或大量平行测序实验的结果，可以包含其他信息，但必须包含的信息有：\u0026ldquo;Chromosome\u0026rdquo;,\u0026ldquo;Start\u0026rdquo;,\u0026ldquo;End\u0026rdquo;,\u0026ldquo;Num_Probes\u0026rdquo;,\u0026ldquo;Segment_Mean\u0026rdquo;，该模式下需要将copy_num_type参数设定为total。\n（1）HAPSEG输入：HAPSEG是一种解释癌症样本中双等位基因标记数据的概率方法。HAPSEG的工作原理是将基因组划分为不同拷贝数的片段，并在每个片段中建模四个不同的基因型。\n（2）segmentation文件：测序的结果。\n输出数据：\n步骤：\n 使用ABSOLUTE分析肿瘤DNA\n ABSOLUTE是如何进行分割片段的？\n2. ACEseq 3. Battenberg 4. CloneHD 5. JaBbA 6. Sclust 直接通过新建R Markdown文件，选择posterdown模板则自动导入模板代码，如下：\n 创建模板\n 参考资料：   CEL是什么格式的文件\n  Dentro, Stefan C., et al. \u0026ldquo;Characterizing genetic intra-tumor heterogeneity across 2,658 human cancer genomes.\u0026rdquo; Cell 184.8 (2021): 2239-2254.\n  介绍了PCAWG中拷贝数数据的来源\n","date":"December 19, 2021","image":null,"permalink":"/post/2021-12-19_cnv_tools2/","title":"检测拷贝数变异的工具及算法【2】-ABSOLUTE"},{"categories":["生信"],"contents":"引言 PCAWG提供的拷贝数变异文件是综合6种不同的拷贝数变异提取工具的结果：\n  ABSOLUTE\n  ACEseq\n  Battenberg\n  CloneHD\n  JaBbA\n  Sclust\n  由于拷贝数结果的不同取决于segmentation的不同，而对大部分基因组的拷贝数状态的分歧来自于是否发生了整个基因组复制的分歧。因此针对6种方法中的5种首先构建了完整的断点数据，针对一致的断点数据使用6种方法得到拷贝数变异结果，解决了倍性结果的不统一后，对6种方法得到的每个segment寻求major allele和minor allele的状态的一致性，最后对每个肿瘤综合6种方法得到纯度结果，对每种方法都给予置信区间和质量星号：克隆性通过（3星），多数投票同意，协议后四舍五入亚克隆拷贝数（2星），调用最好的方法（1星）。3星代表结果非常一致，1星则是结果不那么一致的情况下选一种方法的结果输出。这样来得到最终的完整的拷贝数图谱，包含以下所有列：\nmajor_cn minor_cn position sampleID star total_cn value 工具介绍 1. ABSOLUTE 使用ABSOLUTE算法计算每个样本的纯度、倍性以及绝对DNA拷贝数，在基因组上收集基于片段的覆盖度(来自完整的阅读模板跨度)在基因组上收集，并校正GC含量和匹配偏差。【？】使用PCAWG的正常样本来进行切线归一化(tangent-normalization)处理。基于杂合性位点计算位点特异的拷贝数，使用CBS算法来得到segmentation。采用Nelder-Mead算法搜索可能的纯度和倍性解的空间，并对它们进行排序。对亚克隆拷贝数片段进行Dirichlet过程聚类，以标注相同的亚克隆拷贝数聚类状态。\n2. ACEseq 使用ACEseq计算绝对拷贝数，肿瘤纯度，并估计肿瘤细胞内容，通过结合肿瘤和基因组窗中匹配的正常基因的覆盖率以及相应SNPs的b等位基因频率(BAF)来确定绝对拷贝数。基因组使用PSBCBS包得到segmentation，在分割之前，结构变异断点通过一致的结构变异数据判断，\n利用PSCBS包将基因组分割为平等覆盖和不平衡状态的区域，在分割之前，将共识结构变异集定义的结构变异断点合并成片段边界，片段提交到共识断点估计集，通过共识断点得到的片段使用覆盖度和BAF值注释来估计样本的肿瘤细胞内容和倍性。\n注：配对的双亲特定CBS(配对的PSCBS)算法利用了CBS方法用于将总CN数据分割为来自SNP阵列的2D非阶段数据。该算法依赖于配对测试(肿瘤)和参考(正常)样本杂交到单独的阵列。\n3. Battenberg 使用Battenberg得到绝对拷贝数。针对每个SNP计算BAF和相对logR值，使用GC含量矫正logR值，匹配的正常样本用来获得种系的杂合性SNP，使用分段常数拟合(PCF)对数据进行分段，将结构变异(sv)作为先前建立的中断点，通过对纯度和倍性组合进行网格搜索，拟合克隆拷贝数图谱。\n4. CloneHD 使用CloneHD得到绝对拷贝数。cloneHD使用了隐马尔可夫模型来描述样本的拷贝数状态。cloneHD流程的第一步使用的是filterHD算法，filterHD不寻求解释数据中的亚克隆结构，是一种用于模糊分割的通用算法，是一个通用的一维离散数据概率滤波算法，类似于卡尔曼滤波。它是一个具有泊松或二项发射和跳跃扩散传播子的连续状态空间隐马尔可夫模型。它可以用于无标度平滑、模糊数据分割和数据滤波。\n5. JaBbA JaBbA整合paire-end和read depth信号来推断基因组间隔的拷贝数以及重构junction。在PCAWG共识拷贝数分析中，使用了两轮JaBbA，JbBbA的输入数据是bam文件，junction call set，以及初步分割（可选）和纯度/倍性输入，针对初步分割的结果，进一步使用CBS算法来分割得到低维度的常数拷贝数区域。\n6. Sclust 使用Sclust进行拷贝数分割，计算肿瘤纯度，肿瘤倍性以及位点特异的拷贝数（包含克隆性的和非克隆性的）。输入数据是肿瘤样本和匹配的正常样本的read counts。read counts后续用来计算肿瘤和正常样本的GC含量，接下来Sclust使用SNP数据，计算正常样本的杂合性位点的B位点频率，随后基于read ratio在数据中找到明显的跳跃来进行初次分割。\n共识拷贝数获取步骤 6种拷贝数检测的方法都使用了两步步骤：\n  第一步是把基因组分割为具有恒定拷贝状态的区域\n  第一步是确定每个片段的克隆和亚克隆拷贝数状态\n  6种方法产生的分歧结果主要是以下两个元素：\n  基因组分割的差异\n  是否发生了全基因组重复(WGD)的不确定性\n  共识拷贝数分割结果的分歧 拷贝数识别工具将一个样本的基因组分割成多个具有稳定拷贝数的区域，为了描述这些片段，需要找到片段之间的断点，断点两侧的拷贝数状态发生了变化，一旦建立起断点，不同的工具则确定每个片段内混合的拷贝数状态，包括主等位基因拷贝的数量，次等位基因拷贝的数量，以及处于这种状态的细胞的比例。\n不同的方法得到的断点有差别，有些方法调用的断点比其他方法多一个数量级。，为了解决不同方法考虑的基因组片段不同的问题，建立了共识断点集，所有的方法后续使用共识片段来判断拷贝数状态\n确定共识拷贝数片段断点的方法 创造了共识策略支持真正的断点，潜在的代价是增加假阳性，创建了完整的断点集。来自结构变异的拷贝数断点被用来量化我们的共识策略的“真阳性”和“假阴性”率。拷贝数方法把共识片段作为输入，但允许合并有相同拷贝数的相邻的片段，但是不允许产生额外的断点从而不会产生额外的片段。因为引入虚假断点的成本要小于缺失断点的成本，缺失断点的底层拷贝数状态确实发生了改变。我们为确定共识断点而开发的算法利用了这样一种见解:相邻区段之间的区域表明了一种方法的不确定性，即描述拷贝数状态变化的断点的确切位置。\n 模板\n 参考资料：   CEL是什么格式的文件\n  Dentro, Stefan C., et al. \u0026ldquo;Characterizing genetic intra-tumor heterogeneity across 2,658 human cancer genomes.\u0026rdquo; Cell 184.8 (2021): 2239-2254.\n  ","date":"December 16, 2021","image":null,"permalink":"/post/2021-12-16_cnv_tools/","title":"检测拷贝数变异的工具及算法【1】-PCAWG consensus copy number"},{"categories":["R","可视化"],"contents":"引言 posterdown自动排版，通过调节参数满足个人制作海报的需要。\n1. 介绍 目前posterdown支持3种风格的海报模板：posterdown_html、posterdown_betterland和posterdown_betterport。以posterdown_betterport为例进行阐述。\n 目前支持的三种模板风格\n 2. 创建海报 2.1 创建模板 直接通过新建R Markdown文件，选择posterdown模板则自动导入模板代码，如下：\n 创建模板\n 2.2 添加内容 按照R Markdown语法进行代码块、图片、文字等等的添加，通过点击knit进行渲染，查看在模板基础上更改的内容。点击knit后自动生成包含html在内的如下文件：\n. ├── A\\ Better\\ Reproducible\\ Poster\\ Title.pdf ├── packages.bib ├── poster.Rmd ├── poster.html └── poster_files  ├── figure-html  │ ├── irisfigure-1.png  │ └── myprettycode-1.png  ├── header-attrs-2.11  │ └── header-attrs.js  └── paged-0.15  4 directories, 7 files  图片  可以在该目录下再建立一个Figures文件夹存放Rmd中使用到的图片。\n html文件  默认生成的html文件名前缀和Rmd文件一致，可以通过在Rmd文档开头添加代码自定义生成的html文件名，这里为index.html：\nknit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), \u0026#39;index.html\u0026#39;)) })  海报大小设置  通过横宽两个参数设定，支持cm，in，mm这几个长度单位，在文档开头加入代码：\nposter_height: \u0026#34;90cm\u0026#34; poster_width: \u0026#34;60cm\u0026#34;  字体大小  在文档开头加入代码：\nmain_textsize: \u0026#34;70pt\u0026#34; body_textsize: \u0026#34;30px\u0026#34; 更多参数设置可以参考GitHub上发布的官方指南，另外还有一份更详细的补充参数指南，可具体到该参数支持的长度单位也包含哪些。\n2.3 导出html以及pdf 有多种方法，可以归纳为两种，一种是将Rmd直接转换为PDF，一种是渲染的html文件转换为PDF，能够满足转换的工具都可以尝试使用，不局限于使用R或者其他的方法实现。\n  根据Github上的issue作者的提议，可以使用pagedown包中的函数:pagedown::chrome_print(\u0026quot;myfile.Rmd\u0026quot;)，直接将Rmd导出为PDF，但是该函数并未使用成功，有待后续解决。\n  使用render将Rmd导出为PDF\n  render(\u0026#34;input.Rmd\u0026#34;, \u0026#34;pdf_document\u0026#34;) 该函数导出的PDF并未进行很好的渲染。\n  尝试了使用pandoc对html转换为PDF，但是渲染效果不好。\n  使用Safari浏览器直接将knit的html文件导出为PDF，能够渲染的很好。\n    参考资料：  具体的参数调整官方文档  ","date":"December 15, 2021","image":null,"permalink":"/post/2021-12-15_posterdown/","title":"使用posterdown制作学术海报"},{"categories":["计算机基础"],"contents":"引言 1. 计算机组成 计算机的组成部件可以分为三大类：中央处理单元（CPU）、主存储器和输入/输出子系统。\n中央处理单元 用于数据的运算。在大多数体系结构中，它有3个组成部分：算术逻辑单元（ALU）、控制单元、寄存器组、快速存储定位。\n  算术逻辑单元\n对数据进行逻辑、移位和算术运算。\n  寄存器\n用来存放临时数据的高速独立的存储单元。\n  控制单元\n控制各个子系统的操作。控制是通过从控制单元到其他子系统的信号来进行。\n  主存储器 是存储单元的集合，每一个存储单元都有唯一的标识，称为地址。\n","date":"December 6, 2021","image":null,"permalink":"/post/2021-12-06_consist_of_computer/","title":"计算机组成"},{"categories":["生信","算法","生物统计"],"contents":"引言 潜在语义分析（Latent sematic analysis, LSA）是一种无监督的学习方法。特点是通过矩阵分解来完成，使用的是非概率的话题分析模型，可以通过奇异值分解的方法进行矩阵因子分解，特点是分解的矩阵正交，非负矩阵分解是另一种矩阵的因子分解方法，特点是分解的矩阵非负。\n1. 单词向量空间和话题向量空间 1.1 单词向量空间 给定一个含有 \\( n \\)个文本的集合\\( D=\\left { d_1,d_2,\u0026hellip;,d_n \\right } \\)，在所有文本中出现的\\( m \\)个单词的集合\\( W=\\left { w_1,w_2,\u0026hellip;,w_m \\right } \\)，将单词在文本中出现的数据用一个单词-文本矩阵表示，记作\\( X \\): $$ \\begin{bmatrix} x_{11} \u0026amp;x_{12} \u0026amp;\u0026hellip; \u0026amp;x_{1n} \\ x_{21} \u0026amp;x_{22} \u0026amp;\u0026hellip; \u0026amp;x_{2n} \\ \\vdots \u0026amp;\\vdots \u0026amp; \u0026amp;\\vdots \\ x_{m1} \u0026amp;x_{m2} \u0026amp;\u0026hellip; \u0026amp;x_{mn} \\end{bmatrix} $$\n元素\\( x_{ij} \\)表示单词\\( w_i \\)在文本\\( d_j \\)中出现的频数或权值，由于单词的种类很多，每个文本出现单词的种类通常较少，所以单词-文本矩阵是一个稀疏矩阵。\n权值通常用单词频率-逆文本频率（TF-IDF）表示，定义是： $$ TFIDF_{ij}=\\frac{tf_{ij}}{tf_{·j}}log\\frac{df}{df_i} \\space i=1,2,\u0026hellip;,m; \\space j=1,2,\u0026hellip;,n $$ \\( \\frac{tf_{ij}}{tf_{·j}} \\)表示单词\\( w_i \\)出现在文本\\( d_j \\)中的频数比上文本\\( d_j \\)中出现的所有单词的频数之和，一个单词在一个文本中出现的频数越高，这个单词在文本中的重要度就越高；\\( \\frac{df}{df_i} \\)表示全部文本数比上含有单词\\( w_i \\)的文本数，一个单词在整个文本集合中出现的文本数越少，这个单词就越能代表其所在文本的特点，重要度就越高。TF-IDF是两种重要度的积，表示综合重要度。\n单词向量空间模型直接使用单词-文本矩阵的信息，第\\( j \\)列向量\\( x_j \\)表示文本\\( d_j \\)： $$ x_j=\\begin{bmatrix} x_{1j}\\ x_{2j}\\ \\vdots\\ x_{mj} \\end{bmatrix} $$ 其中$x_{ij}$是单词$w_i$在文本$d_j$的权值，两个单词向量的内积货标准化内积（余弦）表示对应的文本之间的语义相似度，因此文本$d_i$ 与$d_j$ 之间的相似度为: $$ x_i·x_j，\\frac{x_{i}·x_{j}}{\\left | x_{i}\\right |\\left | x_{j}\\right |} $$ $\\cdot $表示向量的内积，$\\left | \\cdot\\right |$表示向量的范数，向量的1-范数即向量元素绝对值之和。两个文本中共同出现的单词越多，其语义就越接近，这个是文本信息处理的一个基本原理。\n单词向量空间的优点是模型简单，计算效率高，局限性是内积相似度未必能够准确表达两个文本的语义相似度，因为自然语言的单词具有一词多义性以及多词一义性，因此基于单词向量的相似度计算存在不精确的问题。\n1.2 话题向量空间 1.2.1 什么是话题向量空间 两个文本的语义相似度可以体现在两者的话题相似度上，话题就是文本所讨论的内容或主题，文本一般含有若干个话题，如果两个文本的话题相似，那么两者的语义应该也相似。话题可以由若干个语义相关的单词表示，则能够解决基于单词的模型存在的问题。话题的个数通常远远小于单词的个数。\n给定一个含有$n$个文本的集合$D=\\left { d_1,d_2,\u0026hellip;,d_n \\right }$，在所有文本中出现的$m$个单词的集合$W=\\left { w_1,w_2,\u0026hellip;,w_m \\right }$，将单词在文本中出现的数据用一个单词-文本矩阵表示，记作$X$，同上单词向量空间中的表示。假设所有的文本共含有$k$个话题，假设每个话题由一个定义在单词集合$W$上的$m$维向量表示，称为话题向量： $$ t_l=\\begin{bmatrix} t_{1l}\\ t_{2l}\\ \\vdots\\ t_{ml} \\end{bmatrix},l=1,2,\u0026hellip;,k $$ 其中$t_{il}$是单词$w_i$在话题$t_l$的权值，权值越大，单词在话题中的重要度就越高，$k$个话题向量张成一个话题向量空间，话题向量空间$T$是单词向量空间$X$的一个字空间。\n单词-话题矩阵： $$ T=\\begin{bmatrix} t_{11} \u0026amp;t_{12} \u0026amp;\u0026hellip; \u0026amp;t_{1k} \\ t_{21} \u0026amp;t_{22} \u0026amp;\u0026hellip; \u0026amp;t_{2k} \\ \\vdots \u0026amp;\\vdots \u0026amp; \u0026amp;\\vdots \\ t_{m1} \u0026amp;t_{m2} \u0026amp;\u0026hellip; \u0026amp;t_{mk} \\end{bmatrix} $$\n1.2.2 文本在话题向量空间的表示 将单词向量投影到话题向量空间$T$中，得到话题向量空间的一个向量$y_j$ $$ y_j=\\begin{bmatrix} y_{1j}\\ y_{2j}\\ \\vdots\\ y_{mj} \\end{bmatrix},j=1,2,\u0026hellip;,n $$ 其中$y_{lj}$是文本$d_j$在话题$t_l$的权值，$l=1,2,\u0026hellip;,k$，权值越大，该话题在该文本中的重要度就越高。\n话题-文本矩阵： $$ Y=\\begin{bmatrix} y_{11} \u0026amp;y_{12} \u0026amp;\u0026hellip; \u0026amp;y_{1n} \\ y_{21} \u0026amp;y_{22} \u0026amp;\u0026hellip; \u0026amp;y_{2n} \\ \\vdots \u0026amp;\\vdots \u0026amp; \u0026amp;\\vdots \\ y_{k1} \u0026amp;y_{k2} \u0026amp;\u0026hellip; \u0026amp;y_{kn} \\end{bmatrix} $$\n1.2.3 从单词向量空间到话题向量空间的线性变换 单词-文本矩阵$X$可以近似的表示为单词-话题矩阵与话题-文本矩阵的乘积形式，这就是潜在语义分析： $$ X\\approx TY $$ 直观上潜在语义分析是将文本在单词向量空间的表示通过线性变换转换为在话题向量空间中的表示：\n原始的单词向量空间中，两个文本的相似度可以由对应的向量的内积表示$x_i·x_j$，经过潜在语义分析，在话题向量空间中，两个文本的相似度可以由对应的向量的内积表示：$y_i·y_j$。\n2. 潜在语义分析 2.1 矩阵奇异值分解算法 奇异值分解（SVD）是一种矩阵因子分解方法，任何一个$m\\times n$矩阵，都可以表示为三个矩阵的乘积形式，分别是$m$阶正交矩阵、由降序排列的非负的对角线元素组成的$m\\times n$矩阵对角矩阵和$n$阶正交矩阵，成为该矩阵的奇异值分解，矩阵的奇异值分解一定存在但不唯一，可以看做是矩阵数据压缩的一种方法。奇异值分解不要求矩阵是方阵。\n 正交矩阵：正交矩阵（Orthogonal Matrix）是指其转置等于其逆的矩阵。\n 奇异值分解是在平方损失（弗罗贝尼乌斯范数）意义下对矩阵的最优近似，紧奇异值分解对应着无损压缩，截断奇异值分解对应着有损压缩。潜在语义分析根据确定的话题个数$k$对单词-文本矩阵$X$进行截断奇异值分解： $$ X\\approx U_k（\\Sigma_k V{k}^{T}） $$ 矩阵的奇异值分解可以看作是将其对应的线性变换分解为旋转变换、缩放变换及旋转变换的组合，得到话题空间$U_k$，以及文本在话题空间的表示$\\Sigma_k V{k}^{T}$。\n2.2 非负矩阵分解 $$ X\\approx WH $$\n2.2.1 损失函数或代价函数 损失函数可以有以下几种：\n  平方损失\n  散度\n  2.2.2 算法 以上两个目标函数：平方损失和散度知识对变量$W$和$H$之一的凸函数，而不是同时对两个变量的凸函数，因此找到全局最优比较困难。Lee提出的基于“乘法更新规则”的优化算法，交替地对$W$和$H$进行更新。\n文献  《统计学习方法》第2版 李航  ","date":"November 26, 2021","image":null,"permalink":"/post/2021-11-26_statistic-lsa/","title":"潜在语义分析（LSA）"},{"categories":["生信","算法","生物统计"],"contents":"引言 1. 马尔可夫模型的基本概念 来对2段氨基酸序列x和y进行残基比对，认为存在3种比对关系的状态：\n M：残基能够比对上但不一定相等 X：序列x的残基比对到1个空位，或x上发生了1次插入 Y：序列y的残基比对到1个空位，或y上发生了1次插入  序列比对就是在上述3个状态中不断转换的过程：\n \\( M(i,j) \\) : \\( x_i \\)比对到\\( y_j \\)时，序列x从1到\\( i \\)和序列\\( y \\)从1到\\( j \\)最好的比对分数 \\( X(i,j) \\) : \\( x_i \\)比对到空位时，序列x从1到\\( i \\)最好的比对分数 \\( Y(i,j) \\) : \\( y_j \\)比对到空位时，序列y从1到\\( j \\)最好的比对分数  转移（从一个状态到另外一个状态）概率：\n$$ a_{kl} = P (X_t=S_l|X_{t-1}=S_k) $$\n$$ a_{lk} = P (X_t=S_k|X_{t-1}=S_l) $$\n转移矩阵：\n \n 设定：\n \\( \\delta \\) ：Gap open（d）的概率 \\( \\epsilon \\) ：Gap extension（e）的概率   马尔可夫链\n 先根据转移概率得到一个转移概率矩阵：\n 转移矩阵\n 假设匹配状态是XMMY：\n 匹配状态\n 计算匹配状态的概率： $$ P(XMMY)=\\alpha_{XM}\\alpha_{MM}\\alpha_{MY} = (1-\\epsilon)(1-2\\delta)\\delta $$\n通过上面的例子，下面介绍马尔可夫模型的一些概念：\n  马尔可夫过程：\n马尔可夫过程是一类随机过程，该过程的“将来”仅依赖“现在”，而不依赖“过去”，把一个总随机过程看作是状态的不断转移，表达式为： $$ x(t+1)=f(x(t)) $$\n  马尔可夫链：\n时间和状态都离散的马尔可夫过程。\n  马尔可夫状态链的状态空间： $$ S = \\begin{Bmatrix} S_1,\u0026amp; S_2,\u0026amp; S_3,\u0026hellip; \\end{Bmatrix}S_i\\in R $$\n  马尔可夫链在时刻\\( t \\)处于状态\\( S_i \\)条件下，在时刻\\( t+1 \\)转移到状态\\( S_j \\)的转移概率是条件概率： $$ P_{ij}(t, t+1)=P\\begin{Bmatrix} x_{t+1}=S_j|x_t=S_i \\end{Bmatrix} $$\n  由于马氏链在时刻 \\( t \\) 从任何一个状态\\( S_i \\)出发，到下一时刻 \\( t+1 \\)，必然转移到\\( S_j \\)，\\( j=1,2,… \\)，诸状\n态中的某一个，所以有：\n $$ \\forall _{i^{\\forall}}\\sum_{j}P_{ij}(t,t+1)=1 $$  当\\( P_{ij}(t,t+1) \\)与\\( t \\)无关时，为齐次马尔可夫链，通常说到的马尔可夫链都是指齐次的。马尔可夫链除了仅依赖于上一次观测值的一阶马尔可夫链，还可以依赖多个连续观测数据，后者称之为高阶马尔可夫链。\n  2. 马尔可夫模型的组成   随机序列变量 $$ X = \\begin{Bmatrix} x_1,\u0026amp; x_2,\u0026amp; x_3,\u0026hellip;,x_t \\end{Bmatrix} $$\n  状态空间 $$ S = \\begin{Bmatrix} S_1,\u0026amp; S_2,\u0026amp; S_3,\u0026hellip; \\end{Bmatrix}\\space\\space S_i\\in R \\space\\space\\space i=1,2,\u0026hellip;,n $$\n  转移概率矩阵 $$ P=\\begin{Bmatrix} P_{ij}=P(x_{t+1}=S_j|x_t=S_i) \\end{Bmatrix} $$\n  初始状态向量 $$ \\prod =\\begin{Bmatrix} \\pi=P(x_0=S_i) \\end{Bmatrix} , \\space\\space\\space i=1,2,\u0026hellip;,n $$\n  3. 隐马尔可夫模型 隐马尔可夫模型是结构最简单的动态贝叶斯网，可以用五元组来描述分别为：\n 状态空间\\( S \\) 状态对应的观测空间\\( X \\) 状态转移矩阵\\( A \\) 每个状态下观测事件的概率矩阵\\( B \\) 初始状态概率分布\\( \\pi \\)  给出这五个参数就能够确定一个隐马尔可夫模型，通常用参数\\( \\lambda=\\begin{Bmatrix}A,B,\\pi\\end{Bmatrix} \\)来指代。\n举一个新的例子：基因预测——给定序列预测编码区\n隐马尔可夫模型在状态的基础上，增加符号的概念，每个状态可以以不同的概率产生可观测到的符号。在例子中，给定的基因组序列为观测到的符号串，编码和非编码为2种隐状态，即编码与否是未知的，需要通过已知的符号来推测。\n 示例：马尔可夫链\n 转移矩阵：\n基因组会同时包含编码和非编码区域，自我转移的箭头表示状态的连续。\n 转移矩阵\n 转移概率矩阵：\n 转移概率矩阵\n $$ a_{kl} = P (X_t=S_l|X_{t-1}=S_k) $$\n生成概率：\n 生成概率\n 这里的状态路径无法进行观测，需要根据符号路径来推测状态，引入生成概率，状态\\( S_k \\)时产生符号\\( b \\)的概率： $$ e_{k}(b) = P (y_i=b|X_{i}=S_k) $$ 生成概率矩阵（在这里有两个）：\n 2个生成概率矩阵\n 训练集：正确标记好了编码和非编码区域的DNA序列。\n根据训练集填好上述转移概率矩阵和生成概率矩阵，来对未知的给定基因组序列反推最可能的基因组状态路径。\nLogarithmic transformation：引入对数计算将乘法变成加法，对转移/生成矩阵概率取\\( log_{10} \\)（在计算机运算中，很容易因为连乘的次数的增加，很容音因为数值过小，出现下溢的问题）\n测试序列：CGAAAAAATCG\n根据训练集得到转移概率矩阵和生成概率矩阵：\n取log10的转移概率矩阵\n取log10的生成概率矩阵\n 动态规划进行序列比对：\n 序列比对\n 假设n状态和c状态默认的分布比例分别是\\( log_{10}(0.8) \\)和\\( log_{10}(0.2) \\)，使用序列比对的方法，找到概率最大的值为起点进行回溯。最终找到的状态链为：NNCCCCCCNNN。\n根据示例我们可以得到一个大概的步骤来对隐马尔可夫模型进行应用：\n 首先要确定具体问题中什么是状态，什么是符号 其次根据状态列出转移概率矩阵，根据状态和符号列出生成概率矩阵 根据训练集填上矩阵的具体数值 根据具体问题使用相应的解决方法(本例子中根据数据来对未知的给定基因组序列反推出最可能的基因组状态路径，迭代使用动态规划进行序列比对)  实际应用中关注隐马尔可夫模型的3个基本问题以及对应的解决方法：\n  估算问题：\n给定模型\\( \\lambda=\\begin{Bmatrix}A,B,\\pi\\end{Bmatrix} \\)，如何有效计算观测序列\\( x=\\begin{Bmatrix} x_1,x_2,\u0026hellip;,x_n\\end{Bmatrix} \\)出现的概率？也就是模型和观测序列之间的匹配程度。\n解决：foreward和backward算法\n  解码问题：\n给定模型\\( \\lambda=\\begin{Bmatrix}A,B,\\pi\\end{Bmatrix} \\)和观测序列\\( x=\\begin{Bmatrix} x_1,x_2,\u0026hellip;,x_n\\end{Bmatrix} \\)，如何找到和观测序列最匹配的状态序列？也就是找到隐藏的模型状态。\n解决：Viterbi算法\n  学习问题或训练问题：\n给定观测序列\\( x=\\begin{Bmatrix} x_1,x_2,\u0026hellip;,x_n\\end{Bmatrix} \\)，如何调整模型参数\\( \\lambda=\\begin{Bmatrix}A,B,\\pi\\end{Bmatrix} \\)，使得该观测序列发生的概率最大？也就是根据训练样本学得最优的参数模型。\n解决：Baum-Welch算法\n  4. 隐马尔可夫模型判断CNV 以PennCNV为例介绍HMM在实际判断CNV中的应用。PennCNV是一个免费的检测SNP分型阵列芯片的拷贝数变异的工具，目前可以处理Illumina和Affymetrix array的数据来得到信号强度，若使用其他类型的SNP芯片数据和寡核苷酸芯片需要预先处理文件的格式。PennCNV使用隐马尔可夫模型整合多个来源的信息来对单个样本推断CNV。它与基于分割的算法不同，除了单独考虑信号强度外，还考虑了SNP等位基因比例分布等因素。\n PennCNV通过基因型来检测拷贝数变异的算法流程（Wang K et al. 2007）\n 在PennCNV中使用的是一阶HMM，隐状态是人为设定的离散值1，2，3，4，5，6，各自对应的总拷贝数数值和CNV基因型如上表所示。注意这里最大的拷贝数状态设定为拷贝数为4，因为4个和4个以上的拷贝无法进行区分。符号是信号强度值的两种形式：BAF和LRR。结合BAF和LRR可以判断不同的拷贝数以及区分出拷贝中性的LOH（文章中没有具体说怎么结合BAF和LRR数据的，但是通过公示我的理解是BAF和LRR同时发生的联合概率作为HMM的生成概率）。\n 隐状态，拷贝数数值及其对应的描述（Wang K et al. 2007）\n 下面介绍一些定义：\n  原始的信号强度数据需要经过“5步标准化”（http://icom.illumina.com/iom/software.ilmn），每个SNP的X值和Y值分别代表实验得到经过标准化的等位基因A和B的信号强度值，\\( R \\)为总信号强度： $$ R = X + Y $$\n   \\( \\theta \\)为相对的等位信号强度比率： $$ \\theta = \\frac{arctan(Y/X)}{\\pi/2} $$ 该计算分母为\\( \\pi/2 \\)可以将数值\\( \\theta \\)压缩在-1～1之间。\n  B Allele Frequency （BAF）通常指的是标准化的等位基因B和A的相对信号强度：\n BAF公式（Wang K et al. 2007）\n 0代表只检测到了A这个allele对应的荧光信号，分型结果为AA；1代表只检测到了B这个allele对应的荧光信号，分型结果为BB；0.5代表A和B这两个allele的荧光信号强度相等，分型结果为AB。\\( \\theta_{AA} \\),\\( \\theta_{AB} \\),\\( \\theta_{BB} \\)都是根据正常样本得到的值，荧光信号存在一定程度的扰动，因此BAF的取值是在0-1范围波动的值。\n  \\( R_{observed} \\)是观测值，\\( R_{expected} \\)是通过算法拟合得到的数值代表了正常样本中的信号强度，每个SNP的\\( log \\) R 比率（LRR）：\n  $$ LRR={log_{2}}(R_{observed}/R_{expected}) $$\n​\tLRR = 0\t拷贝数为2；LRR \u0026gt; 0 拷贝数增加；LRR \u0026lt; 0 拷贝数减少\n介绍完定义之后，来确定转移概率和生成概率以及对应矩阵。\n  LRR的生成概率：\n是混合的均匀和正态分布模型， $$ P(r|z)=\\pi_r+(1-\\pi_r)\\phi(r;\\mu_{r,z},S_{r,z}) $$ \\( (\\phi·；·) \\)是均值为\\( \\mu_{r,z} \\)，标准差为\\( S_{r,z} \\)的正态分布，均匀分布用于对于芯片中随机的信号波动和可能的基因组错误注释和错误assmbly的建模。\n  BAF的生成概率：\n对于每一个隐状态（除了状态1），有不同可能的基因型也就有不同模式的BAF。\n BAF生成概率（Wang K et al. 2007）\n   对于染色体X进行特殊处理：\n将染色体X中所有的SNP的LRR值减去1个常数，使得针对女性，平均的LRR值不是0，针对男性，LRR不是单拷贝删除的LRR的参考值，因为正常的男性染色体X的状态就是state2不应该是state3。\n  隐状态的转移概率：\n即两个相邻SNP发生拷贝数状态改变的概率，一般来讲，临近的SNPs拷贝数状态不太可能发生变化，但是较远的SNPs的拷贝数状态更容易发生改变。因此需要找到转移概率和距离的关系，那么转移概率为：\n $$ p(z_i=l|z_{i-1}=j)=\\left\\{\\begin{matrix} 1-\\sum_{k=2}^{b}p_{j,k-1}(1-e^{d_i/D}),if \\space l=j \\\\ p_{j,l-1}(1-e^{d_i/D}),if \\space l\\neq j \\end{matrix}\\right. $$ \\( D \\)是一个常数，当状态为4时设为100Mb，其他状态为100kb，p是未知参数，用Baum-Welch算法进行估计，得到最优的参数后，再使用Viterbi算法进行隐状态的判断。在PennCNV的分析中，排除了所有包含小于等于\u00032个SNP的CNV，因为这些CNV中可能存在较高的假阳性比例。\n  介绍算法之前先定义几个概念：\n \\( O = O_1,O_2,\u0026hellip;,O_t \\)\t输出的观察序列符号 \\( P(O|\\lambda) \\) 给定模型参数时，输出符号序列\\( O \\)的概率 \\( a_{ij} \\)\t从状态\\( S_i \\)到状态\\( S_j \\)的转移概率 \\( b_j(O_t) \\)\t在状态\\( S_j \\)时，输出\\( O_t \\)的概率 \\( a_t(j) \\)\t输出部分符号序号\\( O = O_1,O_2,\u0026hellip;,O_t \\)达到状态\\( S_j \\)时的前向概率  前向算法：\n 前向算法\n  前向算法步骤\n Vertibi算法\n介绍完定义，明确完我们的五元组，我们再明确一下我们的问题是解码问题，解码问题对应的解法是Viterbi算法，介绍一下该算法具体过程：\n Vertibi算法步骤\n 参考   Wang, Kai, et al. \u0026ldquo;PennCNV: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome SNP genotyping data.\u0026rdquo; Genome research 17.11 (2007): 1665-1674.\n  图：Kai Wang et al. Genome Res. 2007;17:1665-1674\n  Circular Binary Segmentation from Jeremy Teibelbaum\u0026amp;rsquo;s blog\n  CKVkit：https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004873\n  Ming-Lian\u0026amp;rsquo;s blog\n  隐马尔可夫模型：https://www.cnblogs.com/skyme/p/4651331.html\n  coursera生物信息学：导论与方法第四周\n  动态贝叶斯网络\n  ","date":"November 19, 2021","image":null,"permalink":"/post/2021-11-19_hmm/","title":"隐马尔可夫模型（HMM）"},{"categories":["R"],"contents":"引言 使用do.call批量读入文件并合并。\n1. 基本处理步骤 source_dir \u0026lt;- \u0026#34;文件所在路径\u0026#34; file \u0026lt;- list.files(  path = source_dir,  pattern = \u0026#34;*.txt\u0026#34;, # 目标文件夹下需要的文件的格式  all.files = F,  full.names = F,  recursive = F,  include.dirs = F ) allfile \u0026lt;- lapply(file, function(x){read.csv2(paste0(source_dir, x), sep = \u0026#34;\\t\u0026#34;)}) combine \u0026lt;- do.call(rbind, allfile) 2. 涉及到的需求和参数设定   文件名作为新列补充进数据框\n  对文件名进行更改\n  参考    ","date":"November 17, 2021","image":null,"permalink":"/post/2021-11-17_docall/","title":"R：批量读入文件并合并"},{"categories":["生信","R"],"contents":"引言 一个提供批量下载Synapser数据的R包。\n1. 登陆 synLogin(\u0026#34;baomihai@sina.com\u0026#34;,\u0026#34;******\u0026#34;) Welcome, baomihai@sina.com!NULL 参考  biostars-How to install gdc-client in Ubnutu  ","date":"July 24, 2021","image":null,"permalink":"/post/2021-8-31_synapser/","title":"synapser"},{"categories":["R"],"contents":"引言 stringr包是建立在stringi上的，stringi包使用ICU C库提供准确、快速的常见字符串操作，stringr提供了最重要和最常用的字符串处理函数。\nstringr stringr包中所有的函数都以str_开头，第一个参数为字符串向量。对应的在base函数中也有功能一致的函数，记得对比两者之间的异同。\n1. 找到自己需要的数据 tcga_mut \u0026lt;- read.csv2(\u0026#34;/home/tzy/projects/CNX-method/data/TCGA/mc3.v0.2.8.PUBLIC.nonsilentGene.xena\u0026#34;,sep = \u0026#34;\\t\u0026#34;)  saveRDS(tcga_mut, file = \u0026#34;/home/tzy/projects/CNX-method/data/TCGA/tcga_mut.rds\u0026#34;) save(tcga_mut, file = \u0026#34;/home/tzy/projects/CNX-method/data/TCGA/tcga_mut.RData\u0026#34;) 参考  biostars-How to install gdc-client in Ubnutu  ","date":"July 24, 2021","image":null,"permalink":"/post/2021-7-24_stringr_stringi/","title":"处理字符串的两个R包:stringi和stringr"},{"categories":["生信"],"contents":"引言 之前一直用别的方法下载数据，这次使用了gdc-client命令行去下载GDC上TCGA driver gene mutation的一批数据。\n步骤 1. 找到自己需要的数据 这是我本次要下载的数据\n点击数据下载地址发现出现如下界面，其中id就是使用gdc-client下载的文件对应的id\n对于Open access data，使用这两种方法下载\n下载了MAC的Client版本\n2. 安装 解压下载的文件，如果双击会发现出现erro：\n且常规的对~/.bash_profile文件添加环境变量也不可以，正确做法是：\n./gdc-client #(to verify that program works) cp -pi ./gdc-client /usr/local/bin #(if this does not work) sudo cp -pi ./gdc-client /usr/local/bin 在任何路径都可以打开。\n3. 使用  下载单个文件  gdc-client download id  下载多个文件  将含有多个文件的id和名字等信息的页面存储为txt，download加上-m，进行批量下载。\ngdc-client download -m ./PanCan-Driver_Open_GDC-Manifest.txt 参考  biostars-How to install gdc-client in Ubnutu  ","date":"July 20, 2021","image":null,"permalink":"/post/2021-7-20_gdc_client/","title":"gdc-client"},{"categories":["R"],"contents":"引言 rds比RData省空间，为什么？\n步骤 1. 找到自己需要的数据 tcga_mut \u0026lt;- read.csv2(\u0026#34;/home/tzy/projects/CNX-method/data/TCGA/mc3.v0.2.8.PUBLIC.nonsilentGene.xena\u0026#34;,sep = \u0026#34;\\t\u0026#34;)  saveRDS(tcga_mut, file = \u0026#34;/home/tzy/projects/CNX-method/data/TCGA/tcga_mut.rds\u0026#34;) save(tcga_mut, file = \u0026#34;/home/tzy/projects/CNX-method/data/TCGA/tcga_mut.RData\u0026#34;) 参考  biostars-How to install gdc-client in Ubnutu  ","date":"July 20, 2021","image":null,"permalink":"/post/2021-7-20_rdata/","title":"R储存数据"},{"categories":["技术"],"contents":"步骤 1. 配置Leancloud 这部分详细参考：hugo博客添加评论系统Valine\n2. 更改 comments.html 文件 将整体内容替换成如下代码：\n\u0026lt;!-- valine change from origin code--\u0026gt;  {{- if .Site.Params.valine.enable -}}  \u0026lt;!-- id 将作为查询条件 --\u0026gt;   \u0026lt;div id=\u0026#34;vcomments\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;  \u0026lt;script src=\u0026#34;//cdn1.lncld.net/static/js/3.0.4/av-min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;  \u0026lt;script src=\u0026#39;//unpkg.com/valine/dist/Valine.min.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt;   \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt;  new Valine({  el: \u0026#39;#vcomments\u0026#39; ,  appId: \u0026#39;{{ .Site.Params.valine.appId }}\u0026#39;,  appKey: \u0026#39;{{ .Site.Params.valine.appKey }}\u0026#39;,  notify: \u0026#39;{{ .Site.Params.valine.notify }}\u0026#39;,  verify: \u0026#39;{{ .Site.Params.valine.verify }}\u0026#39;,  avatar:\u0026#39;{{ .Site.Params.valine.avatar }}\u0026#39;,  placeholder: \u0026#39;{{ .Site.Params.valine.placeholder }}\u0026#39;,  visitor: \u0026#39;{{ .Site.Params.valine.visitor }}\u0026#39;  });  \u0026lt;/script\u0026gt;  {{- end -}} 3. 引入评论 layouts/_default/single.html 中引入评论，本主题已有配置：\n {{ if not ( eq .Params.comments false) }}  {{ .Render \u0026#34;comments\u0026#34; }}  {{ end }} 参考   Hugo评论插件集成之Valine\n  hugo博客添加评论系统Valine\n  关于该主题已有的配置：给Hugo个人博客添加Valine评论系统\n  Valine配置项\n  ","date":"June 8, 2021","image":null,"permalink":"/post/2021-6-8_comment/","title":"hugo主题增加valine评论功能_test"},{"categories":["技术"],"contents":"引言 根据hugo-future-imperfect-slim主题中issue提到的TOC更改版本，改进后进行配置应用。\n步骤 1. 更改 config.html 文件 在[params] 内容下加入以下参数：\n toc = true # 默认显示toc  tocWords = 400 #超过400字显示toc 2. 更改 main.scss 文件 添加TableOfContents：\n#TableOfContents {  border: $secondary-border;   ul {  list-style-type: none;  padding-inline-start: 1.5em;  } } /* ==========================================================================  Add-Ons  ========================================================================== */  /* reCaptcha */ 3. 更改 single.html 文件 在content内容中添加{{ .TableOfContents }}\n \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt;  {{ .Render \u0026#34;featured\u0026#34; }}  {{ .TableOfContents }} #此处添加一行  {{ .Content }}  \u0026lt;/div\u0026gt; 更新——2022.11.14 由于我更换的新的博客主题：logbook主题，因此对于TOC的配置也有一些变化，新的配置过程主要参考的是Vincent Liu的教程\n 在layouts/partials目录下新建toc.html，toc.html内容如下  \u0026lt;!-- toc.html --\u0026gt; \u0026lt;!-- ignore empty links with + --\u0026gt; {{ $headers := findRE \u0026#34;\u0026lt;h[1-4].*?\u0026gt;(.|\\n])+?\u0026lt;/h[1-4]\u0026gt;\u0026#34; .Content }} \u0026lt;!-- at least one header to link to --\u0026gt; {{ if ge (len $headers) 1 }} {{ $h1_n := len (findRE \u0026#34;(.|\\n])+?\u0026#34; .Content) }} {{ $re := (cond (eq $h1_n 0) \u0026#34;\u0026lt;h[2-4]\u0026#34; \u0026#34;\u0026lt;h[1-4]\u0026#34;) }} {{ $renum := (cond (eq $h1_n 0) \u0026#34;[2-4]\u0026#34; \u0026#34;[1-4]\u0026#34;) }}  \u0026lt;!--Scrollspy--\u0026gt; \u0026lt;div class=\u0026#34;toc\u0026#34;\u0026gt;   \u0026lt;div class=\u0026#34;page-header\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;- CATALOG -\u0026lt;/strong\u0026gt;\u0026lt;/div\u0026gt;   \u0026lt;div id=\u0026#34;page-scrollspy\u0026#34; class=\u0026#34;toc-nav\u0026#34;\u0026gt;   {{ range $headers }}  {{ $header := . }}  {{ range first 1 (findRE $re $header 1) }}  {{ range findRE $renum . 1 }}  {{ $next_heading := (cond (eq $h1_n 0) (sub (int .) 1 ) (int . ) ) }}  {{ range seq $next_heading }}  \u0026lt;ul class=\u0026#34;nav\u0026#34;\u0026gt;  {{end}}  {{ $anchorId := (replaceRE \u0026#34;.* id=\\\u0026#34;(.*?)\\\u0026#34;.*\u0026#34; \u0026#34;$1\u0026#34; $header ) }}  \u0026lt;li class=\u0026#34;nav-item\u0026#34;\u0026gt;  \u0026lt;a class=\u0026#34;nav-link text-left\u0026#34; href=\u0026#34;#{{ $anchorId}}\u0026#34;\u0026gt;  {{ $header | plainify | htmlUnescape }}  \u0026lt;/a\u0026gt;  \u0026lt;/li\u0026gt;  \u0026lt;!-- close list --\u0026gt;  {{ range seq $next_heading }}  \u0026lt;/ul\u0026gt;  {{ end }}  {{ end }}  {{ end }}  {{ end }}   \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt; \u0026lt;!--Scrollspy--\u0026gt;  {{ end }} 新建toc样式，在自己主题的css样式文件中加入以下内容，logbook主题是更改themes/logbook/assets/scss/templates/_main.scss文件  /* toc style */ .toc {  position: fixed;  top: 50%;  left: 2%;  width: 20%;  transform: translateY(-50%);  background-color: #f6f6f6;  /*border: solid 1px #c9c9c9;*/  border-radius: 5px;  padding-bottom: 1rem; }  .toc .page-header {  margin-top: 1rem;  margin-bottom: 1rem; }  .toc-nav ul {  overflow:hidden;  white-space:nowrap;  line-height: 1rem; }  /* ignore h1 header */ .toc-nav ul ul ul {  margin-left: 2rem; }  .toc-nav .nav-link {  text-overflow:ellipsis;  overflow:hidden;  color: #333; }  .toc-nav a.nav-link:hover {  background-color: #f6f6f6;  color: #d78a64;  /*color: var(--accent);*/  /*border-left: 2px solid #ce8460;*/  border-left: solid 2px var(--accent); }    /* Media Queries */ @media (max-width: 1080px) {  main {  max-width: 100%;  }  .toc {  display: none;  } } .toc-nav a.nav-link:hover是鼠标滑过时toc标题产生颜色变化。\nmedia是设置小屏幕不显示toc\n在layouts/_default/single.html中加入以下内容，放在了 \u0026lt;/article\u0026gt; 和comment之间。  {{ if .Site.Params.toc | default true }} {{ partial \u0026#34;toc\u0026#34; . }} {{ end }} 在themes/logbook/assets/js/script.js中添加  /* scroll to the anchor and scroll spy */ var navbarHeight = 55; var scrollSpeed = 200; $(\u0026#34;#page-scrollspy a.nav-link\u0026#34;).on(\u0026#39;click\u0026#39;, function () {  /* decode chinese hash */  var target = decodeURI(this.hash.replace(/^#/, \u0026#39;\u0026#39;));  $(\u0026#39;html,body\u0026#39;).animate({scrollTop: $(\u0026#34;:header[id=\u0026#39;\u0026#34; + target + \u0026#34;\u0026#39;]\u0026#34;).offset().top - navbarHeight}, scrollSpeed);  return false; }); 参考   图片来源\n  hugo官方文档\n  github issue\n  可以尝试的其他方法：HuGo中文章加入目录\n  Hugo博客侧边导航栏\n  Hugo添加文章目录toc\n  Blog养成记(13) 增加一个TOC侧边栏\n  ","date":"June 8, 2021","image":null,"permalink":"/post/2021-6-8_toc/","title":"hugo增加TOC"},{"categories":["技术"],"contents":"引言 分为功能改进、美观改进。\n1. 博客功能改进   个人博客归档（已完成）\n  date的时间更换成自动化填充，每次手动填写很麻烦\n  搜索中文优化，目前速度较慢\n  更改归档页面时间0001\n  每篇博文的分享页面超链接到对应网址\n      删除不需要的语言支持，只保留英文和中文\n  增加评论功能Valine（已完成）\n  参考：https://www.smslit.top/2018/07/08/hugo-valine/\n    分类更加细化，最好能有层层分类\n  ABOUT页面填充自己的个人信息\n  翻页添加页码\n  博文添加目录（已完成）\n  代码块配色更改，增加浅色代码块阴影\n  2. 博客整体美观   每个博文的图片选取大小合适的\n  标题的英文或中文的字距过大，比如下图的 引言 和 博客功能改进\n    ","date":"June 8, 2021","image":null,"permalink":"/post/2021-6-8_optimization_of_the_blog/","title":"博客优化计划"},{"categories":["技术"],"contents":"引言 hugo没有自带的归档设置，需要手动添加。\n操作步骤   在taozy_blog/layouts/_default/目录下创建 archives.html 文件\n  将taozy_blog/layouts/_default/目录下的 single.html 内容复制进 archives.html 文件（single.html的格式就是每篇博文的格式，也可以采用主题的contact.html的格式或者about.html的格式）\n  找到archives.html 文件中的{{ .Content }} 替换为下面的内容:\n  {{ range (.Site.RegularPages.GroupByDate \u0026#34;2006\u0026#34;) }}  \u0026lt;h3\u0026gt;{{ .Key }}\u0026lt;/h3\u0026gt;   \u0026lt;ul class=\u0026#34;archive-list\u0026#34;\u0026gt;  {{ range (where .Pages \u0026#34;Type\u0026#34; \u0026#34;blog\u0026#34;) }}  \u0026lt;li\u0026gt;  {{ .PublishDate.Format \u0026#34;2006-01-02\u0026#34; }}  -\u0026gt;  \u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;  \u0026lt;/li\u0026gt;  {{ end }}  \u0026lt;/ul\u0026gt; {{ end }} 对上述代码进行解读:\n 归档目录  Pages \u0026ldquo;Type\u0026rdquo; \u0026ldquo;blog\u0026quot;即归档目录设置为content/blog/下的内容，如果去掉blog，引号内留空，就会自动归档根目录下的文件，也就是content目录的文件。\n 可选归档时间  .Site.RegularPages.GroupByDate \u0026ldquo;2006\u0026rdquo;：按年归档 .Site.RegularPages.GroupByDate \u0026ldquo;2006-01\u0026rdquo;：按年月归档\n在config.toml文件[menu]中仿照其他添加以下代码，使得主页上栏显示该分类：   [[menu.main]]  name = \u0026#34;Archives\u0026#34;  identifier = \u0026#34;archives\u0026#34;  url = \u0026#34;/archives/\u0026#34;  pre = \u0026#34;\u0026lt;i class=\u0026#39;fa fa-newspaper\u0026#39;\u0026gt;\u0026lt;/i\u0026gt;\u0026#34;  weight = 6 如下：\n完成归档页面的建立。\n 更新——2022.4.2 由于我更换的新的博客主题：logbook主题，因此对于归档页面的配置也有一些变化，新的配置过程如下\n  同上\n  同上\n  在theme/config/_default/menus.en.toml中添加\n  [[main]] name = \u0026#34;Archives\u0026#34; url = \u0026#34;archives\u0026#34; weight = 5 #主页上面的按钮排序为第5 用来替换content的代码{{- if ne .Key \u0026quot;0001\u0026quot; }}来去除莫名出现的年份：0001；另外注意{{ range (where .Pages \u0026quot;type\u0026quot; \u0026quot;post\u0026quot;) }}中的type需要更改为Section（因为存放博文的目录和之前博客主题不同）。  {{ range (.Site.RegularPages.GroupByDate \u0026#34;2006\u0026#34;) }}  {{- if ne .Key \u0026#34;0001\u0026#34; }}  \u0026lt;h3\u0026gt;{{ .Key }}\u0026lt;/h3\u0026gt;   \u0026lt;ul class=\u0026#34;archive-list\u0026#34;\u0026gt;  {{ range (where .Pages \u0026#34;Section\u0026#34; \u0026#34;post\u0026#34;) }}  \u0026lt;li\u0026gt;  {{ .PublishDate.Format \u0026#34;2006-01-02\u0026#34; }}  -\u0026gt;  \u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;  \u0026lt;/li\u0026gt;  {{ end }}  \u0026lt;/ul\u0026gt; {{ end }} 在博文目录下新建一个archives.md文件，文件内容如下：  --- title: \u0026#34;归档\u0026#34; layout: \u0026#34;archives\u0026#34; description: \u0026#34;历史文章按照年归档.\u0026#34; draft: false --- 如果想要单独的年份归档页面（我这里只有2021和2022），可以如下操作\n 在taozy_blog/layouts/_default/目录下创建 archives1.html 文件和archives2.html 文件，其中{{ .Content }}替换代码改为如下：   {{ range (.Site.RegularPages.GroupByDate \u0026#34;2006\u0026#34;) }}  {{ if ne .Key \u0026#34;0001\u0026#34; }}   \u0026lt;ul class=\u0026#34;archive-list\u0026#34;\u0026gt;  {{ if eq .Key \u0026#34;2021\u0026#34; }} #2022的需要修改为2022  \u0026lt;h3\u0026gt;{{ .Key }}\u0026lt;/h3\u0026gt;  {{ range (where .Pages \u0026#34;Section\u0026#34; \u0026#34;post\u0026#34;) }}  \u0026lt;li\u0026gt;  {{ .PublishDate.Format \u0026#34;2006-01-02\u0026#34; }}  -  \u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;  \u0026lt;/li\u0026gt;  {{ end }}  {{ end }}  \u0026lt;/ul\u0026gt; {{ end }}  在theme/config/_default/menus.en.toml中添加  [[main]] name = \u0026#34;Archives\u0026#34; weight = 5 hasChildren = true   [[main]]  parent = \u0026#34;Archives\u0026#34;  name = \u0026#34;2022\u0026#34;  url = \u0026#34;2022/\u0026#34;  weight = 1   [[main]]  parent = \u0026#34;Archives\u0026#34;  name = \u0026#34;2021\u0026#34;  url = \u0026#34;2021/\u0026#34;  weight = 2  在放置博客的目录下新建两个博文2021.md和2022.md，2021.md的内容如下  --- title: \u0026#34;归档\u0026#34; layout: \u0026#34;archives1\u0026#34; description: \u0026#34;历史文章按照年月归档.\u0026#34; draft: false --- 完成。\n参考：   配置主要参考：为hugo添加归档页面\n  我为什么要从 Hexo 更换到 Hugo\n  解读部分主要参考：Hugo添加归档页面\n  Hugo博客时间轴中文化\n  hugo获取某个归档中文章个数\n  ","date":"June 7, 2021","image":null,"permalink":"/post/2021-6-7_%E9%85%8D%E7%BD%AE%E5%BD%92%E6%A1%A3/","title":"hugo博客配置归档页面"},{"categories":["BUG"],"contents":"引言 为了在集群上跑1000个模拟样本的SigprofilerExtractor工具，在集群上自己新建的环境里安装，解决安装bug，并成功使用。\n解决bug思路   发现依赖torch1.5.1版本\n  通过pip install安装失败\n  使用whl安装发现没有对应python3.9的版本\n  根据版本推测1.5.1不能在python3.9安装\n  重建新环境，安装python3.8，进而安装1.5.1\n  成功\n  具体实施 使用sigprofilerextractor发现报错如下：\nERROR: Could not find a version that satisfies the requirement torch==1.5.1 (from sigprofilerextractor) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 1.7.1, 1.8.0, 1.8.1) ERROR: No matching distribution found for torch==1.5.1 需要安装torch1.5.1版本，直接conda安装和pip安装都失败了 另外提示中表明可以通过source使用whl安装，网址如下：\nCannot install torch just with pip, try again with source from https://download.pytorch.org/whl/torch_stable.html Looking in links: https://download.pytorch.org/whl/torch_stable.html 选择匹配版本，发现报错，其中网址中36指的是python3.6版本\nERROR: Could not install requirement torch==1.5.1+cpu from https://download.pytorch.org/whl/cpu/torch-1.5.1%2Bcpu-cp39-cp39-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: https://download.pytorch.org/whl/cpu/torch-1.5.1%2Bcpu-cp39-cp39-linux_x86_64.whl for URL https://download.pytorch.org/whl/cpu/torch-1.5.1%2Bcpu-cp39-cp39-linux_x86_64.whl torch1.5.1没有支持3.9的版本，但是我的python是3.9的\n(R4) [taozy@hpc-login-gpu01 ~]$ python Python 3.9.1 | packaged by conda-forge | (default, Dec 21 2020, 22:08:58) [GCC 9.3.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. 创建一个新环境去跑sigprofilerextractor：sigminer环境，这个python是3.8的 先在这个环境里安装sigminer，使用conda安的时候老是出现以下报错\nSolving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. 有可能是镜像的问题，换源 还没换源莫名其妙好了\nCollecting package metadata (repodata.json): done Solving environment: done proceed yes之后继续下载 载入sigminer时有问题\n\u0026gt; library(sigminer) Error: package or namespace load failed for ‘sigminer’ in dyn.load(file, DLLpath = DLLpath, ...):  unable to load shared object \u0026#39;/slst/home/taozy/miniconda3/envs/sigminer/lib/R/library/data.table/libs/datatable.so\u0026#39;:  /slst/home/taozy/miniconda3/envs/sigminer/lib/R/library/data.table/libs/datatable.so: symbol GOMP_loop_nonmonotonic_dynamic_next, version GOMP_4.5 not defined in file libgomp.so.1 with link time reference In addition: Warning message: package ‘sigminer’ was built under R version 4.0.5 \u0026gt; install.packages(\u0026#34;data.table\u0026#34;) 是库的问题，重新安装data.table，解决 在python3.8下安装发现问题解决，torch1.5.1成功安装 运行时发现自动调用python3.9，通过py_path强制设定3.8版本\nsigprofiler_extract(simulate.tally_X,  output = \u0026#34;PCAWG_1000\u0026#34;,  range = 2:30,  nrun = 100,  init_method = \u0026#34;random\u0026#34;,  is_exome = FALSE,  use_conda = FALSE,  py_path = \u0026#34;~/miniconda3/envs/sigminer/bin/python\u0026#34; ) 运行报错python3.8没有sigprofilerExtractor\npython: /slst/home/taozy/miniconda3/envs/sigminer/bin/python libpython: /public/slst/home/taozy/miniconda3/envs/sigminer/lib/libpython3.8.so pythonhome: /slst/home/taozy/miniconda3/envs/sigminer:/slst/home/taozy/miniconda3/envs/sigminer version: 3.8.2 | packaged by conda-forge | (default, Mar 5 2020, 17:11:00) [GCC 7.3.0] numpy: /slst/home/taozy/miniconda3/envs/sigminer/lib/python3.8/site-packages/numpy numpy_version: 1.20.3  NOTE: Python version was forced by use_python function Python module SigProfilerExtractor not found, try installing it... WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by \u0026#39;NewConnectionError(\u0026#39;\u0026lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x2b8645858070\u0026gt;: Failed to establish a new connection: [Errno -2] Name or service not known\u0026#39;)\u0026#39;: /simple/sigprofilerextractor/ WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by \u0026#39;NewConnectionError(\u0026#39;\u0026lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x2b8645858c40\u0026gt;: Failed to establish a new connection: [Errno -2] Name or service not known\u0026#39;)\u0026#39;: /simple/sigprofilerextractor/ WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by \u0026#39;NewConnectionError(\u0026#39;\u0026lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x2b86458584f0\u0026gt;: Failed to establish a new connection: [Errno -2] Name or service not known\u0026#39;)\u0026#39;: /simple/sigprofilerextractor/ WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by \u0026#39;NewConnectionError(\u0026#39;\u0026lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x2b8645858ac0\u0026gt;: Failed to establish a new connection: [Errno -2] Name or service not known\u0026#39;)\u0026#39;: /simple/sigprofilerextractor/ WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by \u0026#39;NewConnectionError(\u0026#39;\u0026lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x2b864586a550\u0026gt;: Failed to establish a new connection: [Errno -2] Name or service not known\u0026#39;)\u0026#39;: /simple/sigprofilerextractor/ ERROR: Could not find a version that satisfies the requirement SigProfilerExtractor==1.1.0 (from versions: none) ERROR: No matching distribution found for SigProfilerExtractor==1.1.0 Error: Error installing package(s): \u0026#39;SigProfilerExtractor==1.1.0\u0026#39; Execution halted 指定该版本的工具进行安装\npip install SigProfilerExtractor==1.1.0 安装成功\nInstalling collected packages: joblib, threadpoolctl, scipy, scikit-learn, pillow, pyparsing, six, cycler, kiwisolver, python-dateutil, matplotlib, nimfa, pytz, pandas, seaborn, sigProfilerPlotting, patsy, statsmodels, SigProfilerMatrixGenerator, reportlab, psutil, PyPDF2, xlrd, SigProfilerExtractor Successfully installed PyPDF2-1.26.0 SigProfilerExtractor-1.1.0 SigProfilerMatrixGenerator-1.1.30 cycler-0.10.0 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.4.2 nimfa-1.4.0 pandas-1.2.4 patsy-0.5.1 pillow-8.2.0 psutil-5.8.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2021.1 reportlab-3.5.67 scikit-learn-0.24.2 scipy-1.6.3 seaborn-0.11.1 sigProfilerPlotting-1.1.15 six-1.16.0 statsmodels-0.12.2 threadpoolctl-2.1.0 xlrd-1.2.0 终于跑上了\n/opt/gridview//pbs/dispatcher/mom_priv/jobs/2439514.node1.SC: line 16: out_dir: command not found sigminer version 2.0.1 - Star me at https://github.com/ShixiangWang/sigminer - Run hello() to see usage and citation. Warning message: package ‘sigminer’ was built under R version 4.0.5 Loading required namespace: reticulate Python environment configuration. ==================== python: /slst/home/taozy/miniconda3/envs/sigminer/bin/python libpython: /public/slst/home/taozy/miniconda3/envs/sigminer/lib/libpython3.8.so pythonhome: /slst/home/taozy/miniconda3/envs/sigminer:/slst/home/taozy/miniconda3/envs/sigminer version: 3.8.2 | packaged by conda-forge | (default, Mar 5 2020, 17:11:00) [GCC 7.3.0] numpy: /slst/home/taozy/miniconda3/envs/sigminer/lib/python3.8/site-packages/numpy numpy_version: 1.20.3  NOTE: Python version was forced by use_python function  ************** Reported Current Memory Use: 0.41 GB *****************  Extracting signature 2 for mutation type 176 The matrix normalizig cutoff is 17600 参考：  how can i install torch  ","date":"June 4, 2021","image":null,"permalink":"/post/2021-6-4_torch1.5.1_error/","title":"ERROR: Could not find a version that satisfies the requirement torch==1.5.1"},{"categories":["技术"],"contents":"引言 小雨毕业填各种表格，发现数字很长的时候会直接用0替代超长位数的数字，检索之后，给她解决了这个小问题。\n操作方法 设置数字格式，在自定义中输入@\n 重新输入可以发现已经可以了\n  参考资料：  Excel数字长度超13位尾号变0或E\u0026#43;，教你这招只用一个0就能搞定  ","date":"May 27, 2021","image":null,"permalink":"/post/2021-5-27_excel_number/","title":"Excel数字长度超13位尾号变0"},{"categories":["计算机基础"],"contents":"引言 看了一下廖雪峰的官方网站中对多线程和多进程的讲解，写的真是又简洁又明了，结合今天workshop中zk提到的并行计算，简单汇总写个学习笔记。\n操作系统可以同时执行多任务，比如同时运行浏览器、QQ和word，CPU执行代码是按照顺序一条条的执行。\n操作系统执行多任务是让CPU对多个任务轮流进行交替执行，比如让浏览器执行0.1秒，让word执行0.1秒。\n不管是单核还是多核的CPU，都可以同时运行多个任务，单核CPU执行任务交替进行，多核CPU在任务数量多于CPU的核数时，也是交替执行任务。\n一、进程 计算机中一个任务为一个进程，浏览器是一个进程，word也是一个进程。部分进程内部需要同时执行多个子任务，比如使用word一边打字一边检查拼写，一边后台打印，子任务就是线程。\n操作系统调度的最小任务单位是线程。由于一个应用程序可以有，多个进程，也可以有多个线程，实现任务的方法包括：\n多进程模式（每个进程只有一个线程）：\n  多线程模式（一个进程有多个线程）：\n  多进程＋多线程模式（复杂度最高）：\n  二、线程 线程包含在进程内，多任务既可以多进程来实现，也可以单进程内的多线程实现，也可以混合多进程和多线程。\n和多线程相比，多进程的缺点在于：\n 创建进程比创建线程开销大，尤其是在Windows系统上； 进程间通信比线程间通信要慢，因为线程间通信就是读写同一个变量，速度很快。  多进程的优点在于：\n多进程稳定性比多线程高，因为在多进程的情况下，一个进程崩溃不会影响其他进程，而在多线程的情况下，任何一个线程崩溃会直接导致整个进程崩溃。\n多线程编程的特点在于：\n 经常需要读写共享数据，并且需要同步，比如播放电影时一个线程播视频，一个线程播音频，两个线程需要协调运行保持音画同步，因此多线程编程的复杂度高，调试更困难。  三、串行，并发与并行   串行 多个任务，执行时一个执行完再执行另一个。\n  并发 多个线程在单个核心运行，同一时间一个线程运行，系统不停切换线程，看起来像同时运行，实际上是线程不停切换。\n  并行 每个线程分配给独立的核心，线程同时运行。\n  四、CPU与核心  物理核  物理核数量=cpu数(机子上装的cpu的数量)*每个cpu的核心数\n 虚拟核  所谓的4核8线程，4核指的是物理核心。通过超线程技术，用一个物理核模拟两个虚拟核，每个核两个线程，总数为8线程。在操作系统看来是8个核，但是实际上是4个物理核。 通过超线程技术可以实现单个物理核实现线程级别的并行计算，但是比不上性能两个物理核。\n 单核cpu和多核cpu  都是一个cpu，不同的是每个cpu上的核心数，多核cpu是多个单核cpu的替代方案，多核cpu减小了体积，同时也减少了功耗，一个核心只能同时执行一个线程。\n参考资料：   廖雪峰的官方网站-多线程\n  认识cpu、核与线程\n  ","date":"May 24, 2021","image":null,"permalink":"/post/2021-5-24_threads_and_processes/","title":"线程和进程"},{"categories":["生物统计"],"contents":"介绍  p值的含义    假设存在药物A和药物B，想知道两种药物的区别？\n维基百科定义：p值是假设检验中假设零假设为真时观测到至少与实际观测样本相同极端的样本的概率（似乎很拗口）。\np值是介于0-1之间的数字，量化我们相信两种药物不同的信心，p值越接近0，越相信两者不同。当p的阈值为0.05意味着，假设两种药物之间没有差异，执行多次且相同的实验，那么只有5%的实验会得出错误决定，简单来说，p值是对意外的测量。\np值能够帮助确定两种药物是否不同，但是不能告诉我们有什么不同，不管差异是都大还是小，都可以使用较小的p值，即较小的p值不代表差异是大还是小，只是代表意外的结果概率更小 。\n 阈值0.05的由来  不出于逻辑或统计原因，只是科学惯例。\n 术语：假阳性  指的是没有差异时却获得小的p值的情况。\n 术语：假设检验（Hypothesis testing）  试图确定这些药物是否相同的想法。\n 术语：零假设（Null Hypothesis）  零假设是药物相同，p值帮助我们决定是否拒绝零假设。\n统计显著性检验分支 分为以下两个主要的：\n  R.A.Fisher\n  Neyman and Pearson\n  控制假设检验的两类错误很重要：\n 第一类错误  无效说成有效（取伪）。\n第二类错误。  有效判成无效（弃真）。\n这两种错误不能同时消除，但是可以给出一种规范的决策过程来确保第一类错误的可能性只在预先确定的比率下发生（奈曼和皮尔逊），这个比率为显著性水平α（false positive rate），可以根据经验和期望基础设置合适的α，举例：\n建立10%的第一类错误率，设置α = 0.1，当希望决策更加保守，可以将α设置成0.01或更小。确定α后，可以考察哪个 检验过程 的第二类错误的比率更低。\n该体系下，定义一个原假设，即“无效”的假设，再定义一个备择假设，“效应大于0”，构建一个检验去比较这两个假设，假设使用p值，如果p\u0026lt;α，拒绝原假设（费希尔的检验过程把注意力放在揭示任何一个特定的试验证据的强度），p值的大小只用来是否“拒绝原假设”。\n误区 误区1：一次试验的第一类错误率为3.2%\n注意，仅仅通过一次试验不能得到第一类错误率，这是由检验过程决定的，不是一次试验的结果得到的，一个检验过程得到的是一个长期的第一类错误率，不能对应到每一次试验得到的真实p值和对应的第一类错误率。\n误区2：p值越小，差异越大\np值仅仅反应我们相信我们存在差异的信心，p值越小，越有信心拒绝零假设，不管差异是大还是小。\n误区3：P值就是假阳性率\n拒绝原假设犯错属于一类错误，错误的概率就是我们的α，p值只是我们根据一次抽样结果计算出来的值。P \u0026lt; α）表达的是在一次抽样中出现当前结果及更极端结果的可能性比我们认为的在一次抽样中不可能发生的小概率事件的概率更小。\n置信区间 一个置信区间包含一个点估计，和该估计的不确定性。举例：\n如果想检验这个效应量是否显著区别于0，可以构建一个95%的置信区间来检验这个区间是否包含0。\n参考：   《StatQuest》\n  《统计会犯错：如何避免数据分析中的统计陷阱》\n  统计知识|谈谈P值和α水平\n  ","date":"April 10, 2021","image":null,"permalink":"/post/2021-4-07_p%E5%80%BC/","title":"p值"},{"categories":["生信"],"contents":"前言 最近需要对TCGA和PCAWG的表达数据进行免疫浸润水平分析，使用了R包immunedeconv,其中TCGA已经有文献的supplement给出了不同免疫浸润工具进行分析的结果，PCAWG需要自己手动分析，其中CIBERSORT在immunedeconv包中运行需要两个文件：LM22.txt，CIBERSORT.R，需要在官网：https://cibersortx.stanford.edu/ 进行申请。\n上传数据  mixture file  官网上会列出上传数据的要求，我上传了PCAWG的基因表达counts矩阵，数据的第一列是genesymbol的名称，而且第一列的列名需要加上：“GeneSymbol”，数据的第一行是样本的名称。\n注意上传数据的时候，需要勾选自己上传的数据属于哪种类型，否则在分析数据中无法选择到自己上传的数据。\n进行分析 选择cell fraction的custom，得到免疫浸润细胞比例结果，选择custom分析自己的数据。\n勾选LM22作为参考matrix，选择自己上传的matrix作为mixture matrix，需要比较样本间时记住勾选abs。\n运行过程中，可以看到报错信息和输出信息。\n","date":"April 6, 2021","image":null,"permalink":"/post/2021-4-06-cibersort/","title":"使用CIBERSORTx网页版分析免疫浸润"},{"categories":["生物统计"],"contents":"引言  线性回归  假设数据包含 尺寸 和 重量 两组，根据这两组数据用 最小二乘法 拟合一条线后，我们可以做如下的事情：\n  计算r平方来确定两个变量是否相关\n  计算p值确定R平方是否具有统计显著性\n  用于预测，如果一个新鼠标有某重量，可以根据这个线来预测其大小\n  多元回归  假设用 体重 和 血容量 来预测大小，拟合曲线可做上述三个同样的事情，还可以用离散型数值来预测大小。\n比较模型  进行正态回归，使用权重来预测大小。\n逻辑回归 S型函数定义：\n  S 型函数会产生以下曲线图：\n y\u0026rsquo; 是逻辑回归模型针对特定样本的输出。 z 是 b + w1x1 + w2x2 + … wNxN w 的值是该模型学习的权重，b 是偏差。 x 的值是特定样本的特征值。  线性回归的损失函数是平方损失。逻辑回归的损失函数是对数损失函数。\n  逻辑回归预测事物是对还是错，而不是连续的事物，通常用于分类，根据该目的拟合了“S”形曲线，可以给出概率。\n假设这里用体重来预测肥胖，或者基因型和体重来预测肥胖，即不仅可以处理体重和年龄等连续数值，还可以处理离散数值，可以测试每个变量是否对预测肥胖有用。\n 最大似然法拟合曲线  本质就是不停的计算，选择具有最大似然的曲线。\n最大似然 最大似然的目标是找到使分布适合数据的最佳方法。不同类型的数据存在不同类型的分布，让分布适合数据可以让数据的使用更轻松，更通用，使它适用于相同类型的每个实验，假设称重了一批老鼠如下：\n在这种情况下，认为老鼠体重可能呈正态分布，正态分布意味着：\n  老鼠的重量 接近均值 或平均值。\n  期望测量值围绕平均值相对对称。（虽然看起来不是完全对称，但是也没有非常明显的偏向）\n  正态分布存在多种大小和形状，如下：\n当确定形状之后，要找出居中的位置。\n假设选任何一个旧的正态分布，下图分布表示测量的大多数值应该接近平均值，看看它对数据的拟合程度（黑色虚线处是分布平均值）：\n发现测量的大多数值和分布的均值相差很大（右边多数的测量值的似然很低），如果将正态分布移到其均值和平均体重相同的位置：\n发现红色圈出部分的似然相对高，继续移动正态分布，这些测量值的似然再次下降：\n可以在分布中心的位置，绘制观察到数据的似然，从左侧开始，计算观察数据的似然，将分布向右移动并重新计算似然：\n当尝试了所有可能的位置，就可以将正态分布置于需要的位置，即最大化观察我们所测量值的似然的位置，以上都是平均值的最大似然估计，这里讨论的是分布的均值，不是数据的均值吗，接下来找出标准差的最大似然估计：\n日常对话中，概率和似然（likelihood）可能指的是同一个概念，但是在统计学中，似然（likelihood）指的是：尝试针对给定的一组观察到的测量值，找到分布的最佳均值或标准差，这就是找到适合数据分布的过程。\n参考：   《StatQuest》\n  《统计会犯错：如何避免数据分析中的统计陷阱》\n  逻辑回归(Logistic Regression)：计算概率|机器学习速成课程\n  ","date":"April 6, 2021","image":null,"permalink":"/post/2021-4-11_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/","title":"逻辑回归"},{"categories":["技术"],"contents":"前言 最近写文章的时候，发现修改时调整参考文献的引用，是一件非常麻烦的事情，于是找到了一种简便的方法进行调整，发现了用Latex写论文原来这么好用（据涛哥和翔哥说，word也可以自动调整引用文献顺序，而我一直不知道\u0026hellip;）。\n主要内容  LaTex基本语法 模板的使用 文献的引用 排版的调整 特殊符号的引用 图片表格的插入  使用的工具  Oneleaf —— Online LaTeX Editor（推荐）  优点：不用本地搭建环境；在线编辑并渲染；部分投稿期刊直接提供链接模板。\n MacTeX—— For mac  mac的我还没有安过，仅列出来供参考。\n TexWorks —— For windows（我觉得很好用）。  除了上面列出来的，还有很多其他的，根据自己的喜好使用吧。\n基本语法  整体框架  注意到一个部分有开始也有结束，中间就是这个部分的内容。\n\\documentclass{article}  \\begin{document} First document. This is a simple example, with no extra parameters or packages included. \\end{document}  preamble  在LaTex中，所有在document内容之前的都称为preamble,在preamble中可以定义整个文档的格式、使用的语言、你需要使用到的宏包、以及其他的元素。举例：\n\\documentclass[12pt, letterpaper]{article} %设置 \\usepackage[utf8]{inputenc} %加载了名叫inputenc的宏包，设置使用utf-8来编码。 在[]方括号中都是一些参数的选择，documentclass中设置了字体大小为12pt（默认的字体大小是10pt），纸张大小为信纸，其他的设置可以看\u0026lt;font color=blue\u0026gt;Oneleaf的文档说明\u0026lt;/font\u0026gt;。\n这些内容也属于preamble：\n标题\n\\title{First document} 作者\n\\author{cat} 日期\n\\date{March 2021} 谢言\n\\thanks{funded by the Overleaf team}  document内容  字体的简单格式可以通过以下代码实现：\nSome of the \\textbf{greatest} %字体加粗 discoveries in \\underline{science} %加入下划线 were made by \\textbf{\\textit{accident}}. %斜体   还有更多的字体变换可以更改，具体参考\u0026lt;font color=blue\u0026gt;字体格式\u0026lt;/font\u0026gt;，来个简单的应用示例感受一下它的实用性。\nOneleaf 示例 1. 模板的使用 进入 \u0026lt;font color=blue\u0026gt;Oneleaf模板\u0026lt;/font\u0026gt;，选择合适的模板 这其中包括\u0026lt;font color=blue\u0026gt;国科大的毕业论文模板\u0026lt;/font\u0026gt;、\u0026lt;font color=blue\u0026gt;开题报告模板\u0026lt;/font\u0026gt;，以及各种杂志期刊、简历、信件、海报、报告、作业和写书的模板等等（部分期刊杂志会提供Oneleaf的模板）。\n 以论文写作为例 随便打开一个\u0026lt;font color=blue\u0026gt;模板\u0026lt;/font\u0026gt;，最右边是实时的渲染结果，中间是可以编辑的部分，左边是模板的目录下文件。\n  左边的目录下存储了4个文件：\n 以.bib结尾的文件  通常用来存储引用文献的信息，其中引用文献需要用特定的格式——BibTex存储，可以通过谷歌学术、百度学术或者其它方式进行导出（谷歌学术的导出功能经常会崩溃），如何使用Bibtex格式进行文献引用请跳转 \u0026lt;font color=blue\u0026gt;点击跳转\u0026lt;/font\u0026gt;。\n 以.bst结尾的文件  这个文件通常由期刊或杂志提供，设置了参考文献出现的文章结尾的方式，比如：设置排序方式，设置作者名称是缩写还是全称，标题的大小写等等，一般不需要自行维护，而且可以根据自己的需求来在.tex中重新调整。\n 以.tex结尾的文件  这个是进行文档内容编辑的文件，可以在这个文件中加载宏包，进行内容以及格式的更改。\n 以.cls结尾的文件  这个文件通常是类文件，通过文档最前面的\\documentclass导入，这里的\\documentclass[options]{class}是用来指定文档类型的，可以通过options参数来定制文档类的属性，不同的选项之间需要用逗号隔开，比如这里的\\documentclass[final,3p]{CSP}，其中final指的不在页面的边缘标记一个黑色框，这个3p对它的解释是：\n formats the article to the look and feel of the final format of model 3+ journals.\n 我没明白这个3+model是什么意思，但是通过调试，发现这个数字越大，页面距就越大。\n另外别的模板中还存在这些文件：\n .bbl文件  这是编译之后形成的文件，这里直接就显示了编译后的形式，可以直接下载PDF文件。\n .sty文件  这是包文件，通常使用\\usepackage导入。\n2. 内容的编辑以及参考文献的引用 内容的编辑 载入宏包的方法是在文档开始前\\begin{document}，写入\\usepackage{package}\n这里介绍几个常用的宏包：\n  数学公式 - amsmath\n  插图 - graphicx\n  颜色 - xcolor\n  表格 - array\n  中文 - ctex, xecjk\n  西文 otf 字体 - fontspec\n  英文下划线 - geometry\n  特别的，当要使用英文下划线-时，比如写入sigminer包中的函数名read_maf时，并不能直接识别下划线，需要载入该包来处理，或者给每处下划线改成\\_也可以不用载入包来识别。\n 超链接 - hyperref  语法：\\usepackage[options]{hyperref}\n示例：加入超链接，同时将文献也超链接到reference中，并且设置超链接的颜色，常用的设为蓝色或者黑色。\n\\usepackage[backref, colorlinks,linkcolor=blue]{hyperref}   \n文献的引用  保存引用文献信息(google)  如下图所示，谷歌学术中可以直接得到BibTex这种引用格式，将文献信息存储在.txt中，然后更改后缀为.bib即可。\n  点击 BibTex 后会弹出下图所示页面，复制内容至.bib文件内即可。\n   在tex文件中对引用格式进行设置  在文档结束位置\\end{document}前，增加对参考文献格式以及引用的设置，比如：\n\\bibliographystyle{bibft}\\it \\bibliography{bibfile} bibft是模板自带并自己命名的格式文件，这是由.cls文件定义的，bibfile就是制作好的bibtex文件，\n注意这里的文献引用格式有很多种，除了模板中定义的格式，可以通过参数的调整将格式更改为自己想要的，比如常用的，在方括号中标注数字，并且根据文献引用的先后顺序对reference排序：\n\\begin{document} \\bibliographystyle{unsrt}  \\bibliographystyle{unsrt} %根据引用顺序自动排序 \\bibliography{bibfile.bib} %引用文献的文件 \\end{document} 我认为最方便的地方就是这里，能够根据文献引用的顺序对reference进行自动排序。\n 保存引用文献信息(zotero)  在zotero中设置导出为BibTex，在zotero中通过command+shift+c就可以直接复制出该文献的BibTex引用格式。\n   在tex文件中进行引用  通常在正文中有很常见的几种文献引用格式： 温哥华格式（上标形式） 哈佛格式（直接显示作者和发表年份） IEEE 格式（方括号内标注引用顺序）\n在文中一般使用\\cite{}进行引用，括号中的内容就是BibTex中的第一个参数，这个是可以自定义的，通常都是作者的姓或者名+发表年份+论文题目的首个单词。\n@inproceedings{song2013hierarchical,  title={Hierarchical representation using NMF},  author={Song, Hyun Ah and Lee, Soo-Young},  booktitle={International conference on neural information processing},  pages={466--473},  year={2013},  organization={Springer} } 另外还有宏包natbib，通过不同形式的cite比如：\n\\citet：\n\\citet{jon90} ## Jones et al. (1990) \\citep：\n\\citep{jon90}\t## (Jones et al., 1990) \\citeyear：\n\\citeyearpar{jon90} ## (1990) \u0026hellip;\u0026hellip;\n该宏包的使用方式如下。\n\\usepackage[option]{natbib}  \\bibliographystyle{natbib} \\bibliography{bibfile} 3. 表格的制作 分为以下两个部分：\n 手动输入表格（适合小型表格） 其他工具进行表格转换   Excel中的表格  可以在Excel中使用插件：Excel2Latex，该插件能够将Excel表格转化为LaTex的表格形式。\nWord中的表格  可以使用pandoc直接转换为.tex格式，不过转换之后不是完美的，可能需要手动调整一下。\n示例：\npandoc test.docx -o test.tex 其他文件形式的表格  比如在R当中得到的表格，可以使用stargazer包把结果输出为LaTex格式，或者xtable包。\n以xtable包为例：\n\u0026gt; install.packages(\u0026#34;xtable\u0026#34;) #安装xtable \u0026gt; library(xtable) #载入 \u0026gt; data(iris) # 示例数据 \u0026gt; xtable(head(iris),digits=3,caption=\u0026#34;Head of Iris Data\u0026#34;) #将iris数据前6行 # 保留三位小数 #标题设为\u0026#34;Head of Iris Data\u0026#34;，导出为LaTex格式 % latex table generated in R 4.0.2 by xtable 1.8-4 package % Sat Mar 6 20:04:47 2021 \\begin{table}[ht] \\centering \\begin{tabular}{rrrrrl}  \\hline  \u0026amp; Sepal.Length \u0026amp; Sepal.Width \u0026amp; Petal.Length \u0026amp; Petal.Width \u0026amp; Species \\\\  \\hline 1 \u0026amp; 5.100 \u0026amp; 3.500 \u0026amp; 1.400 \u0026amp; 0.200 \u0026amp; setosa \\\\  2 \u0026amp; 4.900 \u0026amp; 3.000 \u0026amp; 1.400 \u0026amp; 0.200 \u0026amp; setosa \\\\  3 \u0026amp; 4.700 \u0026amp; 3.200 \u0026amp; 1.300 \u0026amp; 0.200 \u0026amp; setosa \\\\  4 \u0026amp; 4.600 \u0026amp; 3.100 \u0026amp; 1.500 \u0026amp; 0.200 \u0026amp; setosa \\\\  5 \u0026amp; 5.000 \u0026amp; 3.600 \u0026amp; 1.400 \u0026amp; 0.200 \u0026amp; setosa \\\\  6 \u0026amp; 5.400 \u0026amp; 3.900 \u0026amp; 1.700 \u0026amp; 0.400 \u0026amp; setosa \\\\  \\hline \\end{tabular} \\caption{Head of Iris Data} \\end{table} 表格的介绍 表格的基本格式和要素如下（2行2列表格）：\n\\documentclass{article} \\usepackage{float}%提供float浮动环境 \\usepackage{makecell} %%用来基线 \\begin{table}[h] \\centering %%表居中 \\caption{table} %%表格标题  \\begin{tabular}{|c|c|} %%{cc} 表示各列元素对齐方式，left-l,right-r,center-c，两个c表示两列，｜表示增加垂直方向基线 \\hline %%\\hline 在此行下面画一横线 a \u0026amp; b \\\\\\hline c \u0026amp; d\\\\ \\hline \\end{tabular} \\end{table}  \\end{document}   当表格太大或者太小的时候，有非常多的解决办法，可以通过调整字体的长或宽，也可以直接整体调整表格的大小，本质都是通过在tabular类外，套上调整表格的参数设置。\n通过调整字体的宽度（mm是百分比，60mm就是60%）：\n\\resizebox{\\textwidth}{60mm}{} 通过调整表格的大小：\n\\usepackage{graphicx} \\begin{table}  \\caption{表格标题} \\scalebox{0.9}{ %缩小至原来的90% \\begin{tabular} …… \\end{tabular}} \\end{table} 文献中常用的三线表可以通过以下Latex实现：\n\\documentclass{article} \\usepackage{float}%提供float浮动环境 \\usepackage{booktabs} %%提供命令\\toprule、\\midrule、\\bottomrule \\usepackage{makecell} %%用来基线 \\usepackage{geometry} \\usepackage{amsmath} %\\geometry{papersize={40cm,80cm}} \\geometry{left=1cm,right=1cm,top=3cm,bottom=1cm} \\begin{document}  %经典三线表 \\begin{table}[H] %%H为当前位置 \\caption{\\textbf{test title}}%标题 \\centering%把表居中 \\begin{tabular}{ccc}%四个c代表该表一共四列，内容全部居中 \\toprule[1.5pt]%第一道横线 year \u0026amp; month \u0026amp; day \\\\ \\midrule%第二道横线 2021 \u0026amp; 3 \u0026amp; 5 \\\\  \\bottomrule[1.5pt]%第三道横线 \\end{tabular} \\end{table}  \\end{document}   4. 图片的引入 LaTeX插入图片时，支持格式有各种：png, pdf, jpg, eps等等。\n 准备图片  将图片全部保存在目录下的同一个文件夹下，方便查找，注意图片的命名尽量避免中文，特殊字符等等(这里就只用了一个文件，我就直接放在目录下了)。\n 图片基本语法  必须加载graphicx等包来支持图片的导入。\n\\documentclass{article} \\usepackage{graphicx} \\graphicspath{ {images/} }  \\begin{document} The universe is immense and it seems to be homogeneous, in a large scale, everywhere we look at.  \\includegraphics{universe}  There\u0026#39;s a picture of a galaxy above \\end{document}  给图片进行排版（排版有很多种，现在展示的是两个图片并排）    \\usepackage{graphicx} %%插入图片的宏包 \\usepackage{float} %%设置图片浮动位置的宏包 \\usepackage{subfigure} %%插入多图时用子图显示的宏包 \\begin{figure} %%旋转子系统姿态角  \\centering  \\subfigure{  \\label{fig:subfig:a} %% label for first subfigure  \\includegraphics[width=4cm,height=4cm]{taoziyu.jpg}}  \\hspace{1in}  \\subfigure{  \\label{fig:subfig:b} % label for second subfigure  \\includegraphics[width=4cm,height=4cm]{taoziyu.jpg}}  \\caption{The same cute cat (a) cute cat1. (b) cute cat2.}  %% caption用于图表的标题  \\label{fig:attitude} %% label for entire figure \\end{figure} 参考资料  \u0026lt;font color=blue\u0026gt;Oneleaf官方文档\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;BibTex的使用方法\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;latex documentclass 及相关布局\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;document class\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;LaTex - 从出门到掉到坑\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;LaTex插入图形，表格\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;LaTeX排版札记\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;用R语言快速生成Latex表格\u0026lt;/font\u0026gt; \u0026lt;font color=blue\u0026gt;LaTeX高效写作系列：word表格转LaTeX\u0026lt;/font\u0026gt;  题外之言 该markdown文档中新使用了以下几个有趣的功能：\n 自定义锚实现页内跳转  在跳转目的地附近加上\u0026lt;span id=\u0026quot;jump\u0026quot;\u0026gt;目的地\u0026lt;/span\u0026gt;，在需要点击跳转的地方加上[点击跳转](#jump)\n  更改超链接颜色，更改字体颜色\n  多图片并列\n ","date":"March 5, 2021","image":null,"permalink":"/post/2021-3-05-latex_blog/","title":"使用Latex写论文"},{"categories":["技术"],"contents":"前言 最近师兄和涛哥都分享了这个流程：如何使用了R包blogdown搭建个人博客，但是我和轩哥在使用的过程中发现一个小问题，有一些主题似乎并不能很好的被blogdown安装的hugo来应用，几番求解无果，暂时将这个问题搁置，因为太喜欢这个theme不想放弃，所以找了一种不用blogdown的方法去搭建，终于取得成果。\n搭建流程  下载Hugo  Mac直接使用brew安装即可\n其他的系统可以直接参考官方文档：hugo官方文档\nbrew install hugo 部分主题依赖extended version（比如我使用的这个主题），所以检查一下Hugo版本\nhugo version Hugo Static Site Generator v0.80.0/extended darwin/amd64 BuildDate: unknown  使用Hugo建博客  #新的博客的名字就叫blog hugo new site blog ls archetypes\tcontent\tlayouts\tresources\tthemes config.toml\tdata\tstatic  设置博客主题  从Hugo的官网找到自己喜欢的主题：Hugo themes\n我使用了这个主题：hugo-future-imperfect-slim\n下面开始设置博客主题\ncd blog/themes #blog就是刚才新创建的博客目录，themes是它的子目录  git clone https://github.com/pacollins/hugo-future-imperfect-slim.git #点击主题页的download，进入GitHub主页，找到code⬇当中的网址进行clone #注意主题要下在theme目录下  cp themes/hugo-future-imperfect-slim/exampleSite/config.toml . #使用模板自带的配置文件替换blog目录下的配置文件 有的模板没有exampleSite目录，或者是config.toml文件名为其他的名字，不管怎样，用模板目录下的config文件替换blog目录下的config文件即可。\n像轩哥用的主题 hyde，根据其在github上的安装提示，对blog目录下的config文件首行增加theme = \u0026quot;hyde\u0026quot; 即可，无需拷贝模板的config文件。\n以及主题 npq-hugo，它的模板config文件不在exampleSite目录下，而是themes/npq-hugo/example-config.toml。\n 回到blog目录下创建新博文  cd .. hugo new posts/test.md #会在content/post文件夹下创建test.md的文件，可以直接对其进行修改 开始可能不会修改，可以根据主题目录中的范例进行模仿，我选择主题的范例文件储存在：\nblog/themes/hugo-future-imperfect-slim/exampleSite/content/blog\n 进行预览  hugo server -D Start building sites …   | EN | FR | PL | PT | DE | ES | ZH-CN | ZH-TW | JA | NL -------------------+----+----+----+----+----+----+-------+-------+----+-----  Pages | 11 | 8 | 8 | 8 | 8 | 8 | 8 | 8 | 8 | 8  Paginator pages | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Non-page files | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Static files | 27 | 27 | 27 | 27 | 27 | 27 | 27 | 27 | 27 | 27  Processed images | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Aliases | 3 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1  Sitemaps | 2 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1  Cleaned | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Built in 108 ms Watching for changes in /Volumes/home /github/taozy_blog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /Volumes/home /github/taozy_blog/config.toml Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 在浏览器中打开terminal中显示的网址进行预览： http://localhost:1313/\n你可以使用可以编辑md的工具进行内容修改，我习惯用Rstudio打开它进行更改，而且很棒的是，在编辑的过程中，预览网址上的内容也会实时的变更，很方便进行修改。\n 配置Github repository  我配置了两个repos，一个用于托管我blog目录下所有的文件，一个用来托管public文件夹用于博客的显示。\n 第一个repos随意命名  上传blog目录下的文件\n第二个repos必须命名为：your_git_name.github.io，才能够被当作个人的主页  上传public目录下的文件（注意不是public这个文件夹，而是该文件夹下的所有文件），目前还没有生成public文件，不要着急，继续下面的操作。\n在blog目录下执行下面的命令，把theme改成你自己的theme名称，baseUrl换成你自己的github名，执行完会在blog目录下生成一个public目录，将这个目录下的内容上传到your_git_name.github.io仓库中\nhugo --theme=hugo-future-imperfect-slim --baseUrl=\u0026#34;https://taoziyu97.github.io\u0026#34; Start building sites …   | EN | FR | PL | PT | DE | ES | ZH-CN | ZH-TW | JA | NL -------------------+----+----+----+----+----+----+-------+-------+----+-----  Pages | 11 | 8 | 8 | 8 | 8 | 8 | 8 | 8 | 8 | 8  Paginator pages | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Non-page files | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Static files | 21 | 21 | 21 | 21 | 21 | 21 | 21 | 21 | 21 | 21  Processed images | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Aliases | 3 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1  Sitemaps | 2 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1  Cleaned | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  Total in 209 ms  总结一下hugo-future-imperfect-slim这个主题的缺点\n 对于内容没有很好的汇总界面 只能一页一页的翻页，不能指定去哪一页 搜索内容的时候不支持中文    设置仓库的GitHub Pages  在仓库主页找到Setting，在Options中对Github Pages进行设置，如果你没有购买域名，那么你就可以在这步直接使用github提供的网址，作为你的博客网页，如果你有自己的域名（比如我从阿里云买了.cn的域名，我就将Custom domain设置为自己的域名）\n 解析域名方法1  打开域名解析，进行解析设置，添加两条记录，主机记录分别为@和www，记录类型为CNAME，记录值都指向github的网址，your_git_name.github.io\n现在打开个人主页试一试效果吧！\n 解析域名方法2（推荐，相对方法1速度更快一些）  Netlify 是一个提供静态资源网络托管的综合平台。参考这个链接内容部署：Netlify部署静态网页\n将Netlify随机生成的域名，在阿里云中进行解析设置。\n  Netlify中解析成功。\n  可以打开啦，访问速度比方法1快一些，另外，我的图是通过图床阅览的，方法2中拜托了github.io域名的限制，相当于把github当作一个储存的空间。\n","date":"January 21, 2021","image":null,"permalink":"/post/2021-1-11-build_blog/","title":"Hugo+Github+阿里云域名搭建个人博客（附Netlify部署方法）"},{"categories":["photography"],"contents":"Heading example Here is example of hedings. You can use this heading by following markdownify rules. For example: use # for heading 1 and use ###### for heading 6.\nHeading 1 Heading 2 Heading 3 Heading 4 Heading 5 Heading 6  Emphasis Emphasis, aka italics, with asterisks or underscores.\nStrong emphasis, aka bold, with asterisks or underscores.\nCombined emphasis with asterisks and underscores.\nStrikethrough uses two tildes. Scratch this.\n Link I\u0026amp;rsquo;m an inline-style link\nI\u0026amp;rsquo;m an inline-style link with title\nI\u0026amp;rsquo;m a reference-style link\nI\u0026amp;rsquo;m a relative reference to a repository file\nYou can use numbers for reference-style link definitions\nOr leave it empty and use the link text itself.\nURLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example).\nSome text to show that the reference links can follow later.\n Paragraph Lorem ipsum dolor sit amet consectetur adipisicing elit. Quam nihil enim maxime corporis cumque totam aliquid nam sint inventore optio modi neque laborum officiis necessitatibus, facilis placeat pariatur! Voluptatem, sed harum pariatur adipisci voluptates voluptatum cumque, porro sint minima similique magni perferendis fuga! Optio vel ipsum excepturi tempore reiciendis id quidem? Vel in, doloribus debitis nesciunt fugit sequi magnam accusantium modi neque quis, vitae velit, pariatur harum autem a! Velit impedit atque maiores animi possimus asperiores natus repellendus excepturi sint architecto eligendi non, omnis nihil. Facilis, doloremque illum. Fugit optio laborum minus debitis natus illo perspiciatis corporis voluptatum rerum laboriosam.\n Ordered List  List item List item List item List item List item   Unordered List  List item List item List item List item List item   Notice This is a simple note.\n This is a simple tip.\n This is a simple info.\n  Tab  This is first tab  this is second tab  this is third tab     Collapse collapse 1   This is a simple collapse  collapse 2   This is a simple collapse  collapse 3   This is a simple collapse   Code and Syntax Highlighting Inline code has back-ticks around it.\nvar s = \u0026#34;JavaScript syntax highlighting\u0026#34;; alert(s); s = \u0026#34;Python syntax highlighting\u0026#34; print s  Blockquote  This is a blockquote example.\n  Inline HTML You can also use raw HTML in your Markdown, and it\u0026rsquo;ll mostly work pretty well.\n Definition list Is something people use sometimes. Markdown in HTML Does *not* work **very** well. Use HTML tags.   Tables Colons can be used to align columns.\n   Tables Are Cool     col 3 is right-aligned $1600   col 2 is centered $12   zebra stripes are neat $1    There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u0026rsquo;t need to make the raw Markdown line up prettily. You can also use inline Markdown.\n   Markdown Less Pretty     Still renders nicely   1 2 3     Image  Gallery               Youtube video   ","date":"January 1, 2021","image":null,"permalink":"/post/elements/","title":"Elements That You Can Use To Create A New Post On This Template."},{"categories":null,"contents":"H1 Heading H2 Heading H3 Heading H4 Heading H5 Heading H6 Heading  Paragraph Did you come here for something in particular or just general Riker-bashing? And blowing into maximum warp speed, you appeared for an instant to be in two places at once. We have a saboteur aboard. We know you’re dealing in stolen ore. But I wanna talk about the assassination attempt on Lieutenant Worf. Could someone survive inside a transporter buffer for 75 years? Fate. It protects fools, little children, and ships.\n Emphasis :  Did you come here for something in particular or just general Did you come here for something in particular Did you come here Did you come here for something in particular Did you come here for something in particular  Did you come here for something in particular URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example).   Ordered list  you appeared for an instant to be in two places at once. We have a saboteur aboard. you appeared for an instant to be in two places at once.   Unordered list  Quisque sem ipsum, placerat nec tortor vel, blandit vestibulum libero. Morbi sollicitudin viverra justo Blandit vestibulum libero. Morbi sollicitudin viverra justo Placerat nec tortor vel, blandit vestibulum libero. Morbi sollicitudin viverra justo   Code and Syntax Highlighting : var s = \u0026#34;JavaScript syntax highlighting\u0026#34;; const plukDeop = key =\u0026gt; obj =\u0026gt; key.split const compose = key =\u0026gt; obj =\u0026gt; key.split alert(s); var s = \u0026#34;JavaScript syntax highlighting\u0026#34;; const plukDeop = key =\u0026gt; obj =\u0026gt; key.split const compose = key =\u0026gt; obj =\u0026gt; key.split alert(s);  Buttons Button  Quote  “Did you come here for something in particular or just general Riker-bashing? And blowing into maximum warp speed, you appeared for an instant to be in two places at once.”\n  Notice : This is a simple note.\n This is a simple tip.\n This is a simple info.\n This is a simple warning.\n  Tab :  Title goes here Did you come here for something in particular or just general Riker-bashing? And blowing into maximum warp speed, you appeared for an instant to be in two places at once. We have a saboteur aboard. We know you’re dealing in stolen ore. But I wanna talk about the assassination attempt on Lieutenant Worf.  Title goes here Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.  Title goes here Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo     Table :    # First Last Handle     1 Row:1 Cell:1 Row:1 Cell:2 Row:1 Cell:3   2 Row:2 Cell:1 Row:2 Cell:2 Row:2 Cell:3   3 Row:3 Cell:1 Row:3 Cell:2 Row:3 Cell:3     Collapse : collapse 1    Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur    collapse 2    Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur    collapse 3    Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur     Image  Gallery               Youtube :   ","date":"January 1, 1","image":null,"permalink":"/elements/","title":"Elements"},{"categories":null,"contents":"上海科技大学在读博士生。\n研究方向：癌症基因组学。\n  Find your passion and then aim to be the best on the planet at what you do by having a ferocious hunger for learning.\n-Unknown    My Skills \u0026amp; Experiences:  R 机器学习 生物信息  ","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/about/","title":"Hi, I Am Ziyu Tao"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/full/","title":"Homepage Full"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/full-left/","title":"Homepage Full Left"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/full-right/","title":"Homepage Full Right"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/grid/","title":"Homepage Grid"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/grid-left/","title":"Homepage Grid Left"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/grid-right/","title":"Homepage Grid Right"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/list/","title":"Homepage List"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/list-left/","title":"Homepage List Left"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://blog-1310600458.cos.ap-shanghai.myqcloud.com/20220408140841.png\" alt=\"\" class=\"img-fluid\" height=\"\" width=\"650\"\u003e\n","permalink":"/homepage/list-right/","title":"Homepage List Right"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin sit amet vulputate augue. Duis auctor lacus id vehicula gravida. Nam suscipit vitae purus et laoreet. Donec nisi dolor, consequat vel pretium id, auctor in dui. Nam iaculis, neque ac ullamcorper. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin sit amet vulputate augue. Duis auctor lacus id vehicula gravida. Nam suscipit vitae purus et laoreet.\nDonec nisi dolor, consequat vel pretium id, auctor in dui. Nam iaculis, neque ac ullamcorper.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin sit amet vulputate augue.\n","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/author/john-doe/","title":"John Doe"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/404/","title":"No Search Found"},{"categories":null,"contents":"Responsibility of Contributors Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\npretium, aliquam sit. Praesent elementum magna amet, tincidunt eros, nibh in leo. Malesuada purus, lacus, at aliquam suspendisse tempus. Quis tempus amet, velit nascetur sollicitudin. At sollicitudin eget amet in. Eu velit nascetur sollicitudin erhdfvssfvrgss eget viverra nec elementum. Lacus, facilisis tristique lectus in.\nGathering of Personal Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\nProtection of Personal- Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus.\nMolestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat\nPrivacy Policy Changes  Sll the Themefisher items are designed to be with the latest , We check all comments that threaten or harm the reputation of any person or organization personal information including, but limited to, email addresses, telephone numbers Any Update come in The technology Customer will get automatic Notification.  ","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/privacy-policy/","title":"Our Privacy Policy"},{"categories":null,"contents":"Responsibility of Contributors Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\npretium, aliquam sit. Praesent elementum magna amet, tincidunt eros, nibh in leo. Malesuada purus, lacus, at aliquam suspendisse tempus. Quis tempus amet, velit nascetur sollicitudin. At sollicitudin eget amet in. Eu velit nascetur sollicitudin erhdfvssfvrgss eget viverra nec elementum. Lacus, facilisis tristique lectus in.\nGathering of Personal Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\nProtection of Personal- Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus.\nMolestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat\nPrivacy Policy Changes  Sll the Themefisher items are designed to be with the latest , We check all comments that threaten or harm the reputation of any person or organization personal information including, but limited to, email addresses, telephone numbers Any Update come in The technology Customer will get automatic Notification.  ","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/terms-conditions/","title":"Our Terms And Conditions"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/search/","title":"Search Results"},{"categories":null,"contents":"Ask Us Anything Or just Say Hi, Rather than just filling out a form, Sleeknote also offers help to the user with links directing them to find additional information or take popular actions.\n","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/contact/","title":"Talk To Me Anytime :)"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/2021/","title":"归档"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/2022/","title":"归档"},{"categories":null,"contents":"","date":"January 1, 1","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hud5ac54a8ad9b9f4abf6483df88269ec8_11176_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/archives/","title":"归档"}]